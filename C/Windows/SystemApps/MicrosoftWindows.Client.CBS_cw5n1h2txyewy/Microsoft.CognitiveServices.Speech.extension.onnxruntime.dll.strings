!This program cannot be run in DOS mode.
3^RichA
.text
`.rdata
@.data
.pdata
@_RDATA
@.rsrc
@.reloc
UWATAVAWH
t$8L;
t$ L;
t$hL;
t$PL;
D$`H+
D$xH+
D$0L+
D$HL+
A_A^A\_]
UAVAWH
Ct$ H
A_A^]
UAVAWH
Ct$`H
Ct$@H
Ct$ H
A_A^]
UATAUAVAWH
ukL9-[
A_A^A]A\]
VAVAWH
)D$ f
0A_A^^
L$ fA
(D$ f
t$ WATAUAVAWH
tkfff
A_A^A]A\_
@SWAUAVH
8A^A]_[
SUVAUH
L$ H+
HA]^][
L$(H3
L$0H3
UVWAVAWH
A_A^_^]
@SVWH
VWAVH
0A^_^
T$ Ic
L$(H3
@SVWH
L$`H3
L$pH3
@SUVWAWH
 A__^][
 A__^][
@SWAWH
0A__[
t$ WH
VWATAVAWH
AXHc8H
 A_A^A\_^
|$ AV
L9Qhs
I9Jhs
L$ SVWH
@SVWATAUAVAWH
PA_A^A]A\_^[
UVATAVAWH
D+3L9c0u
Hcl$ H
HcD$ H
L$0H3
@A_A^A\^]
UVWAVAWH
L9{0u
Hc|$ L
HcD$ H
D8{8u;H
L$0H3
@A_A^_^]
|$ AVH
VAVAWH
|$@Hc
|$@Hc
 A_A^^
t$ WH
)D$ H
(D$@f
L$PH3
|$ ATAVAWH
 A_A^A\
VWATAUAWH
t4H91u/L
 A_A]A\_^
@SUVWATAUAVAWH
tMI9:uHM
(A_A^A]A\_^][
@SVWH
@SUVWAUAVAWH
t4I9*u/M
 A_A^A]_^][
@SUVWAVH
`A^_^][
@SVWH
L$HH3
l$ VWAVH
D$(eH
L$(H3
0A^_^
|$ AVH
(t$ H
)D$ H
(t$PH
@SVWAVAWH
L$XH3
`A_A^_^[
UVWAVAWH
A_A^_^]
\$ WH
\$ WH
|$ ATAVAWH
 A_A^A\
|$ ATAVAWH
 A_A^A\
@SVAVH
D$ Hc
L$ Hc
T$ H+
L$@H3
PA^^[
@SVAVH
D$ Hc
L$ Hc
T$ H+
L$@H3
PA^^[
L$0H3
L$0H3
\$ WH
@SUVWAVH
 A^_^][
 A^_^][
@SUATAUAWH
t*HcC
t^HcC
L$(H3
PA_A]A\][
teHcL$ )KTH
L$0H3
@SUVH
@SUAVH
t*HcA
taHcC
L$(H3
@A^][
CX9{Pu(
\$ WH
@SUVWAVH
 A^_^][
 A^_^][
L$(H3
t$ WATAUAVAWH
 A_A^A]A\_
@SUVAWH
(A_^][
(A_^][
u HcI(
t$ WH
\$p9Y0u
H9Y uRA
;w,~PA
t$ WH
G(9G,tPA
;w,~PA
HcQ0H
HcA,H
|$$9y0tAA
~,HcK,H+
HcC,H
C(+C,H
t$ WH
@SVWH
D$0Ic
;Y(|0
tAHcD$ H
HcL$ L
L$0H3
HcC,H
|$x@8y
|$x@8y
h VWATAVAWH
A_A^A\_^
VWATAVAWH
0A_A^A\_^
t'HcS
L$0H3
t$ WAVAWH
 A_A^_
@SWAVH
D$0Hc
|$@E3
L$0H3
`A^_[
\$ WH
D$(HcA
D$$A;
l$`A;
L$(H3
\$0Hc
\$0Hc
L$0H3
L$0H3
t$ WH
t$ WH
WATAUAVAWH
0A_A^A]A\_
@SWAUAVH
8A^A]_[
UVWATAUAVAWH
 A_A^A]A\_^]
@SUVWATAVAWH
 A_A^A\_^][
t$ WATAUAVAWH
 A_A^A]A\_
v?fD;
|$ AV
H9Qhs
I9Khs
t$ WH
L$(H3
|$ AVH
VWAVH
@A^_^
x AVH
\$ UH
M H1E
 H3E H3E
ntelA
GenuD
D$0E3
L$XH3
L$XH3
L$XH3
L$XH3
@SVWAVH
\$ E3
L$XH3
hA^_^[
VWAVH
L$XH3
`A^_^
@SVWATAUAVAWH
fffffff
fffffff
A_A^A]A\_^[
L$8H3
P(H;P0t
\$ VWATAVAWH
t$ E3
L$pH3
A_A^A\_^
\$ WH
L$XH3
t$ WH
L$HH3
\$ WH
L$XH3
\$ WH
L$XH3
\$ WH
L$XH3
\$ WH
L$XH3
\$ WH
L$XH3
@SVWATAUAVAWH
L$pH#
d$HI;
D$`H+
A_A^A]A\_^[
@SVWAVAWH
L$HH3
PA_A^_^[
@SVWATAUAVAWH
L$XH3
`A_A^A]A\_^[
WAVAWH
0A_A^_
|$ AVH
T$8H;
L$@H3
L$0H+
VWATAVAWH
\$0H+
L$@H3
PA_A^A\_^
L$ H+
SVWATAUAVAWH
A_A^A]A\_^[
SVWATAUAVAWH
A_A^A]A\_^[
@SVWATAUAVAWH
L$@H3
PA_A^A]A\_^[
@SVWH
L$HH;
L$HH;
L$HH3
@SVWH
L$XH3
@SVWH
L$XH3
@SVWH
L$XH3
@SVWATAUAVAWH
D$ H;
T$ H;
T$ H;
L$ L;
L$ L;
A_A^A]A\_^[
@SVWATAUAVAWH
gfffffffH
L$ L;
L$ L;
A_A^A]A\_^[
t$ WATAUAVAWH
A_A^A]A\_
VWATAVAWH
D$HI+
L$PH3
`A_A^A\_^
WATAUAVAWH
D$`HcH
D$`HcH
D$hE3
CT$(A
D$`HcH
D$`HcH
A_A^A]A\_
@SVWAVAWH
\$ E3
L$XH3
`A_A^_^[
@SVWAVAWH
L$XH3
`A_A^_^[
WAVAWH
L$hH;
A_A^_
WATAUAVAWH
A_A^A]A\_
WATAUAVAWH
A_A^A]A\_
s WAVAWH
A_A^_
VWATAVAWH
L$hH;
A_A^A\_^
)D$0L
)L$PL
VWAVH
L$8H3
L$8H3
VWATAVAWH
0A_A^A\_^
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
UWAVH
D$PHcH
D$PHcP
D$PHcH
L$PHcQ
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
UUUUUUU
D$0H9P }
H;Q }kM9O
)D$0L
UUUUUUU
A_A^A]A\_^]
\$ UVWATAUAVAWH
UUUUUUU
D$0H9P }
H;Q }kM9N
)D$0L
UUUUUUU
A_A^A]A\_^]
\$ UVWATAUAVAWH
\$X8P
D$0H9X }
H;Y |
)D$0L
A_A^A]A\_^]
\$ UVWATAUAVAWH
UUUUUUU
D$0H9P }
H;Q }kM9N
)D$0L
UUUUUUU
A_A^A]A\_^]
|$ E3
|$ E3
SUVWATAVAWH
A_A^A\_^][
SUVWATAVAWH
A_A^A\_^][
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
D$@L;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
D$@L;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
D$@H;
D$@H;
A_A^A]A\_^]
UVWATAUAVAWH
D$@L;
A_A^A]A\_^]
UVWATAUAVAWH
D$@H;
D$@H;
A_A^A]A\_^]
\$ WH
L$0H3
\$ WH
L$0H3
t$ WATAUAVAWH
A_A^A]A\_
VWATAVAWH
@A_A^A\_^
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
0A_A^A]A\_^[
SVWATAUAVAWH
0A_A^A]A\_^[
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
@SVWATAUAVAWH
tofff
|$0I;
PA_A^A]A\_^[
t$ WH
@UVWH
t$ E3
@SUVH
@SVWH
@SUVH
VWAVH
 A^_^
 A^_^
t$ WATAUAVAWH
t$ I;
A_A^A]A\_
t$ WATAUAVAWH
)t$`I
m fff
(D$ f
(t$`I
A_A^A]A\_
t$ WATAUAVAWH
)t$pI
3333333
(D$ f
3333333
(t$pI
A_A^A]A\_
\$ UVWH
@SUVWAVAWH
HA_A^_^][
@SUVWAVAWH
XA_A^_^][
S H+S
t$0ff
UVWAVAWH
PA_A^_^]
@USVWATAUAVAWH
L$HE3
D$PHcH
D$PHcH
FPI9FHtIH
D$PHcH
L$PHcQ
A_A^A]A\_^[]
VWAVH
 A^_^
VWAVH
L$8H3
@A^_^
l$ VWATAVAWH
UUUUUUU
A_A^A\_^
VWAVH
 A^_^
VWAVH
 A^_^
t$@H+
t$@H+
t$8H+
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWAVH
A^_^][
UWATAVAWH
L$pE3
H9|$p
A_A^A\_]
UVWAVAWH
A_A^_^]
L$@H3
@SVWH
L$0H3
L$@H3
L$HH3
\$ UVWATAUAVAWH
pA_A^A]A\_^]
\$ UH
@SUVWAVH
L$ 9L$$u H
T$8H+
L$@H3
PA^_^][
\$ UVWATAUAVAWH
l$8E3
A_A^A]A\_^]
T$8H+
L$@H3
@SUVWH
L$(H3
8_^][
@USVWAVH
A^_^[]
@SVWH
T$0H+
L$8H3
@SUVWH
t$ UWATAUAVH
T$hE3
D$pHcH
D$pHcH
L$pHcQ
L$pHcQ
A^A]A\_]
t$ WH
t$ WH
l$ VWAWH
t$HH+
 A__^
l$ VAVAWH
|$HH+
 A_A^^
l$ VAVAWH
|$HH+
 A_A^^
\$0ff
@SAUH
|$0fff
I#E0H
VWAVH
@A^_^
VWAVH
@A^_^
VWAVH
@A^_^
t$ WATAUAVAWH
|$HI;
A_A^A]A\_
t$ WATAUAVAWH
|$HI;
A_A^A]A\_
gfffffffH
t$8H+
t$8H+
L$0I;
L$0I;
L;AhL
BAhL+
@SVWATAUAVAWH
UUUUUUU
PA_A^A]A\_^[
l$ VWAVH
0A^_^
@SVWH
@SVWH
L$(H3
L$(H3
l$ VWAVH
\$(E3
0A^_^
@SVWH
@SVWH
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
|$ Mi
0A_A^A]A\_^[
@SUVH
@UVWH
t$ E3
@UVWH
t$ E3
@UVWH
t$ E3
SWAVAWH
HA_A^_[
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
UUUUUUU
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
L$=H;
L$@H3
L$=H;
L$@H3
t$ WATAUAVAWH
)t$PI
(D$ f
(t$PI
A_A^A]A\_
t$ WATAUAVAWH
)t$pI
(D$ f
(t$pI
A_A^A]A\_
VWAVH
 A^_^
\$ UVWH
S H+S
l$ VWAVH
|$ AVH
L$8H3
L$0H3
|$ AVH
L$8H3
VWAVH
 A^_^
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WH
t$8H+
\$ UVWATAUAVAWH
C\$pH
D$ E3
C\$PH
D$ E3
C\$pH
D$ E3
C\$pH
D$ E3
V H;V(t
C\$PH
D$ E3
C\$PH
D$ E3
C\$PH
D$ E3
A_A^A]A\_^]
L$PH3
t$ WH
L$pH3
@USVWAVH
pA^_^[]
@USVWAVH
pA^_^[]
\$ WH
L$HH3
\$ WH
L$HH3
@USVWH
x_^[]
l$ WAVAWH
t$HH+
 A_A^_
H#E0L
@SAVH
I#F0M
L$0I;
L$0I;
@SVWH
L$HH3
L$(H3
L$(H3
L$(H3
L$(H3
L$8H3
L$(H3
L$(H3
L$(H3
L$(H3
L$(H3
t$ WATAUAVAWH
D$ H9X s
H;Y r
UUUUUUU
)D$ H
A_A^A]A\_
@SVWH
@SVWH
L$pH3
L$@H3
UVWAVAWH
A_A^_^]
@SVWH
L$0H3
L$@H3
L$ WH
t$ WH
D;B(|
L$ SH
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
t$ WATAUAVAWH
t$8E3
d$@H;
D$ L)`
A_A^A]A\_
@SVWATAUAVAWH
D$0E3
D$0E3
PA_A^A]A\_^[
@SVWATAUAVAWH
t$0I;
`A_A^A]A\_^[
L$=H;
L$@H3
\$ UVWATAUAVAWH
d$PE3
\$ E3
(D$ f
pA_A^A]A\_^]
\$ UVWATAUAVAWH
d$PE3
(D$ f
`A_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
l$ VWAVH
D$(Hc
l$8@8h
D$0H9H s
H;K r
UUUUUUU
)D$ H
t$ WAVAWH
@A_A^_
t$ WH
t$ WH
@SUVWATAUAVAWH
xA_A^A]A\_^][
t$ WH
@SVWH
@SUVWAVAWH
hA_A^_^][
@SUVWH
H_^][
UVWATAUAVAWH
 A_A^A]A\_^]
UVWATAUAVAWH
 A_A^A]A\_^]
|$ AVH
t$8H+
t$ WH
UWAVH
|$ UAVAWH
|$ E3
A_A^]
t$ WH
L$@H3
t$ WH
L$@H3
t$ WH
L$@H3
t$ WH
L$@H3
t$ WH
L$@H3
t$ WH
L$@H3
t$ WH
L$@H3
|$ UH
|$ UH
AUAVH
I#E0H
tEfff
L$0H3
hA^A]
t$ WATAUAVAWH
A_A^A]A\_
t$8H+
L$ H3
UAVAWH
I#F0H
H;|$0tHH;
L9|$(u
PA_A^]
L9|$(u
I#F0L
SVWATAUAVAWH
PA_A^A]A\_^[
WATAUAVAWH
0A_A^A]A\_
l$ WH
Q +Q0
O +O0
8OPti
H+G8H
G D+G0D
\$ UVWAVAWH
D$ H;
A_A^_^]
@USVWATAUAVAWH
D$HH;
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
)D$ H
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
@USVWATAUAVAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A_A^A]A\_^[]
H+C8H
C(+C0
t$ UWAVH
t$ UWAVH
t$ H9q
D$@HcH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
|$ ATAVAWH
 A_A^A\
WAVAWH
 A_A^_
t$ WATAUAVAWH
t$8E3
d$@H;
D$ H)x
A_A^A]A\_
t$ WATAUAVAWH
l$8E3
L$@H;
A_A^A]A\_
@SUVWAVH
t$0H;
@A^_^][
SVWATAUAVAWH
gfffffffI
fffffff
@A_A^A]A\_^[
@SVWATAUAVAWH
d$8L;
PA_A^A]A\_^[
@SVWATAUAVAWH
D$(E3
D$(E3
D$(E3
T$0I;
PA_A^A]A\_^[
SVWATAUAVAWH
@A_A^A]A\_^[
@SUVH
@SVWH
@SUAVH
0A^][
@SUAVH
|$ E3
0A^][
@SUVH
@SUVH
@UAVAWH
d$ E3
@A_A^]
@SVWH
L$=H;
L$@H3
t$ WAVAWH
@A_A^_
\$ UVWATAUAVAWH
d$PE3
(D$ f
`A_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
L$@H3
L$(H3
\$ UVWATAUAVAWH
UUUUUUU
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
t$ WATAUAVAWH
\$$@2
A_A^A]A\_
VWAVH
L$8H3
@A^_^
t$ WH
t$ WH
VWAVH
L$8H3
L$8H3
L$8H3
|$ AVH
u4A8F
WAVAWH
 A_A^_
UVWATAUAVAWH
)t$@L
(D$ f
l$ fff
(t$@H
PA_A^A]A\_^]
L$0H3
L$0H3
L$0H3
|$ UATAUAVAWH
\$@E3
L$XH;
A_A^A]A\]
UVWATAUAVAWH
\$xE3
A_A^A]A\_^]
UVWATAUAVAWH
t$XE3
D$8H;
A_A^A]A\_^]
UVWATAUAVAWH
\$8E3
A_A^A]A\_^]
t$ WH
L$8H3
UVWATAUAVAWH
A_A^A]A\_^]
VWATAVAWH
L$ E3
L$8H3
@A_A^A\_^
L$0H3
|$ AVH
t$ WH
t$ WAVAWH
 A_A^_
kXH9+t
@8,:|
\$ WH
t$@H+
t$ WH
t$ WH
|$8H;
VWAVH
0A^_^
t$ WH
UWATAVAWH
t$ E3
A_A^A\_]
t$ UWAVH
|$ UH
UVWATAUAVAWH
A_A^A]A\_^]
VWAVH
 A^_^
l$ WAVAWH
t$HH+
 A_A^_
@USVWATAVAWH
L$8H+
G H;G(t
A_A^A\_^[]
\$ UVWH
UVWATAUAVAWH
A_A^A]A\_^]
@SUVWATAUAVAWH
A_A^A]A\_^][
WAVAWH
t$HI;
L$hH3
A_A^_
@SVWH
L$8H3
UVWATAUAVAWH
l$hE3
A_A^A]A\_^]
UVWATAUAVAWH
L$XH;
t$`L;
A_A^A]A\_^]
@USVWATAVAWH
L$HE3
|$ I;
D$PHcH
D$PHcH
D$PHcH
D$PHcH
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@SVWAVAWH
t$ E3
A_A^_^[
|$ UH
@SUVAVAWH
H+C8H;
D$XD+
L$Xf;
D+k0E
|$PD;
 A_A^^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
E0HcH
E0HcH
E0HcH
E0HcH
OxH;Oxu
)D$0f
)D$0f
t$ UWAVH
t$ UWAVH
t$ UWAVH
t$ UWAVH
|$ AVH
t$HI;
L$hH3
s WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
A_A^A]A\_^[
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
d$@E3
A_A^A\_^[]
(D$ H
(D$0H
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWAVAWH
A_A^_^]
t$ UWATAVAWH
A_A^A\_]
@SUVWATAVAWH
L$`H3
pA_A^A\_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SVWATAUAVAWH
|$PI;
A_A^A]A\_^[
WATAUAVAWH
@A_A^A]A\_
@SUVWATAVAWH
)t$@I
H;W8v
(t$@H
PA_A^A\_^][
\$ UVWATAUAVAWH
T$@E3
T$p+U
\$p+]
|$p+}
T$p+U
\$p+]
D$pD+E
T$p+U
\$p+]
D$pD+E
D$p+E
ORTMH
T$p+U
|$p+}
D$p+E
D$xLc
A_A^A]A\_^]
|$ UAVAWH
A_A^]
t$ UWAUAVAWH
E@HcH
E@HcH
D$PHcH
D$PHcH
D$PHcH
D$PHcH
M@HcQ
M@HcQ
A_A^A]_]
C@f99H
@USVWATAUAVAWH
A_A^A]A\_^[]
@VWAWH
@A__^
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
gfffffffH
gfffffffH
|$0E3
D$p(L
gfffffffH
A_A^A]A\_^[]
@USVWATAUAVAWH
T$HE3
gfffffffH
D$`HcH
D$`HcH
gfffffffH
D$`HcH
D$`HcH
|$ L;
A_A^A]A\_^[]
|$ AVH
WATAUAVAWH
t?fff
 A_A^A]A\_
WAVAWH
 A_A^_
|$ AVH
WAVAWH
 A_A^_
WAVAWH
 A_A^_
\$ UVWATAUAVAWH
|$ E3
A_A^A]A\_^]
UVWATAUAVAWH
t$pL;
CD$Hf
C8H;C@t
A_A^A]A\_^]
|$ AVH
|$ ATAVAWH
 A_A^A\
t$ ATAVAWH
gfffffffH
|$HH+
 A_A^A\
l$ VAVAWH
t#fff
|$HH+
 A_A^^
t$ WH
UUUUUUU
L$8H3
@SVWH
L$XH3
D$8H+
L$XH3
@SAUH
I#E0M
L;d$ u
H;t$ 
VWAVH
gfffffffI
fffffff
 A^_^
t$ WH
VWAVH
 A^_^
t$8H+
D$ I;
L$ H3
H#C0H
H9t$xu>M
9H9t$xu
H#A0H
UAVAWH
I#F0H
H;|$0tHH;
L9|$(u
PA_A^]
L9|$(u
I#F0L
UWAWH
H#G0H
H;|$0t
L9|$(
L9|$(u
tnfff
|$@H#A0H
`A__]
H#C0H
H9t$xu>M
9H9t$xu
H#A0H
t$PH;
\$Hfff
|$8H;
|$8H;
@SVWH
\$ UVWH
|$ UATAUAVAWH
C@H;}
tEH;U
C@H;U
A_A^A]A\]
H+A8H;
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SVWH
L$@H3
\$ WH
D$XH+
H9D$H
L$xH3
y(+y0A
q8+q(M
|$ AVH
@SUVWH
L$(H3
8_^][
@SVWH
D$ tp
L$(H3
L$8H3
)t$ f
(t$ u
\$ UVWH
L$ H;
>"t2H
L$(H3
L;AhL
BAhL+
@UVAVH
0A^^]
0A^^]H
|$ Hc
0A^^]
|$ AVH
l$0H+
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
t$ WATAUAVAWH
A_A^A]A\_
@UVWH
t$ E3
\$ UVWATAUAVAWH
(D$ f
PA_A^A]A\_^]
@USVWATAUAVAWH
VhH;VptoL
H9F0u)M
A_A^A]A\_^[]
@SUVWATAVAWH
H+AxH
H+CxH
A_A^A\_^][
UVWATAUAVAWH
u?fff
FxH;FxtJH
A_A^A]A\_^]
L$8H3
L$8H3
@SUVWAVAWH
D$HE3
XA_A^_^][
@SVAVH
l$HH+
 A^^[
@USVWATAVAWH
|$ E3
A_A^A\_^[]
CL$@H
CT$`H
L$(L;
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
|$0I;
A_A^A]A\_
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
@SVWATAUAVAWH
|$ M;
PA_A^A]A\_^[
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
t$ WATAUAVAWH
|$ I;
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
t$(I;
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
\$ UVWAVAWH
u;H;C
A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
\$ UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
`A_A^_^]
UVWAVAWH
D$pE3
T$(H;
A_A^_^]
UVWATAUAVAWH
|$ E3
CD$pf
L$pE3
A_A^A]A\_^]
UVWATAUAVAWH
|$ E3
L$8E3
A_A^A]A\_^]
t$ WH
L$8H3
l$ VWATAVAWH
L$`H3
A_A^A\_^
SUVWAVAWH
(A_A^_^][
t$ WH
L$8H3
t$ WAVAWH
\$0E3
3333333
)D$ L
A_A^_
UWATAVAWH
A_A^A\_]
VWAUAVAWH
Ic@8H
A_A^A]_^
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWAVAWH
A_A^_^]
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWAVAWH
A_A^_^]
\$ UVWAVAWH
A_A^_^]
t$ AVH
u.H;P
M90u7
@SUVH
(D$ L
(L$0A
L$0M;
t$ WH
\$ UVWH
\$ UVWH
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWH
|$ UAVAWH
txH+A
u7H;H
A_A^]
WAVAWH
)D$0L
\$ E3
D$0M+
t$ I+
(D$ f
(D$ f
D$@M;
PA_A^_
@USVWATAUAVAWH
t$8L;
CD$8f
T$`fH
C\$8H
CD$`f
C\$8H
t$ E3
C\$8H
t$ E3
A_A^A]A\_^[]
L$0H;SHt
t$ WH
T$ H;CHt
D$8H;
L$8H3
UVWATAUAVAWH
D$8L;
L$HE3
L;l$8
L$XH3
`A_A^A]A\_^]
S H;S(t
L$`H3
3333333
VWAVH
C(D8s
L$@H;SHt
 A^_^
t$ UWATAVAWH
A_A^A\_]
(D$ I
UVWAVAWH
t$ E3
A_A^_^]
WAVAWH
(D$ f
0A_A^_
L$0H3
C(@8{
L$ H;SHt
D$$trueA
D$$falsH
D$(eH
D$$nullA
L$0H3
L$8H;SHt
C(@8{
D$8H;SHt
C(@8{
L$8H;SHt
t$ WAVAWH
C(D8{
L$PH;SHt
 A_A^_
t$ WAVAWH
D$ H;QHt
S@H;SHt
S@H;SHt
S@H;SHt
S@H;SHt
L$0H3
@A_A^_
UVWATAUAVAWH
EgH;QHt
S@H;SHt
C@H;CHt
}offf
S@H;SHt
A_A^A]A\_^]
 !!"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$%&&&&&&&&&&&&'&&()))*f
C(@8{
L$0H;SHt
t$ WH
t$ WH
L$ SUVWH
8_^][
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
T$ H;
T$ H;
T$ H;
T$ H;
T$ H;
T$ H;
@SVWATAUAVAWH
l$8L;
PA_A^A]A\_^[
@SVWATAUAVAWH
L$pI+
H+T$`H
t$XI;
A_A^A]A\_^[
t$XI;
\$ UVWATAUAVAWH
d$PE3
(D$ f
pA_A^A]A\_^]
\$ UVWATAUAVAWH
D$PE3
(D$ f
pA_A^A]A\_^]
L$8H3
@SAUAVH
|$@I;
`A^A][
t$XL+
`A^A][
`A^A][
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
@SUVWAWH
8striu
t$pH;
8striu
L$ H3
0A__^][
UVWATAUAVAWH
PA_A^A]A\_^]
t$0H;
\$ UVWAVAWH
\$ E3
L$HH3
PA_A^_^]
WATAUAVAWH
S H+S
D$0D9x }
D;y }mH
)D$ L
A_A^A]A\_
L$0H3
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
@SUVWAVH
L$@H3
PA^_^][
UVWAVAWH
(D$ f
A_A^_^]
SVWATAUAVAWH
A_A^A]A\_^[
\$ VWAVH
L$PH3
`A^_^
@SVAVAWH
8A_A^^[
d$0E3
8A_A^^[
t$ WH
l$ VWATAVAWH
uo9w(t%H
ui9w(t%H
9w(t%H
A_A^A\_^
@USVWAVAWH
A_A^_^[]
D$HI;
(D$ H
D$HH;L$Ht
t$ WATAUAVAWH
|$XfI
L$hH3
A_A^A]A\_
L$(H3
L$(H3
UVWATAUAVAWH
)t$pI
)|$`H
(D$ H
(|$`H
A_A^A]A\_^]
\$ UVWATAUAVAWH
)t$pH
)|$`M
(|$`H
A_A^A]A\_^]
@SUVWATAUAVAWH
)|$pH
@8|$Pt
L$hH3
(|$pH
A_A^A]A\_^][
USVWATAUAVAWH
t5#7?
A_A^A]A\_^[]
L$`H3
L$xH3
t$ WATAUAVAWH
A_A^A]A\_
l$ WATAUAVAWH
A_A^A]A\_
L$(H3
D$HH;L$Ht
WAVAWH
L$XH3
A_A^_
L$(H3
UVWATAUAVAWH
)t$PL
)|$@H
L$ Hc
(|$@H
`A_A^A]A\_^]
\$ UVWATAUAVAWH
)t$`L
)|$PH
(|$PH
pA_A^A]A\_^]
VWATAVAWH
A_A^A\_^
\$ UVWATAUAVAWH
|$HL;
(L$pf
A_A^A]A\_^]
@USVWATAUAVAWH
\$D8YPtuH
H9y s
H;z r
H9x s
H;y suH
UUUUUUU
u:fff
H9x s
UUUUUUU
H9x s
H;y suH
UUUUUUU
H9x s
H;y suH
UUUUUUU
H9x s
H;y suH
UUUUUUU
|$hff
t$XH;
A_A^A]A\_^[]
USVWATAUAVAWH
D9|$h~
L$`H;
t$HH;
L;d$`
\$XI;
\$XI;
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
tensor(bH
ool)u
tensor(iH
nt16u
nt32u
nt64u
tensor(uH
int1u
6)t|L
int3u
2)tRL
int6u
4)t(L
int8u
float16)M9H
tensor(dM9
oublu
e)tTL
tensor(fM9
loatu
AVAWH
CPUExecuH9
tionProvH9H
(D$ f
D$ H;
HcK,I
HcK(I
8A_A^
(D$ f
|$0H;
\$ WH
l$Xff
VWATAVAWH
0A_A^A\_^
t_SVWH
D$(L;
(D$ H
VWATAUAVH
)t$`I
)|$PH
(D$ H
A^A]A\_^
UVWATAUAVAWH
)t$pI
)|$`H
(D$ H
(|$`H
A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
\$ UVWAVAWH
A_A^_^]
t$ WH
\$ UVWH
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
`A_A^A]A\_^]
(D$ f
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
`A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
`A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WH
\$ UVWH
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
\$ UVWH
UVWATAUAVAWH
`A_A^A]A\_^]
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
)t$`L
(D$0f
l$ fff
(t$`H
pA_A^A]A\_^]
VWATAVAWH
A_A^A\_^
UVWATAUAVAWH
pA_A^A]A\_^]
UVWATAUAVAWH
pA_A^A]A\_^]
@SVWAVAWH
@A_A^_^[
@UAVH
d$HE3
L9 u+H;
UVWAVAWH
A_A^_^]
@USVWAVAWH
A_A^_^[]
t$ UWATAVAWH
t$ E3
A_A^A\_]
@USVWATAUAVAWH
A_A^A]A\_^[]
D$PE3
D$XH;
@USVWATAUAVAWH
D$8E3
A_A^A]A\_^[]
@SUVATAVH
~ |\H
0A^A\^][
)t$ f
(t$ u
@SUAVH
L$ E3
L$`H3
pA^][
@SVWH
@VAVAWH
0A_A^^
t$ WH
@ H;}
H9r s/H
I;p rdH
L$(8H
D$ H9P s
H;u r
t$ AWH
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWAVAWH
l$8@8k
fffffff
)D$ L
PA_A^_^]
\$ UVWATAUAVAWH
\$0E3
l$8D8k
fffffff
)D$ H
PA_A^A]A\_^]
\$ UVWAVAWH
fffffff
)D$ H
`A_A^_^]
VWAVH
 A^_^
VWAVH
D$0E3
D$0L9@ s
)D$ L
PA^_^
\$ UVWATAUAVAWH
8L$@L
D$HE3
D$xH+
D$XH+
UUUUUUU
uUL9}h
L9p s
L9p s
L;s rwH;
A_A^A]A\_^]
UVWATAUAVAWH
|$pH;}
A_A^A]A\_^]
\$ UVWATAUAVAWH
H9P s
H;Q r
A_A^A]A\_^]
\$ UVWAVAWH
L$HH3
PA_A^_^]
@SVWH
L$(H3
@SVWH
L$hH3
UVWATAUAVAWH
t"fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
H9p s
H;q r
fffffff
A_A^A]A\_^]
UVWATAUAVAWH
L9x s
L;y spH
UUUUUUU
L$8L;
L$8L;
T$8H;
T$8H;
A_A^A]A\_^]
L9P s
L;R r
L9@ s
L;A r
VWAWH
@A__^
VWAVH
H;H s
L$ H3
0A^_^
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
)D$ H
)D$ H
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWAVH
D$0HcH
D$0HcH
)D$ H
L$0HcQ
L$0HcQ
A^_^[]
@USVWAVAWH
D$0HcH
D$0HcH
)D$ H
L$0HcQ
L$0HcQ
A_A^_^[]
@SVWH
L$@H3
t$ WATAUAVAWH
A_A^A]A\_
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
l$ WH
)D$ H
)D$ f
\$ UVWATAUAVAWH
D$PE3
(D$ f
pA_A^A]A\_^]
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
I#W0H
(D$ f
I#w0H
UVWATAUAVAWH
)t$pM
(D$ f
(t$pH
A_A^A]A\_^]
UVWATAUAVAWH
)t$`I
)D$ H
l$ ff
)D$ f
(D$0f
(t$`H
pA_A^A]A\_^]
t$ WATAUAVAWH
)t$`I
)D$ H
)D$ f
d$@E3
d$@E3
(D$0f
(t$`I
A_A^A]A\_
@UVAVH
 A^^]
t$ E3
t$8H+
@USVWAUAVAWH
A_A^A]_^[]
VWAVH
(D$@H
SWAUH
PA]_[
@SUVWATAUAVAWH
(D$Pf
T$pH+
A_A^A]A\_^][
@SUVWAVH
A^_^][
@USVWATAUAVAWH
U H;U(
E@H+E0H
t$PL;
6_outB
U8H;U@t
D$HH;E
D$xH;
CT$xL
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
\$ WH
)D$ H
@USVWAVH
pA^_^[]
@SUVWAVH
`A^_^][
`A^_^][
@SUVWAVH
PA^_^][
@SUVWAVH
`A^_^][
`A^_^][
@SUVWATAVAWH
`A_A^A\_^][
\$ UVWATAUAVAWH
)D$`f
L$0L;v
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SVWH
L$@H+
)D$ H
T$PH+
L$XH3
)D$ H
L$8H3
)L$ f
)D$ f
)D$ f
)D$ f
L$`H3
@SUVWAVH
L$8H3
@A^_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
UVWAVAWH
T$8E3
A_A^_^]
(D$0f
D$`H+
@SUVWAVH
L$ fI
PA^_^][
HcF0H
PA^_^][
t$ UWAUAVAWH
A_A^A]_]
\$ WH
H#W`L
@SUAVAWH
|$@ff
H#V`L
HA_A^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
L$PH3
(D$ L
\$ UVWATAUAVAWH
T$0H;
|$8H;
A_A^A]A\_^]
VWAVH
D$@E3
L$PH3
t$ WH
D$(I+
@USVWATAUAVAWH
L$pE3
D$0E3
)D$0L
T$hH+
)D$0f
T$hH+
)D$0L
T$hH+
D$0H;
D$0H;
D$@H+
D$@H+
D$hH+
A_A^A]A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
VWAUAVAWH
D$@E3
H98t=H
L$PH3
A_A^A]_^
t$ WH
l$ WAVAWH
t$HH+
 A_A^_
@SAVH
I#F0M
)L$@f
)D$0f
)D$0H
l$0fff
)D$@f
t$ WH
VWAVH
@A^_^
UVWATAUAVAWH
)t$pI
)|$`H
(D$ H
(|$`H
A_A^A]A\_^]
USVWATAUAVAWH
D$xH;
L$pH;L$x
A_A^A]A\_^[]
UVWATAUAVAWH
L$hH3
pA_A^A]A\_^]
\$ UVWATAUAVAWH
|$HI;
l$(@8t$0t
|$HH;
T$PH+
L$XH3
`A_A^A]A\_^]
VWATAVAWH
A_A^A\_^
t$ WATAUAVAWH
A_A^A]A\_
\$ UVWH
)t$@H
T$0H;
T$0Hc
L$8H3
(t$@H
D$HH;L$Ht
WAVAWH
L$XH3
A_A^_
@SUVWATAUAVAWH
HA_A^A]A\_^][
t$ WH
@SVWH
t$ WH
t$ UWATAUAVH
T$XE3
A^A]A\_]
|$ UATAUAVAWH
|$8M;
D$HH+
A_A^A]A\]
|$ UATAUAVAWH
|$8M;
D$HH+
A_A^A]A\]
@USVWATAVAWH
(D$0f
A_A^A\_^[]
(D$0f
UVWATAUAVAWH
(D$ f
(D$0f
(D$0f
A_A^A]A\_^]
@SVWH
@SVWH
|$ UH
\$0Hk
@USVWATAUAVAWH
L;uhH
D$@E3
D$hH+
A_A^A]A\_^[]
@USVWATAUAVAWH
1Lcx,D
|$ E3
L$hH;L$x
A_A^A]A\_^[]
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
\$ UVWATAUAVAWH
L$`E3
D$XE3
H+L$@H
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
UVWATAUAVAWH
L$xH+
A_A^A]A\_^]
|$ UATAUAVAWH
D$pfD
A_A^A]A\]
|$ UATAUAVAWH
D$PfD
D$PfD
t$hL;
D$xL+
A_A^A]A\]
|$ UATAUAVAWH
L$xH+
A_A^A]A\]
UVWATAUAVAWH
L$xH+
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
L$xH+
A_A^A]A\]
UVWATAUAVAWH
t$@E3
D$0L;
d$ L;
L$PH3
`A_A^A]A\_^]
@SVWH
\$ H+
D$ H;
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
l$ VAVAWH
|$PL+
d$XL+
0A_A^^
l$ VAVAWH
|$PL+
d$XL+
0A_A^^
VWAVH
 A^_^
VWAVH
 A^_^
t$ WH
@SUVWATAUAWH
t$xH+
 A_A]A\_^][
 A_A]A\_^][
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
T$HL+
PA_A^A]A\_^[
PA_A^A]A\_^[
SVWATAUAVAWH
L$0I+
`A_A^A]A\_^[
`A_A^A]A\_^[
H;APuS
@SUVWATAVAWH
\$0E3
u?fff
)D$ H
PA_A^A\_^][
t$ WH
t$ WH
l$ VWAVH
 A^_^
l$ VWAVH
 A^_^
l$ VWAVH
 A^_^
VWAVH
 A^_^
\$ UVWATAUAVAWH
W0H;W8t
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
A_A^A]A\_^]
t$ WH
@USVWATAUAVAWH
L$xH;
H;D$x
A_A^A]A\_^[]
t$HI;
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
(D$0f
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UWATAVAWH
A_A^A\_]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAVAWH
A_A^A\_^[]
@SUVWATAUAVAWH
u0fff
hA_A^A]A\_^][
t$ UH
USVWATAUAVAWH
(D$`f
t$ E3
(D$`f
(D$`f
(D$`f
(D$`f
(D$`f
(D$pf
(D$pf
(D$`f
(D$pf
@8|$P
)t$pH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
(D$`f
A_A^A]A\_^[]
@USVWATAUAVAWH
(D$`f
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWATAUAVAWH
hA_A^A]A\_^][
VWAVH
 A^_^
@USVWATAUAVAWH
(D$@f
(D$@f
A_A^A]A\_^[]
UVWATAUAVAWH
F(9_(
A_A^A]A\_^]
@USVWATAUAVAWH
|$4E9y(
(D$@f
(D$@f
(D$Pf
(D$Pf
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$`H+
D$`H+
A_A^A]A\_^[]
D$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8I;P
L$8H;S
L$8H;S
L$8H;S
L$8H;S
L$8H;S
UATAUAVAWH
A_A^A]A\]
\$ UVWATAUAVAWH
A_A^A]A\_^]
t$ WH
\$ VH
t$ WH
t$8H+
@SVWH
L$ H3
t$ WATAUAVAWH
)t$pI
(D$ f
(t$pI
A_A^A]A\_
@USVWATAUAVAWH
txfff
t$HH;
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
t$ WATAUAVAWH
)t$`I
)|$PH
(D$ H
A_A^A]A\_
H9A u
@USVWATAUAVAWH
A_A^A]A\_^[]
L;t$`
L;t$`
\$ UVWATAUAVAWH
|$@L;
C\$@H
C\$`H
(D$@f
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
\$@D;
A_A^A]A\_^]
Q HcZ 3
t$ WH
t$ WH
D$HI;
D$HI;
D$HH;L$Ht
D$HH;L$Ht
WAVAWH
L$XH3
A_A^_
t$ WATAUAVAWH
|$XfI
L$hH3
A_A^A]A\_
t$ WH
@SVWH
D$ H;D$(t H
D$ H;D$(u
L$0H3
UAVAWH
 A_A^]
 A_A^]
\$ UVWATAUAVAWH
(D$ f
PA_A^A]A\_^]
t$ WH
UVWATAUAVAWH
@A_A^A]A\_^]
USVWATAUAVAWH
UUUUUUU
UUUUUUU
(D$pf
D$hH;E
D$hH;E
A_A^A]A\_^[]
t$0Hc
t4HkS
UVWATAUAVAWH
0A_A^A]A\_^]
t$ WH
t$8H;
L$XH3
VWAVH
t$8H;
L$XH3
`A^_^
|$ H9A
UVWATAUAVAWH
t>fff
0A_A^A]A\_^]
L#o0M
tkK9<
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
UVWATAUAVAWH
`A_A^A]A\_^]
t$ WH
t$ WH
@USVWATAUAVAWH
D$`H+
L$DH;
D$PL;
CT$PL
t$ E3
gfffffffH
|$HE3
gfffffffH
|$HE3
A_A^A]A\_^[]
UVWATAUAVAWH
D$8H;
t$HH+
A_A^A]A\_^]
UVWATAUAVAWH
t$0L;
t$0L;
A_A^A]A\_^]
t$ UWAVH
l$ VWAVH
t*fff
GPH9GHthH
L$pH3
H9_@~
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
H;G@|
VWAWH
)t$@I+
IHL;IPu
L;FPuS
IHL;IPu
L;FPuS
IHL;IPu
L;FPuS
IHL;IPu
L;FPuS
L$0H3
PA__^
VWATAVAWH
@A_A^A\_^
\$ UVWH
UVWATAUAVAWH
D$HH;
L$PH;
A_A^A]A\_^]
UVWAVAWH
pA_A^_^]
VWAVH
)|$PD
)D$@H
L$0H3
(|$PD
(D$@H
pA^_^
\$ WAVAWH
)t$@L+
L$0H3
PA_A^_
\$ WAVAWH
)t$@L+
L$0H3
PA_A^_
@SVATH
T$0L;
l$`Hc
)t$@H
L$8H3
pA\^[
|$ AVH
L$0H3
\$ WAVAWH
)t$@L+
L$0H3
PA_A^_
UVWATAUAVAWH
H;8uiH
A_A^A]A\_^]
t$ UWAVH
@SUVWAVH
0A^_^][
t$ UWAVH
(D$ f
(D$0f
(D$0f
(D$Pf
zRuPI
(D$ I
(D$0H
@USVWATAUAVAWH
B H9A
A_A^A]A\_^[]
L$(H3
L$(H3
L$(H3
L$(H3
@SVWH
\$ UVWAVAWH
t$0H;
PA_A^_^]
@USVWATAUAVAWH
L$xH;M
A_A^A]A\_^[]
\$ UVWATAUAVAWH
(L$`f
A_A^A]A\_^]
\$ UVWATAUAVAWH
(D$@f
T$@I;
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
L$@H;
L$@H;
A_A^A]A\_^[]
r1w/H
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
(D$@f
D$0I;V
A_A^A]A\_^[]
UVWATAUAVAWH
(D$@f
)D$@L
t$ E3
A_A^A]A\_^]
@SUVWAVH
sHL;sPu
H9D$Ht
L$XH3
`A^_^][
USVWATAUAVAWH
hA_A^A]A\_^[]
WAVAWH
 A_A^_
WAVAWH
 A_A^_
USVWATAUAVAWH
MHH;Mh
A_A^A]A\_^[]
@USVWATAUAVAWH
(D$0f
(D$@f
A_A^A]A\_^[]
(D$ H
(D$0f
@USVWATAUAVAWH
A_A^A]A\_^[]
CPUExecuH9
tionProvH9P
ideru
UVWATAUAVAWH
)D$@H
A_A^A]A\_^]
)D$@L
UVWATAUAVAWH
d$@E3
t$(I;~Pt
t=8D$ t
E9}(u
|$P;G
t$0I;
A_A^A]A\_^]
l$ VWAVH
0A^_^
@USVWATAUAVAWH
D$HL;
L;d$H
A_A^A]A\_^[]
(D$0H
(D$@H
(D$ M
(D$0I
(D$0L
(D$ H
WAVAWH
 A_A^_
USVWATAUAVAWH
A_A^A]A\_^[]
|$ ATAVAWH
 A_A^A\
@USVWATAUAVAWH
t$`L;
A_A^A]A\_^[]
UWAVH
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
(D$ f
l$ VWAVH
 A^_^
UVWATAUAVAWH
H9\$p
H9\$`
H;D$`
|$ E3
|$ E3
D$hH;0tK
A_A^A]A\_^]
UWAVH
(D$@f
(D$Pf
(D$Pf
(D$0f
t$ WATAUAVAWH
A_A^A]A\_
UVWATAUAVAWH
(D$pf
(D$pf
A_A^A]A\_^]
x UATAUAVAWH
A_A^A]A\]
@UVATAVAWH
T$ I;
@A_A^A\^]
9Yielu
tfD9P(u
l$ VWAVH
0A^_^
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$pH+
A_A^A]A\_^[]
WATAUAVAWH
)D$ f
0A_A^A]A\_
t$8H+
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
)D$ f
)L$0f
)D$ f
@SUVWAVH
0A^_^][
UVWAVAWH
pA_A^_^]
t$ WATAUAVAWH
)D$ f
0A_A^A]A\_
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
t$ WATAUAVAWH
A_A^A]A\_
\$ UVWATAUAVAWH
d$PE3
\$ E3
(D$ f
pA_A^A]A\_^]
\$ UVWATAUAVAWH
)t$pL
)D$@H
)|$`H
(|$`H
A_A^A]A\_^]
S H+S
@8,:|
t$ WATAUAVAWH
(D$0H
(t$PL
(|$@I
A_A^A]A\_
@USVWATAUAVAWH
|$xI;
\$pE3
A_A^A]A\_^[]
@SUVWATAVAWH
A_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWAVH
A^_^[]
@USVWATAVAWH
(D$@f
(D$Pf
(D$Pf
(D$@f
A_A^A\_^[]
VWAVH
 A^_^
x UATAUAVAWH
(D$0f
A_A^A]A\]
@USVWATAUAVAWH
(D$@f
(D$@f
|$XH;
A_A^A]A\_^[]
t$ WAVAWH
A_A^_
t$ WATAUAVAWH
A_A^A]A\_
@SUAUAVAWH
@A_A^A]][
@SVWH
t$ WAVAWH
\$ I;
@A_A^_
\$ UVWATAUAVAWH
)t$pH
(|$`H
A_A^A]A\_^]
@USVWATAUAVAWH
D$AE2
D$EE3
0D$CI
|$AD2
t$BD2
t$@@2
A_A^A]A\_^[]
@SVWAVH
D$(L+
T$0H+
L$8H3
HA^_^[
t$ WATAUAVAWH
D$8H;
A_A^A]A\_
@USVWATAUAVAWH
|$@L;
A_A^A]A\_^[]
X UVWATAUAVAWH
A_A^A]A\_^]
VWATAVAWH
0A_A^A\_^
@SVWH
@SVWH
t$ WAVAWH
\$ I;
@A_A^_
\$ UVWATAUAVAWH
)t$PH
D$ L#
(|$@H
`A_A^A]A\_^]
\$ UVWATAUAVAWH
)t$pH
(|$`H
A_A^A]A\_^]
t$ WH
@8,:|
|$0u5H
@USVWATAUAVAWH
|$pE3
D$HH;
H;t$HH
|$@E3
D$hE3
A_A^A]A\_^[]
UVWATAUAVAWH
SAME_UPPL9
ERt)H
SAME_LOWH9
L)|$(M
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
D$@H;
CT$@L
A_A^A]A\_^]
@SVWH
T$0D8D$8t
L$XH3
t$ UWATAVAWH
(D$@f
(L$`f
D$@H;
CT$@L
A_A^A\_]
UVWATAUAVAWH
(L$`f
D$`H;
CT$`L
A_A^A]A\_^]
l$ VWATAVAWH
)|$PH
L$@H3
(|$PI
A_A^A\_^
t$ WH
t$ WH
t$8H;
L$XH3
UWAVH
l$ VWATAVAWH
A_A^A\_^
UVWATAUAVAWH
(D$Pf
D$PH;
CT$PL
A_A^A]A\_^]
UVWATAUAVAWH
|$xL;
T$HH;
;H9D3(
9P(uUI
~LH;H t#
uA9P(u<H
|$xH;
D8d$0
L;d$x
M+<$I
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
H9E`t6L
A_A^A]A\_^]
UVWAVAWH
A_A^_^]
UVWATAUAVAWH
A_A^A]A\_^]
(D$Pf
D$PH;
CT$PL
(D$Pf
t$ UWATAVAWH
(D$@f
(L$`f
D$@H;
CT$@L
A_A^A\_]
@SWAUH
`A]_[
l$ WATAUAVAWH
0A_A^A]A\_
@USVWATAVAWH
D$hH;D$p
D$hH;D$p
D$hH;D$pu}
D$hH;D$pum
D$hH;D$puL
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
USVWATAVAWH
A_A^A\_^[]
VWAVH
L$8H3
@A^_^
UVWAVAWH
A_A^_^]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
|$ UH
@USVWATAUAVAWH
D$xH;
H;t$x
(t$pf
A_A^A]A\_^[]
|$ UH
@SVWH
@USVWAVH
A^_^[]
@SVWH
@USVWATAUAVAWH
\$@E3
\$@E3
_q_to_dqJ
\$@E3
|$`H;
(D$Pf
L$8E3
|$ E3
t,HcW H
D$ E3
A_A^A]A\_^[]
@USVWATAUAVAWH
L$@L;
L;|$@
A_A^A]A\_^[]
@USVWATAUAVAWH
L$@L;
L;|$@
A_A^A]A\_^[]
@USVWATAUAVAWH
L$hH;L$x
A_A^A]A\_^[]
UVWAVAWH
D$xH;
D$xH;
A_A^_^]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
r3Hc>H
s HcD$ H
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
(D$pf
D$0E2
t$@L;
C\$@H
D$PH+
uKH;Q
A_A^A]A\_^]
UAVAWH
A_A^]
@UVWAVAWH
\$hL;
 A_A^_^]
 A_A^_^]
@SUVWAVH
 A^_^][
 A^_^][
@SUVWAVH
 A^_^][
 A^_^][
@SUVWAVH
 A^_^][
 A^_^][
 A^_^][
@SUVWAVH
 A^_^][
 A^_^][
@SUVWAVH
 A^_^][
 A^_^][
 A^_^][
@USVWATAUAVAWH
D$PL;
tyfff
L;l$PtNH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
(D$@f
(D$`f
(D$@f
A_A^A]A\_^]
@USVWATAUAVAWH
)D$PH
(D$Pf
(D$Pf
(D$Pf
t$ E3
A_A^A]A\_^[]
@USVWATAVAWH
(D$@f
A_A^A\_^[]
@USVWATAUAVAWH
(D$@f
A_A^A]A\_^[]
@USVWATAVAWH
(D$@f
A_A^A\_^[]
WAVAWH
 A_A^_
@USVWATAUAVAWH
D$`E3
A_A^A]A\_^[]
@SWAVH
 A^_[
 A^_[
t$0ux
WAVAWH
 A_A^_
\$ UVWH
T$xH;U
T$xH;U
UVWATAUAVAWH
(D$ f
A_A^A]A\_^]
@USVWATAUAVAWH
L$HE3
L$XE3
D$@L;
L;t$@H
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWAVH
A^_^[]
(D$ f
(D$ f
(D$ f
(D$ H
x UATAUAVAWH
(D$@f
D$@E3
(D$@f
(D$@f
(D$@f
(D$@f
(D$@f
D$@E3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
8E?ubH
x UAVAWH
(D$ f
)D$ f
(D$ f
A_A^]
(D$0f
T$HH+T$@H
L$`H3
|$ UAVAWH
A_A^]
x UATAUAVAWH
\$ H;U
A_A^A]A\]
x UAVAWH
(L$@f
T$PH+
A_A^]
|$ UH
UWAVH
T$@H+
D$HH;
D$HH;
L$PH3
t$ WH
(D$ f
D$ E3
D$8H+
T$@H+
D$8H+
(D$ f
L$HH3
\$ UVWATAUAVAWH
UUUUUUU
d$8E3
n fff
(D$ f
PA_A^A]A\_^]
UVWATAUAVAWH
)t$`I
fffffff
)D$ H
)D$ f
|$@E3
\$0E3
(D$0f
fffffff
(t$`H
pA_A^A]A\_^]
S H+S
UVWAVAWH
 A_A^_^]
@SUVWAVAWH
T$@H+
L$HH3
XA_A^_^][
@SUVWAVAWH
T$@H+
L$HH3
XA_A^_^][
@USVWATAVAWH
pA_A^A\_^[]
WAVAWH
0A_A^_
t$ WH
)D$@L
T$0H+
L$XH3
T$8H+
t$ WH
L$@H3
WAVAWH
0A_A^_
l$ VWAVH
T$8H+
L$@H3
l$ VWAVH
T$8H+
L$@H3
@SUVWAVH
)D$ L
T$@H+
L$HH3
PA^_^][
t$ UWAVH
)D$ L
T$@L;
D$HI+
L$XH3
|$ UATAUAVAWH
t$ E3
A_A^A]A\]
(D$ f
T$@E3
L$PH3
@USVWAVH
A^_^[]
VWAVH
t$ WH
(D$0H
(D$0f
D$0xVH;
(D$ O
L$@H3
@SVWH
L$ E3
D$@H+
T$XH+
L$`H3
t$ AVH
D$ H+
L$HH3
SUVWAVH
(D$Pf
)L$`H
)D$`L
A^_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAVAWH
(D$@f
(D$@f
A_A^A\_^[]
(D$0H
(D$@f
L$HH3
@USVWATAUAVAWH
A_A^A]A\_^[]
@USWH
L$h@8}
UVWATAUAVAWH
(|$@f
D$0L;
H#EpH
L;l$0
|$PE2
(D$0f
(L$@f
|$xH;_
(D$0f
A_A^A]A\_^]
@USVWATAUAVAWH
)D$0H
)D$0H
A_A^A]A\_^[]
USVWATAVAWH
T$PH+
D$PH+
(L$@f
T$PH+
(D$@f
D$@E3
A_A^A\_^[]
@USVWATAUAVAWH
(D$0f
(L$@f
(D$@f
(L$0f
D$0H;
)t$@H
H;\$0t
t$xE3
A_A^A]A\_^[]
@USVWAVH
pA^_^[]
UWATAVAWH
A_A^A\_]
UVWATAUAVAWH
t$0L;
\$@H+
)D$ 3
)D$ f
)D$ L
T$PH+
L$XH3
`A_A^A]A\_^]
l$ VWAVH
T$HI+
L$XH3
t$ UWATAVAWH
A_A^A\_]
@SUVWAVAWH
)L$PH
L$`H+
T$pH+
L$xH3
A_A^_^][
UVWAVAWH
`A_A^_^]
\$ UVWH
T$8H+
L$@H3
USVWATAUAVAWH
T$pH+
D$pH+
D$pH+
T$pH+
t$0fD
t$0fD
(L$0f
T$pH+
)D$0L
T$pH+
T$@H+
t$0fD
T$pH+
)D$0L
T$pH+
t$0fD
A_A^A]A\_^[]
@SUVWAVH
T$@H+
L$HH3
PA^_^][
@USVWAVAWH
)t$pH
(t$pH
A_A^_^[]
@SUVWAVH
T$@H+
T$hH+
L$pH3
A^_^][
USVWATAUAVAWH
(D$0f
(D$0f
(D$0f
(D$0f
)D$@H
)D$@H
)D$@L
(D$0f
(D$0f
(D$0f
A_A^A]A\_^[]
@USVWATAVAWH
A_A^A\_^[]
VAVAWH
 A_A^^
@SUVWATAVAWH
D$@H+
T$XH+
`A_A^A\_^][
I#F0M
)L$Pf
)D$0f
)D$0L
)D$Pf
t$ UWAVH
T$HH+
T$HH+
l$ VWAVH
D$PH;W
 A^_^
USVWATAUAVAWH
L$0E2
T$8E3
M+,$I
A_A^A]A\_^[]
UVWATAUAVAWH
D$@L;
L;|$@
L;|$@
L;|$@
A_A^A]A\_^]
@USVWATAUAVAWH
L$0M;
\$pI;
A_A^A]A\_^[]
UVWATAUAVAWH
t$ E3
t$ E3
A_A^A]A\_^]
UVWATAUAVAWH
D$HL;
L;|$H
L;|$H
L;|$H
A_A^A]A\_^]
@SUVWAVH
D9H,tcH
D$@Mc@
D$0L;
|$8L;
L$@I+
L$HH3
PA^_^][
t$ WATAUAVAWH
A_A^A]A\_
@SUVWATAUAVAWH
HA_A^A]A\_^][
VWAWH
(t$@L
(|$0H
pA__^
pA__^
@USVWATAUAVAWH
D$XE3
A_A^A]A\_^[]
@SUVWH
(D$ f
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
k VWAVH
L$hH3
UVWAVAWH
t$`E3
 A_A^_^]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
t$ WATAUAVAWH
A_A^A]A\_
@SUVWATAUAVAWH
(D$ f
XA_A^A]A\_^][
p WATAUAVAWH
(D$0f
A_A^A]A\_
(D$ f
(t$@H
t$8H+
@USVWATAUAVAWH
D$PE3
A_A^A]A\_^[]
@USVWATAUAVAWH
D$pE3
L;|$p
A_A^A]A\_^[]
\$ UVWATAUAVAWH
L$`H3
pA_A^A]A\_^]
@USVWATAUAVAWH
)D$PH
A_A^A]A\_^[]
UVWATAUAVAWH
(D$ f
H;D$0
A_A^A]A\_^]
@USVWATAUAVAWH
S H+S
I#EpH
H;|$8t
EXM#upM
M;EHu
H;D$0L
A_A^A]A\_^[]
@SAUH
|$0fff
I#E0H
t$ WH
@SUVWAVH
A^_^][
\$ UVWH
H;|$p|
|$ AVH
N H;H u
@SUVWAVH
PA^_^][
PA^_^][
PA^_^][
VWATAVAWH
 A_A^A\_^
D$xH;
l$ VH
D$@H9
L$PH3
UVWAVAWH
A_A^_^]
(D$ H
(D$0I
(D$ H
(D$0I
t$ WH
t$ WATAUAVAWH
|$(Ik
>HkL$0
A_A^A]A\_
L$8I+
L$hH3
L$XI+
|$ UAVAWH
D$ E3
A_A^]
@USVWAVAWH
A_A^_^[]
@SUVWATAUAVAWH
L$PH3
hA_A^A]A\_^][
\$ UVWH
L$pH3
L$8I+
L$hH3
L$8I+
L$hH3
SxH+SpH
|$ UH
UVWATAUAVAWH
A_A^A]A\_^]
t$ WH
L$hH3
L$hH3
VWATAVAWH
\$ I;
@A_A^A\_^
WAVAWH
;p uN
@A_A^_
T$ H;
@SVWH
T$@H;
UVWATAUAVAWH
`A_A^A]A\_^]
|$ ATAVAWH
tj9h ueH
X ;k 
@A_A^A\
X ;{ H
x AVH
;h u=H
p ;n 
UVWAVAWH
A_A^_^]
@USVWAVH
A^_^[]
(D$ f
D$ H;
@USVWAVAWH
D$8H+
A_A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
(D$`f
A_A^A]A\_^[]
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
UVWATAUAVAWH
M;F u
E0H#D$0H
(D$ f
E0H#D$0H
@A_A^A]A\_^]
@SVWH
L$0H3
UVWATAUAVAWH
L$pL;
L$pL;
T$pH;
T$pH;
A_A^A]A\_^]
@SVWH
D$@H+
|$PH;
L$XH+
gfffffffH
\$ UVWATAUAVAWH
A_A^A]A\_^]
VWAVH
L$`H3
pA^_^
@USVWAVH
T$`E3
A^_^[]
@USVWATAUAVAWH
|$ E3
A_A^A]A\_^[]
H#E0L
@SVWATAUAVAWH
D$0E3
D$0E3
PA_A^A]A\_^[
L$0H3
t$ WH
t$ WH
L$8H3
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
|$ UH
@SVWH
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
@SUVWAVH
t$0H;
L$`H3
pA^_^][
@SUVWAVH
t$0H;
L$`H3
pA^_^][
VWAWH
l$hH+
 A__^
|$ AVH
|$(A^
|$ AVH
|$(A^
VWAWH
l$hH+
 A__^
|$ AVH
|$(A^
|$ AVH
|$(A^
UWAVH
)D$0H
UWAVH
)D$0H
UWAVH
)D$0H
UWAVH
)D$0H
t$ WH
UVWATAUAVAWH
 A_A^A]A\_^]
@SUVWAVH
L$@H3
PA^_^][
t$ UWAVH
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
D$4E3
@USVWATAVAWH
A_A^A\_^[]
UWATAVAWH
)D$0H
A_A^A\_]
UVWATAUAVAWH
)D$0H
A_A^A]A\_^]
UVWATAUAVAWH
)D$0H
A_A^A]A\_^]
@SVWH
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
T$ M;
@SUVWAUAVAWH
D$HE3
PA_A^A]_^][
PA_A^A]_^][
PA_A^A]_^][
PA_A^A]_^][
PA_A^A]_^][
@SUVWAUAVAWH
D$HE3
PA_A^A]_^][
PA_A^A]_^][
PA_A^A]_^][
PA_A^A]_^][
PA_A^A]_^][
@USWH
@USVWAUAVAWH
A_A^A]_^[]
UWAVH
UWAVH
USVWH
D$@I;
T$pH;
USVWH
T$pH;
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
VWAVH
[ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
~ I+~
E I+E
A_A^A]A\_^[]
\$0A+
\$0A+
UVWATAUAVAWH
t$@E3
D$0L;
d$ L;
L$PH3
`A_A^A]A\_^]
@SUVWAVH
L$HH3
PA^_^][
@USVWATAVAWH
@ H+A
N H+N
A_A^A\_^[]
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
UWAVH
UWAVH
D$0H+
D$HH+
t$ WH
t$ WH
UVWAVAWH
A_A^_^]
UVWAVAWH
T$II+
A_A^_^]
UVWAVAWH
T$II+
A_A^_^]
USVWAVH
A^_^[]
UVWAVAWH
D$pH+
A_A^_^]
UVWAVAWH
D$pH+
A_A^_^]
t$ UWATAVAWH
A_A^A\_]
t$ WH
L$XH3
WAVAWH
(t$PL
(|$@I
A_A^_
|$ ATAVAWH
r$H9y
(|$ H
(t$0H
@A_A^A\
WAVAWH
(|$0D
(D$ H
PA_A^_
WAVAWH
A_A^_
l$ WH
l$ WH
l$ WH
l$ WH
l$ WH
l$ WH
L$(H3
x ATAVAWH
(\$PD
(t$ L
A_A^A\
t$ WH
L$LH+
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
pA_A^A]A\_^]
@SUVWAUAVAWH
PA_A^A]_^][
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
|$ AVH
\$@ff
(%A25
(5J15
(=[15
)T$pD
)\$`D
)d$PD
)l$@D
(-q15
)t$0D
(5305
)|$ D
(=U05
(|$ D
(t$0D
(l$@D
(d$PD
(\$`D
(T$pD
A H9A
A H9A
u`H9A
A H9A
A H9A
UWAVH
D$0H+
D$HH+
D$`H+
D$xH+
|$ UH
D$HH;L$Ht
WAVAWH
L$XH3
A_A^_
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
M;A M
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
SUVWAVH
t$0H;
L$`H3
pA^_^][
D$ H;
CT$ L
L$hH3
D$ H;
CT$ L
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
@SUVWH
H_^][
l$(H+
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
S H+S
\$ UVWATAUAVAWH
L9L$0
K0L9L$PuYH
D$@L;
A_A^A]A\_^]
SVWAVH
A^_^[
)t$ I
(t$ H
)t$ I
(t$ H
)t$ I
(t$ H
)t$ M
(t$ H
)t$ I
(t$ H
D$1H+
)t$ M
(t$ H
)t$ M
(t$ H
)t$ I
(t$ H
)t$ I
z)u'H;
z.u,H;
(t$ H
)t$ M
(t$ H
t\fff
)t$ M
(t$ H
)t$ I
z(u&H;
z-u+H;
(t$ H
UVWAVAWH
A_A^_^]
D$1H+
)t$ M
(t$ H
)t$ M
(t$ H
)t$ M
(t$ H
)t$ I
.5?53
(t$ H
|$0H9
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
L$@H3
\$ WH
L$@H3
\$ WH
L$@H3
A u^H9A
A H9A
A H9A
VWAVH
 A^_^
t$ WH
t$8H;
L$XH3
@USVWATAVAWH
d$ E3
A_A^A\_^[]
UVWATAUAVAWH
D;|$0ujH
|$4D;|$8
A_A^A]A\_^]
t$ UWATAVAWH
D$0E3
D$PH+
(D$Pf
D$@H+
d$ E3
A_A^A\_]
(5pP3
)D$0D
)L$ D
(L$ D
(t$PL
(=v'3
)T$pD
)\$`D
)d$PD
)l$@D
)t$0D
(5.N3
)|$ D
(=@N3
(|$ D
(t$0D
(l$@D
(d$PD
(\$`D
(T$pD
l$ WH
L$XH3
\$ UVWATAUAVAWH
I+4$H
A_A^A]A\_^]
tcfff
D$HH;
t$DE3
t$ WH
L$XH3
t$ WH
L$XH3
|$ ATAVAWH
@A_A^A\
|$ ATAVAWH
@A_A^A\
WATAUAVAWH
@A_A^A]A\_
WATAUAVAWH
@A_A^A]A\_
@USVWATAUAVAWH
tcfff
D$PH;
(D$Pf
A_A^A]A\_^[]
@USVWATAUAVAWH
tcfff
D$PH;
(D$Pf
A_A^A]A\_^[]
UVWATAUAVAWH
t$@E3
D$0L;
d$ L;
L$PH3
`A_A^A]A\_^]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
SUVWAVH
t$0H;
L$`H3
pA^_^][
t$ WH
UVWATAUAVAWH
A_A^A]A\_^]
X UVWATAUAVAWH
A_A^A]A\_^]
@USVWAVH
A^_^[]
UVWATAUAVAWH
A_A^A]A\_^]
t$ E3
VWAVH
 A^_^
@USWH
UVWATAUAVAWH
t$@E3
D$0L;
d$ L;
L$PH3
`A_A^A]A\_^]
|$ UH
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
H H+H
T$0H;
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
USVWATAUAVAWH
hA_A^A]A\_^[]
@USVWAVH
PA^_^[]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
t$ WH
UVWATAUAVAWH
A_A^A]A\_^]
l$ VWAVH
L$hE3
L$xL;
L$xL;
|$hL;|$p
D$xM;
$$L;g8
|$hL;|$p
D$(H+p
d$8L;
D$(H+p
d$8L;
|$0I;
\$ L;
|$(M;zH
\$ L+
JPH+h
|$(I;
|$ M;zH
D8I1A
\$ WH
L$8H3
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWAVAWH
A_A^_^]
@UATH
M9A8~yff
M;A8|
@UATH
M9A8~yff
M;A8|
|$ AVM
I9Q8~{
I;Q8|
|$(A^
@VAWH
d$8E3
I;Y8|
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
UVWAVAWH
(D$Pf
A_A^_^]
@USVWATAUAVAWH
)D$ L
)D$ L
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$ L
)D$ L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
USVWATAUAVAWH
)D$0L
)D$0L
T$0H;
A_A^A]A\_^[]
t$ WH
VWAVH
 A^_^
t$ WH
VWAVH
 A^_^
t$ WH
VWAVH
 A^_^
t$ WH
VWAVH
 A^_^
t$ WH
VWAVH
 A^_^
t$ WH
VWAVH
 A^_^
UWAVH
L$xH3
SUAWH
UWAVH
L$xH3
SUAWH
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
SATAWH
A_A\[
L$xH3
SATAWH
A_A\[
L$xH3
SATAWH
A_A\[
UVWATAUAVAWH
)|$PH
(|$PH
pA_A^A]A\_^]
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
t$ WH
(D$0f
}'fff
}'fff
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
l$0M;
l$0M;
\$ UVWATAUAVAWH
D$`H+
D$hH+
A_A^A]A\_^]
\$ UVWAVAWH
A_A^_^]
@UVAVH
 A^^]
SVAUH
L$hL;
L;l$`
0A]^[
SVAVAWH
\$hL;\$p
8A_A^^[
VATAUAWH
L;|$P
A_A]A\^
VATAUAWH
L;|$P
A_A]A\^
SWATAUH
L;d$P
A]A\_[
SWATAUH
L;d$P
A]A\_[
SVAVAWH
\$hL;\$p
8A_A^^[
l$ ATAUAVAWL
l$@A_A^A]A\
SWATAUH
L;d$P
A]A\_[
l$ ATAUAVAWL
l$@A_A^A]A\
SUAWH
L$hL;L$p
@A_][
l$ ATAUAVAWL
l$@A_A^A]A\
l$ ATAUAVAWL
l$@A_A^A]A\
SWATAUH
L;d$P
A]A\_[
SUAWH
L$hL;L$p
@A_][
UVAVH
t$0M;
T$8L;
SVAUH
L$hL;
L;l$`
0A]^[
SUAWH
L$hL;L$p
@A_][
SUAWH
L$hL;L$p
@A_][
UVAWH
l$ M;
)|$`D
)D$Pf
L$@L;
(t$pL
UVAWH
l$ M;
)|$`D
)D$Pf
L$@L;
(t$pL
SVAUH
L$hL;
L;l$`
0A]^[
SVAUH
L$hL;
L;l$`
0A]^[
\$ UVWH
|$ UAVAWH
D$ E3
A_A^]
|$ UAVAWH
D$ E3
A_A^]
|$ UAVAWH
D$ E3
A_A^]
|$ UAVAWH
D$ E3
A_A^]
|$ UAVAWH
D$ E3
A_A^]
|$ UAVAWH
D$ E3
A_A^]
UVWATAUAVAWH
A_A^A]A\_^]
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
T$@H;
t$ AWH
T$PH;
t$ AWH
T$PH;
WAVAWH
T$PH;
A_A^_
WAVAWH
T$PH;
A_A^_
WAVAWH
T$PH;
A_A^_
WAVAWH
T$PH;
A_A^_
WAVAWH
T$PH;
A_A^_
WAVAWH
T$PH;
A_A^_
WAVAWH
T$PH;
A_A^_
WAVAWH
T$PH;
A_A^_
@USVWATAUAVAWH
D$XH+
A_A^A]A\_^[]
@USVWATAUAVAWH
D$XH+
A_A^A]A\_^[]
@USVWATAUAVAWH
D$XH+
A_A^A]A\_^[]
@USVWATAUAVAWH
D$XH+
A_A^A]A\_^[]
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
|$ AVH
T$@H;
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
@SUVWH
\$ UVWATAUAVAWH
A_A^A]A\_^]
USVWATAUAVAWH
D$@E3
D8d$@H
D$XtCH
t$AD8
t$XH;t$`t1L
D$`L+D$XI
A_A^A]A\_^[]
A H+A
@SVAVH
|$xfff
@A^^[
2H;y 
|$ A^
t$ ATAVAWH
|$ ff
t$8A_A^A\
L;Y }Hf
M;Y |
@SVAVH
|$xfff
~Ufff
@A^^[
L;A }If
M;A |
L;Y }Hf
M;Y |
t$ ATAVAWH
|$ ff
t$8A_A^A\
*H;y 
H;{ |
@SVAVH
|$xfff
@A^^[
L;I }PL+
M;J |
*H;y 
H;{ |
L;A }Gf
M;A |
2H;q 
t$ A^
WATAUAVAWH
\$8A_A^A]A\_
2H;y 
|$ A^
WATAUAVAWH
\$8A_A^A]A\_
t$ ATAVAWH
|$ ff
t$8A_A^A\
UWATAUAWH
\$8A_A]A\_]
@SVAVH
|$xfff
~Ufff
@A^^[
L;A }If
M;A |
*H;y 
H;{ |
t$ ATAVAWH
|$ ff
t$8A_A^A\
L;A }Gf
M;A |
@SVAVH
|$xfff
@A^^[
2H;q 
t$ A^
\$ WH
l$Xff
VWATAVAWH
0A_A^A\_^
t$ WH
oD$0L
t$ WH
oD$0L
@SUVWAVAWH
T$@H;
A_A^_^][
@SUVWAVAWH
D$(E3
T$@H;
A_A^_^][
|$ UH
@SUVWAVAWH
A_A^_^][
\$ UVWATAUAVAWH
D$pL+
A_A^A]A\_^]
@SUVWAVH
T$8H+
L$@H3
PA^_^][
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@SUVWATAVAWH
L$pE3
T$0H;
L$xH3
A_A^A\_^][
@SUVWATAVAWH
L$pE3
T$0H;
L$xH3
A_A^A\_^][
@SVWH
AUAWH
T$`E;
HA_A]
t$ WH
t$ WH
UVWATAUAVAWH
t+LcN
 A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
D$0Lc
D$@Lc
D$PLc
D$`Lc
X UVWATAUAVAWH
D8n,tEH
D8n t
t(HcF
)E@Ic
8^,t3HcN
)E@LcF
A_A^A]A\_^]
@SVWH
\$ WH
gfffffffH+
t$ WH
|$ UH
@SVWATAUAVAWH
D$0E3
D$0E3
PA_A^A]A\_^[
t$ WH
UVWATAUAVAWH
L$xE3
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SUVWATAVAWH
S H;S(H
L$@H3
PA_A^A\_^][
@SUVWATAUAVAWH
A_A^A]A\_^][
UWAVH
UWAVH
@SVWH
@SVWH
@SVWH
@SVWH
@USVWH
@SVWH
@USWH
SUVWH
@SUVWH
@SVWH
@USWH
@USWH
l$ VWAVH
l$ VWAVH
L$(H3
@UVWH
l$huNI
@UVWH
@UVWH
@UVWH
@SUVH
@SUVH
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAVAWH
fC9tE
A_A^A\_^[]
@USVWATAVAWH
fC9tE
A_A^A\_^[]
@USVWATAVAWH
A_A^A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
\$8E3
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
\$ I;
\$ I;
\$ I;
\$ I;
\$ I;
L$pH3
L$pH3
L$pH3
L$pH3
L$pH3
L$pH3
L$pH3
\$ I;
\$ I;
\$ I;
\$ I;
)t$0H
L$(H3
(t$0H
UWAVH
WAVAWH
0A_A^_
@USVWAVH
A^_^[]
t$ WH
L$ H;
>"t(H
L$(H3
\$ UVWH
L$ H;
>"t%H
L$(H3
\$ UVWH
L$ H;
>"t%H
L$(H3
|$ AVH
@USVWAVH
A^_^[]
D$HH;D$Ht&
WAVAWH
L$XH3
A_A^_
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
T$pH;
A_A^A\_^[]
@USVWATAVAWH
T$pH;
A_A^A\_^[]
@USVWATAVAWH
T$pH;
A_A^A\_^[]
\$ UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
@USVWATAVAWH
T$pH;
A_A^A\_^[]
t$ WH
UVWAVAWH
A_A^_^]
VWAVH
 A^_^
@SUVWATAVAWH
}7fff
A_A^A\_^][
@SUVWATAVAWH
A_A^A\_^][
@SUVWATAVAWH
A_A^A\_^][
l$ VWATAVAWH
A_A^A\_^
|$ UATAUAVAWH
H;T$@uzM
A_A^A]A\]
|$ UATAUAVAWH
H;T$@uzM
A_A^A]A\]
|$ UATAUAVAWH
H;T$@uzM
A_A^A]A\]
@SUVWATAVAWH
A_A^A\_^][
|$ UATAUAVAWH
H;T$@uzM
A_A^A]A\]
|$ UATAUAVAWH
H;T$@uzM
A_A^A]A\]
@USVWATAVAWH
Lc2E3
A_A^A\_^[]
UVWATAUAVAWH
T$HE3
D$HE3
L;d$H
A_A^A]A\_^]
USVWATAUAVAWH
A_A^A]A\_^[]
HXI9HX
t$ WH
|$8H;
L$XH3
VWATAVAWH
0A_A^A\_^
|$ UH
t$ WH
t$ WH
t$ WH
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
Et$PH
L$XH3
UVWATAUAVAWH
A_A^A]A\_^]
t$ UWAVH
UVWAVAWH
PA_A^_^]
@SUWATAVAWH
x H+x
HA_A^A\_][
L$(H3
L$(H3
L$(H3
UWAVH
D$0H+
UWAVH
D$0H+
UWAVH
D$0H+
|$ UH
@USVWATAVAWH
upfff
uxfff
0A_A^A\_^[]
@SUVWAVAWH
t$(H;
|$(H;
|$(H;
|$(H;
8A_A^_^][
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
L$(H3
L$(H3
@USVWATAUAVAWH
L$`E3
(t$`f
d$`H+
(D$Pf
(t$ f
d$`L+
(D$@f
A_A^A]A\_^[]
@USVWATAUAVAWH
L$`E3
(t$`f
d$`H+
(D$Pf
(t$ f
d$`L+
(D$@f
A_A^A]A\_^[]
@USVWATAUAVAWH
L$`E3
(t$`f
d$`H+
(D$Pf
(t$ f
d$`L+
(D$@f
A_A^A]A\_^[]
@USVWATAUAVAWH
L$`E3
(t$`f
d$`H+
(D$Pf
(t$ f
d$`L+
(D$@f
A_A^A]A\_^[]
@USVWATAUAVAWH
L$`E3
(t$`f
d$`H+
(D$Pf
(t$ f
d$`L+
(D$@f
A_A^A]A\_^[]
t$ WH
t$ WH
UVWATAUAVAWH
C(H+C H
C@H+C8H
A_A^A]A\_^]
@SUVWATAUAVAWH
t$XH;
H9t$8}
H+D$PH
A_A^A]A\_^][
UVWATAUAVAWH
A_A^A]A\_^]
l$ VWAVH
C0H9C(u
C0H9C(u
C0H9C(u
C0H9C(u
H9q0vb
C0H9C(u
@SUWAVAWH
 A_A^_][
@USVWATAUAVAWH
A_A^A]A\_^[]
@SWATAUAVAWH
8A_A^A]A\_[
8A_A^A]A\_[
\$ UVWATAUAVAWH
A_A^A]A\_^]
L$@H3
L$@H3
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UWAVH
D$0H+
D$HH+
D$`H+
UWAVH
D$0H+
D$HH+
D$`H+
@USVWATAUAVAWH
Hct$P
A_A^A]A\_^[]
@USVWATAUAVAWH
Hct$P
A_A^A]A\_^[]
@USVWATAUAVAWH
Hct$P
A_A^A]A\_^[]
@USVWATAUAVAWH
Hct$P
A_A^A]A\_^[]
@USVWATAUAVAWH
Hct$P
A_A^A]A\_^[]
@USVWATAUAVAWH
Lcl$Pf
L;t$h
A_A^A]A\_^[]
t$8Hc
|$(Mc
t$8Hc
|$(Hc
@SVWATH
D$ D;
XA\_^[
l$PHc
XA\_^[
t$8Hc
|$(Hc
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
t$ WH
UVWAVAWH
L$XE3
A_A^_^]
@USVWAVH
T$@E3
A^_^[]
@USVWATAUAVAWH
Lct$h3
D$xL;
D$pH+
HcL$hH;
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SUVWAVAWH
(A_A^_^][
(A_A^_^][
t$ WH
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
A_A^A\_^[]
t$ WH
|$ UH
t$ WH
UVWATAUAVAWH
T$HE3
F L+F
A_A^A]A\_^]
@SUWAUAVAWH
l$ fff
XA_A^A]_][
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
ATAUAWH
t$ fff
0A_A]A\
ATAUAWH
t$ fff
0A_A]A\
ATAUAWH
t$ fff
0A_A]A\
H;t$p
H;t$p
H;t$p
H;t$p
ATAUAWH
t$ fff
0A_A]A\
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
w+fff
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
T$`H+
(D$`f
A_A^A]A\_^]
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
w+fff
UVWATAUAVAWH
D$`I+
(D$`f
A_A^A]A\_^]
@SVWATAUAVAWH
T$HM+
t#fff
L$pH3
A_A^A]A\_^[
UWAVH
T$`H;
D$8H+
D$PH+
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
t$ WH
|$ UH
\$ UVWAVAWH
L$`H3
pA_A^_^]
@USVWAVH
@ H+A
A^_^[]
|$ UH
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
@SVWATAUAVAWH
tofff
|$0I;
PA_A^A]A\_^[
SVWATAUAVAWH
|$ Mi
0A_A^A]A\_^[
@SVWATAUAVAWH
t$0Mi
t$ I;
`A_A^A]A\_^[
@SUVWAVH
@A^_^][
UVWAVAWH
0A_A^_^]
gfffffffH
fffffff
|$8H+
t$8H+
t$8H+
t$@H+
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
\$0E9`
A_A^A\_^[]
\$ UVWATAUAVAWH
EXH;E`t
EXH;E`t
A_A^A]A\_^]
t$ UWATAVAWH
T$`H;
T$`H;
A_A^A\_]
t$ UWAVH
UVWATAUAVAWH
A_A^A]A\_^]
@SUVWATAVAWH
A_A^A\_^][
UVWATAUAVAWH
T$HE3
U I+U
t$@E3
A_A^A]A\_^]
UVWAVAWH
P H+P
A_A^_^]
@SUVWATAVAWH
A_A^A\_^][
l$ WAVAWH
t$HH+
 A_A^_
l$ WAVAWH
t$HH+
 A_A^_
t$ WATAUAVAWH
|$HI;
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
\$ WH
D$ L;
T$ H;
L$`H3
L$0I;
L$0I;
L$ H3
(D$ f
L$hH3
L$hH3
L$pH3
L$xH3
L$xH3
L$xH3
l$ VH
T$ H;
T$ H;
T$`H;
T$`H;
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
VWATAVAWH
\$ H;
D$HH;
A_A^A\_^
VWATAVAWH
d$ H;
D$HH;
A_A^A\_^
UAVAWH
J0L9rPH
A_A^]
VWATAVAWH
L$1B8
A_A^A\_^
VWATAVAWH
D$dfff
A_A^A\_^
VWATAVAWH
L$1B8
A_A^A\_^
s WAVAWH
D$IL+
A_A^_
D$ H;
D$ H;
L$ H;
CT$ H
UAVAWH
J0L9rPH
A_A^]
UAVAWH
J0L9rPH
A_A^]
t$ UH
T$HA8
L$`H3
L$`H3
UAVAWH
J0L9rPH
A_A^]
VWATAVAWH
A_A^A\_^
D$PA8
L$pH3
L$pH3
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ WH
t$ E3
@USVWATAUAVAWH
\$ E3
A_A^A]A\_^[]
t$ UH
t$ UH
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
t$ WH
t$ WH
t$ UWAVH
UWATAVAWH
A_A^A\_]
\$ UVWATAUAVAWH
I9upt
E\$pH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
T$@H;
T$@H;
p AWH
(t$`H
p AWH
(t$`H
@SUVWATAUAVAWH
hA_A^A]A\_^][
\$ UVWAVAWH
S H;S(t
L$@H3
PA_A^_^]
|$ UH
|$ UH
@USVWATAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A\_^[]
t$ WH
t$ WH
t$ WH
UVWAVAWH
pA_A^_^]
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
H9C`u
E I+E
d$pM;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
(D$@f
(D$@f
|$8I;
(D$@f
F(I+F H
A_A^A]A\_^[]
t$ WAVAWH
WhL;O
0A_A^_
\$ UVWAVAWH
L9yxA
S H;S(t
L$@H3
PA_A^_^]
@SUVWH
8_^][
t$xE3
H;T$`|
8_^][
\$ UVWH
VWAVH
PA^_^
VWAVH
PA^_^
VWAVH
PA^_^
@SUVWATAVAWH
`A_A^A\_^][
@SUVWATAVAWH
`A_A^A\_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
UWAVH
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
H9Chu
Dt$PH
f M+f
3333333
\$HE3
\$HE3
gfffffffH
A_A^A]A\_^]
\$ UVWATAUAVAWH
W H+W
W I;W(t
A_A^A]A\_^]
t$ AWH
gfffffffH+
UWAVH
t$ WH
\$ UVWATAUAVAWH
A_A^A]A\_^]
N L+N
L$(H3
L$(H3
UWAVH
UWAVH
UWAVH
UWAVH
p UWATAVAWH
(|$0f
)t$PL
(D$@f
(D$@f
(D$0f
D$xH;
A_A^A\_]
p UWATAVAWH
(|$0f
)t$PL
(D$@f
(D$@f
(D$0f
D$xH;
A_A^A\_]
p UWATAVAWH
(|$0f
)t$PL
(D$@f
(D$@f
(D$0f
D$xH;
A_A^A\_]
p UWATAVAWH
(|$0f
)t$PL
(D$@f
(D$@f
(D$0f
D$xH;
A_A^A\_]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
p UWATAVAWH
(|$0f
)t$0L
(D$@f
(D$@f
(D$0f
(|$@f
)t$0L
(D$Pf
D$pH;
A_A^A\_]
p UWATAVAWH
(|$0f
)t$0L
(D$@f
(D$@f
(D$0f
(|$@f
)t$0L
(D$Pf
t^fff
D$pH;
A_A^A\_]
p UWATAVAWH
(|$0f
)t$0L
(D$@f
(D$@f
(D$0f
(|$@f
)t$0L
(D$Pf
t^fff
D$pH;
A_A^A\_]
p UWATAVAWH
(|$0f
)t$0L
(D$@f
(D$@f
(D$0f
(|$@f
)t$0L
(D$Pf
D$pH;
A_A^A\_]
@USWH
D$hH+
(D$0f
(D$@f
T$pH+
@USWH
D$hH+
(D$0f
(D$@f
T$pH+
@USWH
D$hH+
(D$0f
(D$@f
T$pH+
@USWH
D$hH+
(D$0f
(D$@f
T$pH+
@SUVWAVH
)D$0A
)L$@L
)L$`H
A^_^][
@SUVWAVH
)D$0A
)L$@L
)L$`H
A^_^][
@SUVWAVH
)D$0A
)L$@L
)L$`H
A^_^][
@SUVWAVH
)D$0A
)L$@L
)L$`H
A^_^][
UVWATAUAVAWH
p L+p
(t$@H
D$ E3
A_A^A]A\_^]
UVWATAUAVAWH
p L+p
(t$@H
D$ E3
A_A^A]A\_^]
UVWATAUAVAWH
p L+p
(t$@H
D$ E3
A_A^A]A\_^]
UVWATAUAVAWH
p L+p
(t$@H
D$ E3
A_A^A]A\_^]
B H+B
UWAWH
 A__]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
t$ WH
t$ WH
l$ VWAVH
l$ VWAVH
l$ VWAVH
UWAVH
USVWAVAWH
T$`H;
A_A^_^[]
t$ WH
UVWATAUAVAWH
A_A^A]A\_^]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
UUUUUUU
PA_A^A]A\_^[
\$ UH
|$@fff
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
t$ WH
t$ WH
t$ WAVAWH
D$XH+
t$8HcE,H;
E@H+E0H
E8H;E@t
A_A^_
t$8H+
UVWATAUAVAWH
W(H;W0tL
W(H;W0t
W@H;WHt
W(H;W0tH
WXH;W`t
L;d$0
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWATAUAVAWH
T$PE3
fffffff
McH,H
gfffffffH
fffffff
D$hHc
T$pH;
A_A^A]A\_^]
|$ UH
t$ WH
L$HH3
\$ UVWATAUAVAWH
IcP(H
Ic@(H
|$@H;t$X
HcP,H
Hcx,H
A_A^A]A\_^]
@SUVWATAVAWH
f9Gvu$
PA_A^A\_^][
|$ UH
@USVWAVH
`A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
~,fff
A_A^A]A\_^]
t$ WH
L$pH3
VWAVH
0A^_^
L$`L+
D$ I+
\$ WH
L$HH3
@USVWAVH
A^_^[]
Ic8H;
t$ WH
 Hc:H
Ic(H;
t$ WH
 Hc:H
Ic(H;
Ic8H;
tQfff
Ic8H;
Ic8H;
Ic8H;
@UAVAWH
 Hc*L
Mc0I;
 A_A^]
Ic8H;
Ic8H;
UWAVH
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWAVH
A^_^[]
\$ UVWATAUAVAWH
v I+v
D$@I;
T$PE3
A_A^A]A\_^]
\$ UVWATAUAVAWH
^ H+^
T$HE3
A_A^A]A\_^]
\$ UVWATAUAVAWH
q L+q
D$@I;
T$XE3
~5fff
A_A^A]A\_^]
\$ UVWATAUAVAWH
q L+q
D$HI;
T$XE3
A_A^A]A\_^]
t$ WH
\$ UVWATAUAVAWH
N H+N
A_A^A]A\_^]
HXH9NX
|$ UH
@USVWATAVAWH
(D$@f
A_A^A\_^[]
@USVWATAVAWH
(D$@f
A_A^A\_^[]
USVWAVH
(D$@f
A^_^[]
USVWAVH
(D$@f
A^_^[]
@USVWATAVAWH
(D$@f
A_A^A\_^[]
@USVWAVH
`A^_^[]
t$ WH
L$hH3
\$ UVWAVAWH
pA_A^_^]
\$ UVWAVAWH
pA_A^_^]
\$ UVWAVAWH
pA_A^_^]
\$ UVWAVAWH
pA_A^_^]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
@USVWATAUAVAWH
)L$PH
T$ H;
A_A^A]A\_^[]
l$ AVAWH
l$0A_A^
t$ A^
t$ A^
l$ AVAWH
l$0A_A^
l$ AVAWH
l$0A_A^
t$ A^
t$ A^
l$ AVAWH
l$0A_A^
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
VWATAVAWH
D$(H;
|$ H;
0A_A^A\_^
@USVWATAUAVAWH
P I+P
A_A^A]A\_^[]
@USVWATAUAVAWH
P I+P
A_A^A]A\_^[]
@USVWATAUAVAWH
P I+P
A_A^A]A\_^[]
@USVWATAUAVAWH
P I+P
A_A^A]A\_^[]
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
@SUAVH
 A^][
 A^][
 A^][
z3u1I;
z5u3I;
z3u1I;
z5u3I;
@SVATAUAWH
|$8H+
sXfff
@A_A]A\^[
@SVATAUAWH
|$8H+
s\fff
@A_A]A\^[
@SVATAUAWH
|$8H+
sXfff
@A_A]A\^[
@SVATAUAWH
|$8H+
s\fff
@A_A]A\^[
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
\$ UVWAVAWH
\$HA_A^_^]
\$HA_A^_^]
A_A^_^]
@SUVWAUAVH
sJfff
L$8H3
HA^A]_^][
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
@SUVWAUAVH
sLfff
L$8H3
HA^A]_^][
@SUVWAUAVH
sJfff
L$8H3
HA^A]_^][
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
\$ UVWAVAWH
0A_A^_^]
0A_A^_^]
@SUVWAUAVH
sLfff
L$8H3
HA^A]_^][
WAVAWH
l$PH+
sJfff
L$ H3
0A_A^_
WAVAWH
l$PH+
sLfff
L$ H3
0A_A^_
WAVAWH
l$PH+
sJfff
L$ H3
0A_A^_
WAVAWH
l$PH+
sLfff
L$ H3
0A_A^_
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
@VATAVH
\$ A^A\^
VWAVH
|$PI;
D9K vr
T$XH+
L$`H3
@VATAVH
\$ A^A\^
t$(M;
k0L9{
L$@H3
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
t$(M;
L$@H3
t$(M;
L$@H3
@VATAVH
\$ A^A\^
VWAVH
\$PI;
D9G vu
T$XH+
L$`H3
@VATAVH
\$ A^A\^
t$(M;
tufff
L$@H3
VWAVH
|$PI;
D9K vs
T$XH+
L$`H3
t$(M;
k0L9{
tufff
L$@H3
t$(M;
k0L9{
L$@H3
t$(M;
k0L9{
tufff
L$@H3
VWAVH
|$PI;
D9K vr
T$XH+
L$`H3
VWAVH
|$PI;
D9K vs
T$XH+
L$`H3
t$(M;
L$@H3
@USVWATAVAWH
A_A^A\_^[]
@VATAVL
\$ A^A\^
@VATAVL
\$ A^A\^
@VATAVL
\$ A^A\^
@VATAVL
\$ A^A\^
VWATAVAWH
@A_A^A\_^
t$ WH
t$ WH
t$ WH
t$ WH
UVWAVAWH
A_A^_^]
@SUAVH
@A^][
D8I1A
\$ UVWATAUAVAWH
G I+G
O M+O
L$ M+
A_A^A]A\_^]
\$ UVWATAUAVAWH
L$@L;
A_A^A]A\_^]
D$xH;
\$ UVWAVAWH
A_A^_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
UWAVH
UWAVH
SVWATAUAVAWH
UUUUUUU
@A_A^A]A\_^[
t$ WH
t$ WH
t$8H+
\$ UVWATAUAVAWH
H9wht
A_A^A]A\_^]
\$ UVWATAUAVAWH
8T$`I
A_A^A]A\_^]
\$ UVWATAUAVAWH
\$ I+\$
~ H+~
t$hE2
D$HH;
UUUUUUU
3333333
L$`E3
gfffffffH
A_A^A]A\_^]
L$pH+
L$0H+
|$ E3
l$ WAVAWH
t$HH+
 A_A^_
VWAVH
UUUUUUU
 A^_^
UWAVH
@USVWATAUAVAWH
D$@HcH
D$@HcH
D$@HcH
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^_^[]
t$ WH
\$ UVWATAUAVAWH
L9qXt
A_A^A]A\_^]
@SUVWATAVAWH
S H;S(H
L$PH3
`A_A^A\_^][
@SUVWATAUAVAWH
A_A^A]A\_^][
UWAVH
t$ WH
UWAVH
UVWATAUAVAWH
t$0E3
A_A^A]A\_^]
UWAVH
SUVWH
T$PH;
t$ WH
VWAVH
|$@L;
 A^_^
UVWATAUAVAWH
A_A^A]A\_^]
L$xHc
H9D$0t
|$@ff
t$ WH
SUVWATAUAVAWH
T$ H;
T$pH;
A_A^A]A\_^][
SUVWATAUAVAWH
T$ H;
T$pH;
A_A^A]A\_^][
SUVWATAUAVAWH
T$PH;
A_A^A]A\_^][
SUVWATAUAVAWH
T$PH;
A_A^A]A\_^][
t$ WATAUAVAWH
D$0Hc
A_A^A]A\_
t$ UWAVH
t$ UWAVH
t$ UWAVH
t$ UWAVH
(t$0L
WAVAWH
)t$ L
0A_A^_
WAVAWH
)t$ L
W(fff
0A_A^_
ATAVH
)D$0H
F(fff
(t$PL
|$ ATAVAWH
)t$ L
0A_A^A\
(t$0L
|$ ATAVAWH
)t$ L
0A_A^A\
ATAVH
)D$0H
(t$PL
\$ UVWATAUAVAWH
(D$pf
A_A^A]A\_^]
\$ UVWATAUAVAWH
(D$pf
A_A^A]A\_^]
\$ UVWATAUAVAWH
(D$pf
A_A^A]A\_^]
\$ UVWATAUAVAWH
(D$pf
A_A^A]A\_^]
USVWATAUAVAWH
A_A^A]A\_^[]
USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
t$ WH
WAVAWH
(t$ H
0A_A^_
AVAWH
)t$0I
N0fff
(t$0L
hA_A^
AVAWH
)t$0I
(t$0L
hA_A^
WAVAWH
(t$ H
0A_A^_
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
L;EpL
BEpL+
A_A^A]A\_^[]
(t$ H
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
gfffffffI
fffffff
D$0I;
t$pI;
gfffffffH
A_A^A]A\_^[
UVWATAUAVAWH
)t$`M
(D$ f
(t$`H
pA_A^A]A\_^]
UVWATAUAVAWH
)t$`M
(D$ f
(t$`H
pA_A^A]A\_^]
t$ UWATAVAWH
A_A^A\_]
gfffffffH
t$ WH
X UVWATAUAVAWH
D$8Lc
HcD$8H
A_A^A]A\_^]
@SUVWH
t$ WH
t$ WH
t$ WH
@SUVWATAVAWH
H;=U;7
tfH;=
T$PH;
T$PH;
A_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
D$0Hc
(|$PH
UVWAVAWH
)|$PM
|$0Lc
(|$PH
pA_A^_^]
VWATAVAWH
)|$`D
)D$PM
|$0E3
(|$`E
A_A^A\_^
Lc\$@E3
)D$pD
)L$`D
)T$PD
)\$@D
)d$0D
)l$ D
(l$ D
(d$0D
(\$@D
(T$PD
(L$`D
)D$pD
)L$`D
)T$PD
)\$@D
)d$0D
)l$ D
(5'~&
(=?~&
(l$ D
(d$0D
(\$@D
(T$PD
(L$`D
UVWAVAWH
)|$PM
|$0Mc
(|$PH
pA_A^_^]
)l$ D
)<$Mc
(5+u&
(=Cu&
)4$Mc
(%z]'
(5u]'
(|$pL
HcT$xL
d$`Mc
t$ WHc|$0E3
D$@Hc
D$ E3
L$@H3
HcL$0M
 Hcl$PI
 Hcl$PI
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SVWH
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
SVWATAUAVAWH
gfffffffI
fffffff
0A_A^A]A\_^[
@SVWATAUAVAWH
|$PLi
D$0I;
>HiL$8
A_A^A]A\_^[
SVWAVAWH
fffffff
gfffffffI
0A_A^_^[
t$ WATAUAVAWH
A_A^A]A\_
t$ WAVAWH
D$0A9
F8I+F(H
FPI+F@H
F0I;F8t
FHI;FPt
A_A^_
VWAVH
VWAVH
\$ E3
\$ UVWATAUAVAWH
f9Pvu$
L$HH3
PA_A^A]A\_^]
UVWATAUAVAWH
t$0E3
A_A^A]A\_^]
@USVWAVH
A^_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWAVAWH
0A_A^_^]
UVWAVAWH
0A_A^_^]
UVWATAUAVAWH
IcP Ic@
A_A^A]A\_^]
t$ UWATAVAWH
A_A^A\_]
@USVWATAUAVAWH
t$PHc
t$PE3
d$xL9
(L;|$`L
gfffffffH
t$PE3
|$xH;
A_A^A]A\_^[]
@SVWH
@USVWAVH
D$HH;
A^_^[]
L$0I;
UAUAVH
H#E0H
L;|$8t
L9l$(
L9l$(u
H#E0L
`A^A]]
\$ VH
gfffffffI
VWATAVAWH
@A_A^A\_^
VATAUAVAWH
 A_A^A]A\^
\$ UVWATAUAVAWH
A_A^A]A\_^]
t$ WH
@SUVWAVAWH
T$@H;
A_A^_^][
L$PMc
X UVWATAUAVAWH
)D$pf
LcG$A
A_A^A]A\_^]
X UVWATAUAVAWH
)D$pf
LcG$A
A_A^A]A\_^]
@SUVWATAVAWH
L$pE3
T$0H;
L$xH3
A_A^A\_^][
UVWAVAWH
0A_A^_^]
@SUVWAUAWH
C(D98
u[G9<3uUH
D;8|tH
D;<)|dH
C(D;8
A_A]_^][
@SUVWAUAWH
C(D98
u[G9<3uUH
D;8|tH
D;<)|dH
C(D;8
A_A]_^][
LcA$H
D$PLc
D$`Lc
D$pLc
@SUWAWH
D$xLc
D$@D9
HcW$C
HcO$L
Hc_$H
LcG$H
Hc_$H
LcG$H
Hc_$H
LcG$H
HcO$H
A__][
D$8H+
D$8H+
E;X$|
LcI$L
t$ WL
|$ UH
L$@H3
WAVAWH
0A_A^_
L$(H3
t$ UWAVH
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@SUVWATAVH
(A^A\_^][
(A^A\_^][
@SVWATAUAVAWH
\$ I;
PA_A^A]A\_^[
@SVWH
L+IHL
T$0E3
t$ WH
UVWAVAWH
D$(E3
t$`H+
L$pH3
A_A^_^]
t$ WH
L$8H3
t$ WH
L$(H3
t$ WH
L$PH3
L$(H3
L$HH3
VWAVH
0A^_^
@SUVWAVH
L$8H3
@A^_^][
@SUVWAVH
A^_^][
@SUVWAVH
L$8H3
@A^_^][
\$ VH
D$0I;
L$(H3
D$0H;
T$0M;
L$0M+
(D$0f
VWAVH
CT$8L
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
L$0I+
L+l$8I
`A_A^A]A\_^[
`A_A^A]A\_^[
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
I#W0H
(D$ f
I#w0H
UVWATAUAVAWH
t$4fD
D$4fD
t$4fD
A_A^A]A\_^]
t$@H+
|$Hfff
l$@H+
H#G0H
L$(H3
B 9A 
A 9B 
t$ WH
L$`H3
L$`H3
H#C0H
L$`H3
T$ H;
\$ UVWH
)D$PH
UVWAVAWH
(D$@f
A_A^_^]
)D$pH
)D$pH
@USVWAVAWH
A_A^_^[]
UVWAVAWH
(D$0f
A_A^_^]
\$ UVWAVAWH
A_A^_^]
L$PH3
@SVWH
L$8H3
VWATAVAWH
0A_A^A\_^
L$(H3
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ UVWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
@SUVWATAVAWH
T$0H;
pA_A^A\_^][
@SUVAVH
(A^^][
@SUVWAVAWH
HA_A^_^][
@SUVWAVH
@A^_^][
L$ H3
VWAVH
 A^_^
|$ AVH
@USVWAVAWH
L$HE3
A_A^_^[]
@USVWATAVAWH
A_A^A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
(D$@f
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
|$ AVH
t9fff
t$ UWATAVAWH
(D$`f
(D$@f
A_A^A\_]
L$HH3
L$0H3
@USVWATAVAWH
A_A^A\_^[]
@USVWATAVAWH
D$PH+
D$pH+
A_A^A\_^[]
@USVWATAVAWH
D$PH+
D$pH+
A_A^A\_^[]
@USVWAVAWH
(D$@f
(D$@f
D$pH+
A_A^_^[]
@UVWATAUAVAWH
D$PH+
D$pH+
A_A^A]A\_^]
@USVWATAVAWH
D$PH+
D$pH+
A_A^A\_^[]
@USVWATAUAVAWH
(D$@f
A_A^A]A\_^[]
@UVWATAUAVAWH
L$xL;
D$PH+
A_A^A]A\_^]
@USVWATAUAVAWH
L$pL;
D$PH+
A_A^A]A\_^[]
t$ WH
L$(H3
@USVWAVAWH
A_A^_^[]
@USVWAVH
(D$Pf
D$@H+
A^_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USWH
|$ AVH
L$0H+
\$ UVWATAUAVAWH
3333333
d$8E3
(D$ f
PA_A^A]A\_^]
@USVWATAUAVAWH
I#M0H
A_A^A]A\_^[]
t)H;V
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
@USVWAVAWH
A_A^_^[]
@SVWATAUAVAWH
t$ I;
|$PH+
pA_A^A]A\_^[
t$ WATAUAVAWH
A_A^A]A\_
@SVWH
UVWATAUAVAWH
|$ E3
A_A^A]A\_^]
|$ UATAUAVAWH
d$ E3
t$ E3
A_A^A]A\]
@USVWATAVAWH
A_A^A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SVWH
T$HH+
T$HI+
L$PH3
T$HI+
@SUVWATAUAVAWH
L$0E3
L$8H3
HA_A^A]A\_^][
t$ ATAVAWH
 A_A^A\
@USVWATAUAVAWH
gfffffffH
A_A^A]A\_^[]
@SUVWAVH
L$PH3
`A^_^][
@USVWATAUAVAWH
gfffffffH
A_A^A]A\_^[]
t$ WH
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
gfffffffI
fffffff
A_A^A]A\_^[]
\$ UVWATAUAVAWH
gfffffffH
`0M+`(I
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWAVAWH
A_A^_^]
L9@ s
L;A r
tionProvH
CPUExecuH9
TvmExecuH9
VitisAIEH9
xecutionH9H
ProviderH9H
ACLExecuH9
UWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
@SUVWH
|$ L;
(_^][
t"fff
(_^][
t$ WATAUAVAWH
A_A^A]A\_
VWATAVAWH
D$@L;
D$@H;
L$`H3
A_A^A\_^
UAUAVH
L$0M;
L$@H3
pA^A]]
@SVWH
@SUVWATAUAVAWH
L$ H+
8A_A^A]A\_^][
@SUVWATAUAVAWH
\$ L;
8A_A^A]A\_^][
@SUVWAVAWH
L$PH3
hA_A^_^][
t$ WAVAWH
\$0E3
)D$ L
A_A^_
|$ UAVAWH
A_A^]
\$ UVWH
\$ WH
WATAUAVAWH
0A_A^A]A\_
L9A s
uFL;B r@I
L9A s
L;B s
L$(9J(
L9A s
uKL;B rELcL$(I
L9I s
L;J s
t$ UWAVH
@A^_]
@SVWH
\$ WH
\$ WH
@SUVWH
t$0H;
8_^][
\$ UVWAVAWH
A_A^_^]
H;HHs`H
\$@u!
{ AVH
t$pL9u
\$`u'
(D$ f
@SUVWAVH
A^_^][
@SVWH
@SVWH
@SVWH
@SVWH
@SVWH
\$ AVH
D$0H;S
@SUVWATAUAVAWH
XA_A^A]A\_^][
\$ AVH
L$0H;S
@SVWAVH
xA^_^[
xA^_^[
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
@UVWH
|$0H+|$(H
WAVAWH
 A_A^_
t$ WATAUAVAWH
t$pA8h
D9h0t
H,A;I
H(A;I
I;6ugD;j
T$ D9j0t
B,A;G
B(A;G
udE;n0t
A;F,t
A;F(t
A_A^A]A\_
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
fffffff
d$ E3
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
fffffff
d$ E3
H#U0H
(D$ f
H#}0H
@SUVWATAUAVAWH
XA_A^A]A\_^][
t$ UWAVH
L$@E3
H#C0H
UVWATAUAVAWH
$H9D$0
)D$pL
VXI;V`t)L
A_A^A]A\_^]
@UAVH
H#E0L
L$(H3
A9Y0t
A,A;@
A(A;@
A;C0t
A;C,t
A;C(t
@SUVWATAUAVAWH
A_A^A]A\_^][
\$ UVWATAUAVAWH
fD9Iv
Fu8Au
Ft8At
Gvf9Av
Gu8Au
Gt8At
A_A^A]A\_^]
@SUVWATAUAVAWH
A_A^A]A\_^][
\$ UVWATAUAVAWH
fD9Iv
Fu8Au
Ft8At
Gvf9Av
Gu8Au
Gt8At
A_A^A]A\_^]
@SVWH
L$(H3
T$0E3
T$0D9R0t
A;A0t
A;A,t
A;A(t
)D$ L
@SVWATAUAVAWH
t$0I;
`A_A^A]A\_^[
A,A;B
A(A;B
A;A,t
A;A(t
D;J0t
A9X0t
@,A;B
@(A;B
A;C0t
A;C,t
A;C(t
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
\$ VH
l$8H+
UVWAVAWH
|$ L;
PA_A^_^]
UVWAVAWH
|$ L;
PA_A^_^]
UVWAVAWH
|$ L;
PA_A^_^]
@SUVWH
L$@H3
X_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWH
H#CXH
@USVWATAUAVAWH
A_A^A]A\_^[]
l$ VWATAVAWH
)D$pL
A_A^A\_^
t$ UWAVH
l$ VWAVH
t_fff
L$0H3
@A^_^
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
t$ WATAUAVAWH
L$8E2
A_A^A]A\_
t$ WATAUAVAWH
L$8E2
L$8L;d$P
L$8H;
A_A^A]A\_
@SUVWATAUAVAWH
L$ E3
)D$ L
XA_A^A]A\_^][
l$ WATAVH
u-fff
 A^A\_
\$ UVWATAUAVAWH
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
I#W0H
(D$ f
I#w0H
@SUVWAVH
PA^_^][
UVWATAUAVAWH
t$0L;
C\$0H
t$0L;
C\$0H
A_A^A]A\_^]
USVWAVH
A^_^[]
UWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
@SUVWATAUAVAWH
A_A^A]A\_^][
@USVWATAUAVAWH
t$hI;
D$PH;D$Xt
D$PH9D$H
|$PH;
T$XH+
|$PH;
T$XH+
A_A^A]A\_^[]
|$PH;
T$XH+
H#C@H
\$ UVWATAUAVAWH
A_A^A]A\_^]
@UAVH
H#E0L
L$(H3
@SVWH
\$ UVL
\$0^]
\$0^]
@SUVWATAVAWH
H#U0H
0A_A^A\_^][
H#U0H
(D$ f
H#}0H
UVWATAUAVAWH
)t$pI
)|$`E3
(|$`H
A_A^A]A\_^]
\$ UVWATAUAVAWH
T$0E3
L9H s
L;I r
A_A^A]A\_^]
USVWATAUAVAWH
L9x s
L;y r
A_A^A]A\_^[]
|$8H;
t$ WH
H;S8v
(t$ H
VWATAVAWH
0A_A^A\_^
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
WATAUAVAWH
D$ H;S
l$0M;
L$8H3
@A_A^A]A\_
WATAUAVAWH
D$ H;S
l$0M;
L$8H3
@A_A^A]A\_
WATAUAVAWH
D$(H;S
l$(M;
L$0H3
@A_A^A]A\_
VWATAUAWH
l$(H;S
t$ M;
L$0H3
@A_A]A\_^
WATAUAVAWH
D$(H;S
l$ M;
L$0H3
@A_A^A]A\_
d$0I;Q
L$0H;W
D$0H;U
D$(H;S
D$0H;W
L$8H3
L$8H3
d$0I;Q
t$Hfff
L$0H;W
D$0H;U
D$(H;S
D$0H;W
L$8H3
L$8H3
d$(I;Q
t$Hfff
L$(H;W
D$(H;U
D$(H;S
D$ H;W
L$0H3
L$0H3
d$(I;Q
t$Hfff
L$(H;V
D$(H;U
|$(H;S
D$(H;V
L$0H3
L$0H3
d$(I;Q
t$Hfff
L$(H;W
D$(H;U
D$(H;S
D$(H;W
L$0H3
L$0H3
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
@USVWATAUAVAWH
L$AE3
(D$Pf
(D$Pf
(D$Pf
(D$Pf
A_A^A]A\_^[]
@USVWATAUAVAWH
(D$Pf
(D$Pf
(D$Pf
(D$Pf
A_A^A]A\_^[]
@USVWATAUAVAWH
D$hL;
T$hI;
A_A^A]A\_^[]
@USVWATAUAVAWH
D$`L;
T$xff
A_A^A]A\_^[]
t$ WH
@SUVWAVH
L$ E3
L$(H3
0A^_^][
@SUVWAVH
L$ E3
L$(H3
0A^_^][
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
\$ UVWH
\$ UVWH
\$ UVWH
\$ UVWH
@SUVWH
L$`H3
x_^][
@SUVWH
L$`H3
x_^][
@SUVWH
L$`H3
x_^][
@SUVWH
L$`H3
x_^][
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SUVWH
L$`H3
x_^][
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
\$ VH
l$hHc
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
\$ VH
l$hHc
\$ WH
H;L$xt
D$(I;
D$ I;
L$0H3
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
@SUVWATAVAWH
\$4D9
t$ E3
A_A^A\_^][
@SVWAVH
L$`H3
xA^_^[
H;L$ht*
SVWATAUAVAWH
T$0I+
T$@I+
PA_A^A]A\_^[
PA_A^A]A\_^[
SVWATAUAVAWH
T$0I+
T$@I+
PA_A^A]A\_^[
PA_A^A]A\_^[
SVWATAUAVAWH
T$0I+
T$@I+
PA_A^A]A\_^[
PA_A^A]A\_^[
@WATAVAWH
l$ E3
8A_A^A\_
@SUVWAVH
`A^_^][
@SUVWAVH
 A^_^][
 A^_^][
9B(uzH
A H;B up
\$ 9B(uNH
L$0H3
@SUVWAVAWH
A_A^_^][
UVWATAUAVAWH
(D$@f
(D$@f
(D$@f
(D$@f
L;|$H
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
D$8H+
(D$ f
T$@H+
L$HH3
@USVWH
@USVWATAUAVAWH
A_A^A]A\_^[]
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
D$pH+
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
D$PH;
\$ UVWAVAWH
L$HH3
PA_A^_^]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWAVAWH
A_A^_^]
VWATAVAWH
L$`E3
H;|$`
L$hH3
A_A^A\_^
\$ UVWATAUAVAWH
d$8E3
v fff
(D$ f
PA_A^A]A\_^]
@USVWAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A__^[]
@SUVWATAVAWH
A_A^A\_^][
VWAVH
t0H;E
@A^_^
UVWAVAWH
t$HH;
\$@@2
T$PH+
L$XH3
`A_A^_^]
t$ WH
L$8H3
t$ UWATAVAWH
A_A^A\_]
|$ AVH
@USVWATAUAVAWH
A_A^A]A\_^[]
VWATAVAWH
@A_A^A\_^
t$ WH
VWAVH
V H+V
 A^_^
@USVWAVH
A^_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
WAVAWH
A_A^_
|$ UH
UWATAVAWH
t$ E3
A_A^A\_]
@SVWATAUAVAWH
T$pE3
t$0L;
C\$0H
L$ E3
\$0E3
|$8D8{
A_A^A]A\_^[
@SWATH
O(+O0
H+G8H
H+G8H
O(+O0
PA\_[
@SUVWAVH
0A^_^][
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A_A^A]A\_^[]
t$ WATAUAVAWH
l$HH;
tpfff
A_A^A]A\_
t$ WATAUAVAWH
A_A^A]A\_
@SVWATAUAVAWH
PA_A^A]A\_^[
A9X,t
@(A;B
A;C,t
A;C(t
L$HL;
L+|$8
\$ UVWATAUAVAWH
0A_A^A]A\_^]
\$ UVWATAUAVAWH
L$PH+
|$(L;
H+L$0H
t$@M;
l$(M;
D$HL;
|$(L;
t$@u?M;
l$ M;
`A_A^A]A\_^]
@SUVWATAUAVAWH
L9|$(|
HA_A^A]A\_^][
t$ WATAUAVAWH
D$(I;
A_A^A]A\_
@SUVWAVAWH
(A_A^_^][
(A_A^_^][
@SUVWATAUAVH
T$8H+
|$HM;
|$@ff
|$HM;
L$xH3
A^A]A\_^][
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
fffffff
I#W0H
(D$ f
I#w0H
l$ VWAVH
T$0E3
T$0D9R,t
A;A,t
A;A(t
"""""""
)D$ L
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
H#U0H
@A_A^A]A\_^]
l$0E3
H#E0H
(D$ f
H#}0H
L$8H3
@SUVWATAVAWH
I#W0H
0A_A^A\_^][
I#W0H
(D$ f
I#w0H
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
d$ E3
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
D$PE3
F0H#D$0H
(D$ f
F0H#D$0H
pA_A^A]A\_^]
@SUVWATAVAWH
I#V0H
0A_A^A\_^][
I#V0H
(D$ f
I#~0H
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
)|$@H
(|$@H
`A_A^A]A\_^]
\$ UVWATAUAVAWH
)t$pH
)|$`M
(|$`H
A_A^A]A\_^]
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
@SVWH
VWAVH
t$@I+
UVWATAUAVAWH
t$@I;
I#O0H
I#O0M
l$hH;
A_A^A]A\_^]
t$HH+
UVWATAUAVAWH
T$ I+T$
A_A^A]A\_^]
@USVWAVAWH
A_A^_^[]
@SUVWAVH
u$H;Q
A^_^][
uCH;Q
SUVWH
t$ WH
UVWATAUAVAWH
|$@H;|$x
\$`H;
T$pH+
H;|$x
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
@SUVWATAVH
H+F8H;
H+F8H;
v(D+v0D
N(+N0
8NPtk
H+F8H
F(D+F0D
(A^A\_^][
\$ UVWATAUAVAWH
FxI;Fxu
A_A^A]A\_^]
t$ WAVAWH
D+z0A
N +N0
8NPtk
H+F8H
F D+F0D
N +N0
8NPtk
H+F8H
F D+F0D
 A_A^_
Q(+Q0
H+C8H
H+C8H;
H+C8H
C(+C0
UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
L$pH+
A_A^A]A\_^[]
@USVWATAUAVAWH
T$xH;
I;\$xu
O H;O 
A_A^A]A\_^[]
@USVWAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A__^[]
\$ UVWH
fD9H6u
D8P5u
D8@4tqH
L$@H3
@SUVWAVH
@A^_^][
@A^_^][
@SUVWATAVAWH
|$ H;
@A_A^A\_^][
UVWATAUAVAWH
H9y }
D$@H9x }
vb'vb'v
)D$ L
pA_A^A]A\_^]
UVWATAUAVAWH
M(+M0
M(+M0
8MPtm
H+E8H
E(D+E0D
L$pH3
A_A^A]A\_^]
D$ fH
L$xH3
:Loopt
8Scanu
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
I#D$0H
A_A^A]A\_^[]
UVWATAUAVAWH
D$0E3
L$pL;
T$pH;
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
t$8H;
L$XH3
@USVWATAUAVAWH
A_A^A]A\_^[]
|$ UATAUAVAWH
T$ H;
A_A^A]A\]
Q +Q0
H;{Hv
@SUVWATAVAWH
H9q }
I;p |
D$0H9p }
H;r }cH
UUUUUUU
)D$ L
L$`H3
pA_A^A\_^][
UVWATAUAVAWH
L$8E3
t$8H;|$@
T$PH;
A_A^A]A\_^]
|$ AVH
@SVWAVH
HcT$0H
A^_^[
\$ UVWH
HcT$0H
@SAVH
I#F0M
VWAVH
 A^_^
H#F0H
L9|$0u
l$ L9|$0u
H#F0L
|$ UATAUAVAWH
A_A^A]A\]
t$ WATAUAVAWH
A_A^A]A\_
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@SVWATAUAVAWH
gfffffffI
fffffff
t$8L;
gfffffffH
PA_A^A]A\_^[
WATAUAVAWH
 A_A^A]A\_
UVAWH
 A_^]
t$ WATAUAVAWH
|$ Ik
A_A^A]A\_
t$ E3
@SWAVAWH
L$PH3
hA_A^_[
@USVWATAUAVAWH
A_A^A]A\_^[]
gfffffffH
t$8H+
t$ WAVAWH
 A_A^_
t$ WATAUAVAWH
A_A^A]A\_
\$ VWAVH
gfffffffH
L$XH;
UVWATAUAVAWH
A_A^A]A\_^]
t$ WH
UWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
@USVWATAVAWH
D$PHcH
D$PHcH
L$PHcQ
L$PHcQ
A_A^A\_^[]
UVWATAUAVAWH
H9A s
UUUUUUU
HcS(H
HcC(H
A_A^A]A\_^]
X UVWATAUAVAWH
L$0L;
A_A^A]A\_^]
\$ UVWATAUAVAWH
\$0H;
A_A^A]A\_^]
L$0H3
t$ WAVAWH
fffffff
H9FDtzI
)D$0L
A_A^_
@SUVWAVH
W(H9h u0H
A^_^][
|$ UH
gfffffffH
UVWAVAWH
l$8H;
t_fff
A_A^_^]
@SVWH
UVWAVAWH
A_A^_^]
UVWATAUAVAWH
gfffffffH
D$8L;
gfffffffH
L;l$8
d$@Hc
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
u.H;C
UVWATAUAVAWH
L$@H;
ubE9g0
D$0H;D$@t
A_A^A]A\_^]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$HE3
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
\$ UVWH
t$8H+
\$ VH
l$8H+
t$ WH
|$ AVH
@SVWH
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
L$0H+
D$hH+
L$0H+
D$hH+
A_A^A]A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
tefff
@SUVWATAUAVAWH
A_A^A]A\_^][
@USVWATAUAVAWH
L;d$x
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
|$ UATAUAVAWH
A_A^A]A\]
C\$pH
C\$PH
C\$0H
t$ WH
@SVATAVAWH
l$XH+
 A_A^A\^[
VWAVH
@A^_^
VWAVH
@A^_^
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ VWAVH
L$(H3
0A^_^
@SVWH
CD$Pf
@USVWH
UVWATAUAVAWH
\$ E3
(D$ f
`A_A^A]A\_^]
UVWATAUAVAWH
)t$PM
(D$ f
(t$PH
`A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
com.micrH9
QLinearCL9
NhwcMaxPH9
>0O'H
p~|:]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@VAVAWH
d$(E3
gfffffff
t fff
@A_A^^
@SUVH
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
l$ VWAVH
T$0E3
T$0D9R0t
A;A0t
A;A,t
A;A(t
3333333
)D$ L
@SVWATAUAVAWH
I#G0H
|$hH+
gfffffffH
D9J0t
A;@0t
A;@,t
A;@(t
D$PH;
A_A^A]A\_^[
UVWAVAWH
A_A^_^]
|$ UH
@USVWATAUAVAWH
|$ E3
H9\$@
E HcH
E HcH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAUAVAWH
D$`I;
(D$@f
A_A^A]A\_^[]
@SUVWH
L$8H3
H_^][
@SUVWAVAWH
A_A^_^][
t$ WH
L$(H3
|$ AVH
H;A(s
H;H@s
@USVWATAUAVAWH
A_A^A]A\_^[]
\$ UVWATAUAVAWH
Y8H+Y0H
(H;l$0
A_A^A]A\_^]
gfffffffH
\$ UVWATAUAVAWH
gfffffffI
D$8I+D$0H
|$8I+|$0H
D$0Hc
A_A^A]A\_^]
@SVWH
L$8H3
@SVWH
L$PH3
@USVWAVH
A^_^[]
t$ WH
L$(H3
|$ UATAUAVAWH
A_A^A]A\]
\$ UVWATAUAVAWH
A_A^A]A\_^]
l$ VWATAVAWH
l$8H;
L$XH;
L$hH3
A_A^A\_^
l$ VWATAVAWH
D$0fH
D$xI;
A_A^A\_^
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVAUI
VWATAVAWH
\$ I;
@A_A^A\_^
T$(H;
t$ WH
t$ WH
@SUVWH
d$XH;
(_^][
B L+B
O H+O
@USVWAUAVAWH
O L+O
O L+O
A_A^A]_^[]
@USVWAUAVAWH
O L+O
O L+O
A_A^A]_^[]
L$HH3
@USVWAVH
A^_^[]
@USVWAVH
A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
t$0I;
pA_A^A]A\_^[
@SUVWATAUAVAWH
XA_A^A]A\_^][
l$ VWATAVAWH
D$ I+
|$XI;
L$xH3
A_A^A\_^
t$8H+
|$8H+
@SVWH
WATAUAVAWH
L$`H;
nPM;nXtQ3
A_A^A]A\_
|$ UAVAWH
K8H9CHt
A_A^]
@USVWATAUAVAWH
E HcH
E HcH
E HcH
E HcH
gfffffffH
A_A^A]A\_^[]
@SVWATAUAVAWH
|$hE3
H9P s
H;Q r
H9P s
H;Q r
A_A^A]A\_^[
|$P@2
l$hff
|$pE3
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@SVWAVH
FXI+FHH
VPI;VXt
A^_^[
@USVWATAUAVAWH
D$`E3
CT$hH
A_A^A]A\_^[]
UVWATAUAVAWH
l$0E3
A_A^A]A\_^]
SVWATAUAVAWH
T$`H;
L9A s
L;B r
H9P s
H;Q r
gfffffffH
A_A^A]A\_^[
@SUVWATAVAWH
L$0IcY
L$8H3
@A_A^A\_^][
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USWH
)D$ f
t$ WATAUAVAWH
A_A^A]A\_
t$ WATAUAVAWH
D$ I;
BPfff
A_A^A]A\_
VWATAVAWH
@A_A^A\_^
UVWATAUAVAWH
)t$`Ic
)|$PH
(|$PH
pA_A^A]A\_^]
UVWATAUAVAWH
)t$`L
)|$PI
(D$ H
(|$PH
pA_A^A]A\_^]
t$ WH
t$8H+
X UVWATAUAVAWH
L9P s
L;Q r
A_A^A]A\_^]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
UVWATAUAVAWH
PA_A^A]A\_^]
UVWATAUAVAWH
T$<A;
L$xH;
I+AHH
I;Q@t
N 9H u\
I+AHH
I+AHH
I;Q@t
I+AHH
I;QXt
I+AHH
I;QXt
I+AHH
I;QXt
A_A^A]A\_^]
UVWATAUAVAWH
L$HH;
T$HH;
t$4I;N
L9` s
L;a r
\$@H;]
A_A^A]A\_^]
UVWAVAWH
A_A^_^]
UWATAVAWH
A_A^A\_]
L$ UVWATAUAVAWH
 A_A^A]A\_^]
VWATAVAWH
A_A^A\_^
UVWAVAWH
l$xt|H
L$hI+
A_A^_^]
@USVWATAUAVAWH
L$hE3
L$`E3
L;d$`
T$HH;
D$xt=
D$8H;x
A_A^A]A\_^[]
S D9R0t
C A;A0t
A;A,t
A;A(t
UVWATAUAVAWH
T$PE3
I;]xtbL
I;]xt
`A_A^A]A\_^]
l$ VWAVH
|$ AVH
L$0H+
@SUVWATAVAWH
u-9H(u
O H;H tj2
L$0H3
@A_A^A\_^][
t$8H+
\$ WH
l$Xff
WAVAWH
)D$0L
T$ E3
D$0M+
)D$@I
L$@I+
(D$ f
(L$0f
\$ M;
PA_A^_
VWATAVAWH
0A_A^A\_^
@SWAVH
(D$ H
`A^_[
(D$ L
(L$0H
`A^_[
A H+A
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
l$8E3
(D$ f
PA_A^A]A\_^]
@USVWAUH
A]_^[]
L$`L;
OPH;OPH
\$ WH
T$0E3
T$0D9R0t
A;A0t
A;A,t
A;A(t
)D$ L
@SVWH
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
|$ AVH
|$ AVH
l$ VWAVH
0A^_^
t$ WH
\$ UVWATAUAVAWH
Q0H+Q(H
d$`H;\$h
A_A^A]A\_^]
|$ E3
t$ WH
D$ H;
t$(H+
@SVWH
L$8H3
@USVWATAUAVAWH
M0I+M(H
L9x8t4H
xA_A^A]A\_^[]
@USVWAVH
pA^_^[]
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
d$ E3
H#U0H
(D$ f
H#}0H
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
@SUVWAVH
pA^_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
t$ UWATAVAWH
HcT$0H
fA9Fvu
A8Fuu
A8Ftu
A_A^A\_]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SUVWAVH
L$@E3
L$HH3
PA^_^][
@USVWATAUAVAWH
|$ E3
A_A^A]A\_^[]
@USVWATAUAVAWH
|$XE3
t$PH;
|$`E3
A_A^A]A\_^[]
\$ UVWATAUAVAWH
D$@H;H
D$PL;
I#G0H
L;l$P
A_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
|$ AVH
@USVWATAUAVAWH
t$0L;
C\$0H
|$pE3
A_A^A]A\_^[]
@USVWATAUAVAWH
t$0L;
C\$0H
A_A^A]A\_^[]
@USVWATAUAVAWH
|$PH;
|$PH;
T$PH;
T$PH;
T$PH;
A_A^A]A\_^[]
L$(H3
UVWAVAWH
T$0E3
T$0D9J0t
A;B0t
A;B,t
A;B(t
)D$ L
PA_A^_^]
t$ WATAUAVAWH
gfffffffI
fffffff
gfffffff
gfffffff
A_A^A]A\_
@SVWATAUAVAWH
t$ H;
`A_A^A]A\_^[
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
fffffff
d$ E3
I#W0H
(D$ f
I#w0H
t$ WH
@SUVWAVH
L$XH3
`A^_^][
gfffffffH+
UVWATAUAVAWH
G I;G(t
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
D$0H;
gfffffffH
t$ WH
L$0H;
@SUWH
L$ H;
@SWATH
l$@ff
O(+O0
H+G8H
H+G8H
G(+G0
 A\_[
|$ AVH
H+C8H;
D$HH;D$Ht
|$ ATAVAWH
L$XH3
A_A^A\
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
|$ AVH
 HcD$PI
L$ H3
L$ H3
t$ WATAUAVAWH
l$8H;
A_A^A]A\_
UVWATAUAVAWH
L$ E3
l$8D8h
H(;M(u
M,9H,
E(A;@(u
@,9E,
UUUUUUU
)D$ L
PA_A^A]A\_^]
D$0E3
A;@(u
UUUUUUU
)D$ L
SVWATAUAVAWH
UUUUUUU
0A_A^A]A\_^[
t$ WATAUAVAWH
A_A^A]A\_
SVWATAUAVAWH
UUUUUUU
0A_A^A]A\_^[
t$ WATAUAVAWH
UUUUUUU
A_A^A]A\_
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
@SVWATAUAVAWH
tofff
|$0I;
PA_A^A]A\_^[
@SVWATAUAVAWH
T$0I;
PA_A^A]A\_^[
A(A;@
A,A9@
A;A(u
A,A9@
@SWAVH
 A^_[
 A^_[
@SATAUAVH
(A^A]A\[
WATAUAVAWH
1M+0I
L$0I+
L+l$HI
A_A^A]A\_
\$ VWAVH
0A^_^
\$ UVWATAUAVAWH
PA_A^A]A\_^]
@SUVWATAUAVAWH
8A_A^A]A\_^][
WATAUAVAWH
\$ I;
L+l$8t
PA_A^A]A\_
VWATAVAWH
UUUUUUU
\$hI;
0A_A^A\_^
@SUVWAUAVAWH
L$8I;
L$XH3
`A_A^A]_^][
@SUVWAVAWH
(A_A^_^][
(A_A^_^][
\$ UVWATAUAVAWH
d$PE3
\$ E3
(D$ f
pA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
H#U0H
0A_A^A]A\_^]
d$ E3
H#U0H
(D$ f
H#}0H
t$ WH
UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
UVWATAUAVAWH
UUUUUUU
M;F u
E0H#D$0H
(D$ f
E0H#D$0H
@A_A^A]A\_^]
UVWATAUAVAWH
D$@fH
D$ H;
H;|$ 
A_A^A]A\_^]
UVAVH
PA^^]
PA^^]
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
t$ WATAUAVAWH
UUUUUUU
(D$ f
UUUUUUU
A_A^A]A\_
@SUVWATAUAVAWH
XA_A^A]A\_^][
l$ VWAVH
0A^_^
@SUVWAVAWH
hA_A^_^][
t$ WH
t$ WH
t$ WH
L$8H3
@SUVWH
8_^][
VWAVH
L$ H3
0A^_^
S H+S
l$ VWAVH
UUUUUUU
@A^_^
|$ UH
T$pH+
UVWAVAWH
\$XE3
 A_A^_^]
UVWATAUAVAWH
\$pE3
D$@H;
HcB H
HcAPH
HcA8H
D$8I;
H9D$8
HcAhH
HcA I
A_A^A]A\_^]
|$ ATAVAWH
 A_A^A\
SUVWAVH
 A^_^][
|$8E3
\$HE3
t$ WH
t$8H+
\$ VH
l$8H+
l$ VH
\$ UVWH
t$PH;
@USVWATAUAVAWH
T$ E3
D$ L;
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
UUUUUUU
\$ UVWAVAWH
T$8H+
L$@H3
PA_A^_^]
\$ WH
L$8H3
@SVWH
t$ WH
\$ WH
L$8H3
t$ WH
l$ VWAVH
L$PH3
@USVWATAUAVAWH
H8H+H0H
A_A^A]A\_^[]
\$ UVWATAUAVAWH
(L$@f
A_A^A]A\_^]
@USVWATAUAVAWH
8v6H+U
|$PE3
A_A^A]A\_^[]
l$ VWAVH
\$ UVWH
L$0H3
\$ UVWATAUAVAWH
D$@L+
tZI90t
H;D$hM
t$PI;
T$0I9
|$0I;
T$0I;
|$0I;
l$0H;
D$0H;
|$0I;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
t$ WH
AVAWH
(A_A^
\$ UVWATAUAVAWH
D$HM;
 H;|$@
t$@E3
D$PI;
 H;|$p
|$pH+
\$PL+
(D$pf
(L$Pf
A_A^A]A\_^]
@USVWATAUAVAWH
A0H;L$(
A_A^A]A\_^[]
@SUVWATAUAVAWH
L9yXuNA
e(D+e0D
)D$@L
A_A^A]A\_^][
l$ VWAVH
\$ UVWATAUAVAWH
L$pH;
D$0HcK,
|$0L;
D$8HcK(
D$hH;D$pt
A_A^A]A\_^]
@SVWATH
d$HI;
D$ H;V
L$hH3
xA\_^[
t$ WAVAWH
L$0H3
@A_A^_
@USVWATAVAWH
`A_A^A\_^[]
(HcA(
t$ WH
\$ UVWATAUAVAWH
d$ ff
d$ E3
D$0H;
A_A^A]A\_^]
\$ UVWATAUAVAWH
T$PE3
|$ E3
D$pHcH
D$pHcH
D$xE3
D$(L;
D$pHcH
D$pHcH
A_A^A]A\_^]
|$ AVH
@SVWH
\$ UVWATAUAVAWH
|$ H;
PA_A^A]A\_^]
t$ WH
t$ WH
t#Hc@(
@USVWATAUAVAWH
d$PL;
A_A^A]A\_^[]
@SVWATAUAVAWH
C\$XH
C\$XH
A_A^A]A\_^[
@SUVWATAVAWH
0A_A^A\_^][
t$ WATAUAVAWH
L$pE3
L$xH;
\$xH;
l$xI;
UUUUUUU
KH;|$@t
A_A^A]A\_
UVWATAUAVAWH
A_A^A]A\_^]
|$ UATAUAVAWH
HcB8H
HcBPH
H;t$ht
HcAhH
F0H;Q
D$8I;
A_A^A]A\]
\$ UVWATAUAVAWH
|$XM;
L$HH;
L$HH;
|$XM;
L$@ H
L$@@L
L$HH;
A_A^A]A\_^]
(D$ f
t$XH;
|$ AVH
|$ UATAUAVAWH
L;t$0t
T$PH;
L$PL;
L;t$0t
T$PH;
|$@M;
|$@I;
A_A^A]A\]
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWAVAWH
A_A^_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWAVAWH
8A_A^_^][
@SVWAVAWH
\$0E3
uPA9A(t)H
A_A^_^[
@SVWH
L$pH3
UVWATAUAVAWH
)L$`L
H;\$0
H;\$0
H;Mxt.I
A_A^A]A\_^]
@SVWH
L$8H3
UVWATAUAVAWH
A_A^A]A\_^]
Q(+Q0
@SUVWATAVAWH
A_A^A\_^][
UVWATAUAVAWH
d$0I;
IcE8H
\$0H;
A_A^A]A\_^]
L9s }
t$ WH
uBfff
D$ L;
L$HH3
t$ WH
t$8H;
L$XH3
@USVWAVH
A^_^[]
@USVWATAUAVAWH
T$HH;
A_A^A]A\_^[]
)D$0H
T$@H;
UWAVH
L$ H;
@SUVWAVH
o(+o0
@8wPt
L$8I+
L$PI+
L$XH3
`A^_^][
@SUVWAVH
T$8H+
L$@H3
PA^_^][
@USVWATAUAVAWH
H;|$Pu
H;D$0
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
I+E8H
U(A+U0A
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
I+E8H
}(E+}0E
U(A+U0A
U(A+U0A
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
I+E8H
u(E+u0E
U(A+U0A
U(A+U0A
U(A+U0A
M(A+M0A
I+E8H
U(A+U0A
M(A+M0A
I+E8H
](A+]0A
A8EPt
E(A+E0A
A_A^A]A\_^[]
@USVWATAUAVAWH
H+F8H;
|$Xff
V(+V0
N(+N0
H+F8H
V(+V0
H+F8H
^(+^0
A_A^A]A\_^[]
UVWATAUAVAWH
H#E@H
H;t$0t
|$@I;
C0H;U
D$0H+
\$8E3
D$0H+
A_A^A]A\_^]
l$ VWATAVAWH
A_A^A\_^
\$ WH
L$`H3
\$ UVWATAUAVAWH
W H+W
UUUUUUU
(D$@f
(D$Pf
D$PI;
A_A^A]A\_^]
l$ VWAVH
 A^_^
L$(H3
UVWATAUAVAWH
HcB8H
T$0L;
L9t$Hu
A_A^A]A\_^]
UVWAVAWH
tEfff
A_A^_^]
d$hH;
t$8H;
UVWATAUAVAWH
|$hL;
C\$hH
H;0uoA
A_A^A]A\_^]
WAVAWH
0A_A^_
UVWATAUAVAWH
d$ L;
L$PH3
`A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
D$ E3
H;{HtdH
D$@E3
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
|$0L;
t$0L;
t$0L;
@SVWATAUAVAWH
UUUUUUU
H#D$HH
|$hE3
|$`E3
(D$`f
H#D$HH
H;D$X
D$HH#
UUUUUUU
(D$`f
H;D$X
UUUUUUU
H;D$X
\$HI;
A_A^A]A\_^[
|$ AVH
l$ WAVAWH
t$HH+
 A_A^_
@SVATAVAWH
l$XH+
 A_A^A\^[
l$ VAVAWH
|$HH+
 A_A^^
@SAUH
I#E0M
L;d$ u
H;t$ 
t$ WH
t$ WH
UUUUUUU
t$ E3
t$8H+
@SVWH
H#C0H
H9t$xu>M
9H9t$xu
H#A0H
UAVAWH
I#F0H
H;|$0tHH;
L9|$(u
PA_A^]
L9|$(u
I#F0L
UVAVH
H#E0H
H;|$(t
L9t$ uzI
uL9t$ u
H#E0L
PA^^]
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
O(+O0
8OPtk
H+G8H
G(D+G0D
|$8H;
H#F0H
H9l$(u
H9l$(u
H#F0H
\$Hff
VWAVH
L$0H3
@A^_^
t$ WH
WpH;Wxt
SVWATAUAVAWH
L$0I+
`A_A^A]A\_^[
`A_A^A]A\_^[
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
UWATAVAWH
t$ E3
A_A^A\_]
UVWATAUAVAWH
L$XH+
A_A^A]A\_^]
\$ UVWATAUAVAWH
T$(E3
J0;K0
A_A^A]A\_^]
VWATAVAWH
T$(E3
@A_A^A\_^
\$ UVWATAUAVAWH
T$(E3
J0;K4
A_A^A]A\_^]
@SUVWATAVAWH
MXH;MX
V8H;V8tiH
D$ H9
@A_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@SVWATAUAVAWH
D9p }
D$0D9p }
)D$`L
D$xH;XX
D$09H }
;J }wH
)D$`L
A_A^A]A\_^[
@SUVWAVH
T$0E3
L$8H3
@A^_^][
VWAVH
L$(H3
0A^_^
l$ VWAVH
H9Y0t
9{ ~h
@A^_^
t$ WAVAWH
MXH9MXt
0A_A^_
AUAVH
I#E0H
tEfff
L$0H3
hA^A]
H#C0E3
t$ WATAUAVAWH
(D$ f
A_A^A]A\_
\$ UVWATAUAVAWH
T$@H;
T$@H;
T$@H;
I+VHH
I+VHH
l$0I;
A_A^A]A\_^]
t$@H;
T$ tMH
L$(H3
|$ AVH
Fp;Gpt
VWAVH
0A^_^
H+C8H
C(D+C0D
VWAVH
L$xE3
@SVWAVAWH
L$xE3
A_A^_^[
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
\$ VWAVH
L$0E3
D$PH;
L$`H3
pA^_^
\$ UVWATAUAVAWH
3333333
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
3333333
d$8E3
(D$ f
PA_A^A]A\_^]
@SUVWAVAWH
HA_A^_^][
\$ UVWATAUAVAWH
t$DE3
IcD$8H
D8D$@t
H;D$P
IcD$hH
D$XH;
A_A^A]A\_^]
\$ UVWATAUAVAWH
D$XE3
l$DE3
d$HE3
A_A^A]A\_^]
UWATAVAWH
t$ E3
A_A^A\_]
@SVWAVH
A^_^[
@USVWAVH
A^_^[]
@USVWATAUAVAWH
D$`E3
A_A^A]A\_^[]
UVWATAUAVAWH
)D$`H
A_A^A]A\_^]
\$ UVWH
@USVWATAUAVAWH
IcE H
v D+v0D
V +V0
N +N0
H+F8H
V +V0
H+F8H
~ +~0
v(D+v0D
V +V0
V +V0
V +V0
N +N0
H+F8H
V +V0
H+F8H
^ +^0
F(+F0
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
A_A^A]A\_^[]
UVWATAUAVAWH
|$hL;
A_A^A]A\_^]
T$`H;
|$ UH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
t$ WH
VWAVH
L$xH3
\$HE3
\$PE3
t$ WH
@ 9A 
G 9A 
VWAVH
VWAVH
L$HE3
l$PE3
UWAVH
D$`E3
|$ UAVAWH
A_A^]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
A_A^A]A\]
T$`H;
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
T$`H;
UWAVH
D$PE3
UWAVH
UWAVH
D$`E3
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
VWAVH
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
A_A^A]A\]
VWAVH
(D$ H
t$ UWAVH
@ 9p 
T$0H;T$8t
T$8H+
L$@H3
UVWATAUAVAWH
A_A^A]A\_^]
u-A9P(t[H
u:A9P(t)H
UWAVH
|$ UH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UAVAWH
A_A^]
L$0H3
UVWATAUAVAWH
D$ E3
A_A^A]A\_^]
|$ UH
U/H;U7
@USVWAVH
A^_^[]
D$xE3
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
|$ UH
UWAVH
UWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UH
|$ UH
|$ UH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
USVWH
UWAVH
|$ UATAUAVAWH
D$`E3
A_A^A]A\]
|$ UH
UWATAVAWH
A_A^A\_]
|$ UH
USVWH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UH
UWAVH
D$PE3
|$ UH
UWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
USVWH
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
|$ AVH
 HcD$PI
SVWATAUAVAWH
D$0H+
L+d$HI
`A_A^A]A\_^[
`A_A^A]A\_^[
@SUVWATAVAWH
D$ L;
L$@H3
PA_A^A\_^][
l$ VWAVH
T$ E3
|$HE3
D$(H;
L$XH3
UVWATAUAVAWH
l$ E3
A_A^A]A\_^]
|$ UAVAWH
A_A^]
t$ WH
VWAUAVAWH
A_A^A]_^
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
UVWATAUAVAWH
@ Hc@ H
A_A^A]A\_^]
D$HE3
VWAVH
@A^_^
t$ WH
VWAVH
D$@E3
D$ E3
UWAVH
T$8H+
L$XH3
VWATAVAWH
@A_A^A\_^
t$ WATAUAVAWH
|$ A;
A_A^A]A\_
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
L$ E3
T$pH;T$xt
D$xH+
A_A^A]A\]
L$8H+
D$`I+
D$`I+
T$HH+
L$hH3
@USVWATAUAVAWH
A_A^A]A\_^[]
|$ UATAUAVAWH
A_A^A]A\]
D9}H~f
D$(I;
D$(H+
D$(H+
D$0H+<
@USVWAVH
E0H9E
T$hH;T$pt
D$pH+
A^_^[]
SUVWH
x 9K(u
UWAVH
UWAVH
|$ UH
|$ UATAUAVAWH
D$hE3
A_A^A]A\]
|$ UATAUAVAWH
D$hE3
A_A^A]A\]
|$ UH
|$ UH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
L+|$PI
A_A^A]A\]
@SUVWATAVAWH
A_A^A\_^][
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
\$ Mk
>HkL$88H
PA_A^A]A\_^[
\$ UVWATAUAVAWH
@A_A^A]A\_^]
k VWATAVAWH
A_A^A\_^
D$0L;I
UVWATAUAVAWH
(D$Pf
A_A^A]A\_^]
@SUVWAVH
L$@H3
PA^_^][
@SUVWAVAWH
D$8H+
L$@H3
XA_A^_^][
\$ UVWATAUAVAWH
D$0H;
(D$@f
L$(H;L$0
T$pH+
T$pH+
A_A^A]A\_^]
|$ UAVAWH
A_A^]
\$ UVWH
@SUVWAVH
 A^_^][
s WATAUAVAWH
D$PH+
r6w4HcC(H
|$`H+
\$0fff
|$`H+
L$pH+
L$xH3
A_A^A]A\_
@SWAUAVAWH
HcK,I
0A_A^A]_[
UVWATAUAVAWH
\$ L;
C(A9E
(D$@f
(D$`f
L;l$0
A_A^A]A\_^]
L$0H3
L$0H3
UVWAVAWH
A_A^_^]
tbD;H,t_L
WAVAWH
 A_A^_
l$ VWAVH
L$(E3
l$ VWAVH
L$(E3
UVWAVAWH
L$(E3
HcC(H;
pA_A^_^]
t$ WH
L$8H3
@SUWAVH
(D$0f
D$0H;
L$@H3
XA^_][
\$ UVWH
L$ H+
L$8H3
tbD9H(t_L
)D$ f
VWATAVAWH
(D$ H
(t$@L
(|$0I
A_A^A\_^
)D$ f
;ai.ou{f
)D$ f
)D$ f
@SUVWAVH
l$8H;
L$HH3
PA^_^][
\$ UVWAVAWH
|$8H;
L$HH3
PA_A^_^]
L$(H+L$ H
L$8H3
x UATAUAVAWH
A_A^A]A\]
UVWAVAWH
D$@Mc
D$8H9D$0
\$0H;
L$HH3
PA_A^_^]
L$XL;
@SUVWAVH
\$ I;
L$8H3
@A^_^][
UVWATAUAVAWH
(D$`f
\$8L;
D9`,I
A_A^A]A\_^]
H+K8H
C D+C0
@SUVWAVAWH
\$(H+\$ H
H+F8H;
T$0H+
L$@H3
XA_A^_^][
@SUVWATAVAWH
t$0L+t$(I
W(+W0
O(+O0
H+G8H
W(+W0
H+G8H
G(+G0
T$8H+
L$HH3
PA_A^A\_^][
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
SVWATAUAVAWH
vb'vb'v
D$ E3
D$ E3
@A_A^A]A\_^[
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
@SWAVH
k(+k0
8KPtwL
H+C8H
C(D+C0D
@8{Ptt
H+C8H
C(D+C0D
 A^_[
UVWATAWH
D+b0L
M +M0
8MPtm
H+E8H
E D+E0D
M +M0
8MPtk
H+E8H
E D+E0D
 A_A\_^]
@SWATAUH
O +O0
H+G8H
H+G8H
O(+O0
H+G8H
G(D+G0D
XA]A\_[
UVWATAUAVAWH
(D$@f
|$0E3
A_A^A]A\_^]
\$ UVWATAUAVAWH
H;t$0t
D$0H+
A_A^A]A\_^]
@SUVWAVH
d$pH;
0A^_^][
0A^_^][
@SUWAVH
T$ E3
H#E0H
8A^_][
@USVWATAUAVAWH
_(+_0
D8wPt
D8oPt
FXL+FPI
A_A^A]A\_^[]
@USVWATAUAVAWH
I+N H
A_A^A]A\_^[]
l$ WAVAWH
t$HH+
 A_A^_
VWAVH
@A^_^
VWAVH
vb'vb'v
 A^_^
UAVAWH
I#F0H
H;|$0tHH;
L9|$(u
PA_A^]
L9|$(u
I#F0L
T$ t(H
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@SVWATAUAVAWH
PA_A^A]A\_^[
t$ WATAUAVAWH
)t$PH
)|$@r
(D$0H
(t$PL
(|$@I
A_A^A]A\_
@SUVWATAUAVAWH
(D$ f
XA_A^A]A\_^][
|$ ATAVAWH
H#E0H
 A_A^A\
UVWATAUAVAWH
)t$pI
)|$`H
(D$ H
(|$`H
A_A^A]A\_^]
UVWATAUAVAWH
)t$pI
)|$`H
(D$ H
(|$`H
A_A^A]A\_^]
@SUVWATAUAVAWH
XA_A^A]A\_^][
@SUVWAVH
0A^_^][
|$ AWH
USVWATAUAVAWH
S H+S
d$`L;
~Dfff
d$`I;
D$pH;
H;|$pL
D$pH;
H;|$p
D$`H;
D$`I;D$
HcH0H
D$`I;D$
D$`I;D$
HcH0H
D$`H;
D$`I;D$
l$`H;
D$`I;D$
D$`I;D$
D$`H;
D$`I;
IcM0H
D$`I;D$
R0IcM0H
P0IcM0H
D$`H;
HcPPH
|$pI;~
)D$`L
A_A^A]A\_^[]
@USVWATAUAVAWH
I+VHH
I+V`H
L$XH;
A_A^A]A\_^[]
@USVWATAUAVAWH
Hc@PH
t+H;O
D$8H;H
L$ H;V
D$@H;H
A_A^A]A\_^[]
@SVWH
@8,:|
\$ UVWATAUAVAWH
A_A^A]A\_^]
L$0H;
USVWATAUAVAWH
IcEhH
McEhM
IcEhL
|$XLcD$TH
D$hL;
|$XHc\$pH
H#D$xHk
H#L$xH
LcD$TL
\$XLcD$TH
\$XHc\$pH
H#D$xHk
H#L$xH
LcD$TL
Ic@PH
A_A^A]A\_^[]
@USVWATAUAVAWH
UUUUUUU
tqfff
IcFhL
IcEPH
d$hM;l$
A_A^A]A\_^[]
UVWATAUAVAWH
HcB H
tAI;V
HcBPH
A_A^A]A\_^]
t$8H+
@SVATH
L$pH3
GXH;GXu
l$ VWAVH
|$ AVH
t$ E3
t$ WH
H;S8v
(t$ H
l$ WATAUAVAWH
0A_A^A]A\_
VWATAVAWH
0A_A^A\_^
)t$ f
(t$ u
l$ VWATAVAWH
)t$@H
l$0H;
l$0Hc
L$8H3
(t$@I
A_A^A\_^
l$ VWATAVAWH
t$0H;
t$0Hc
L$8H3
A_A^A\_^
|$ AVH
H+K8H;
@USVWATAUAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A]A\_^[]
@SUVWAVH
T$0H+
L$8H3
@A^_^][
@SUVWATAVAWH
t$0L+t$(I
W +W0
O +O0
H+G8H
W +W0
H+G8H
G +G0
T$8H+
L$@H3
PA_A^A\_^][
@USVWATAUAVAWH
A_A^A]A\_^[]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
^(+^0
^(+^0
^(+^0
~(D+~0D
V(+V0
N(+N0
8NPtk
H+F8H
F(D+F0D
~(+~0
V(+V0
N(+N0
8NPtm
H+F8H
F(D+F0D
H+N8H;
F(+F0
^(+^0
^(+^0
HcGXH
V(+V0
N(+N0
H+F8H
V(+V0
H+F8H
^(+^0
A_A^A]A\_^[]
@USVWATAUAVAWH
~(E+~0E
V(A+V0A
N(A+N0A
I+F8H
I+F8H;
V(A+V0A
N(A+N0A
A8NPtk
I+F8H
F(E+F0E
A_A^A]A\_^[]
@SUVWATAVAWH
w(D+w0D
O(+O0
8OPtk
H+G8H
G(D+G0D
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
L$@H3
PA_A^A\_^][
H+C8H
C(D+C0D
(t$ H
O(+O0
8OPtk
H+G8H
G(D+G0D
UVWATAUAVAWH
VUUUUUUUH
A_A^A]A\_^]
UWATAVAWH
A_A^A\_]
)t$@H
L$8H3
(t$@H
VWAUAVAWH
A_A^A]_^
|$ UATAUAVAWH
A_A^A]A\]
t$ WATAUAVAWH
A_A^A]A\_
@USVWATAUAVAWH
A_A^A]A\_^[]
t$ WH
@SUVWAVAWH
XA_A^_^][
)D$ A
)L$0A
\$ UVWATAUAVAWH
D$@H+
A_A^A]A\_^]
@SLcT$pLc\$XHc\$HL
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
t$ WH
L$hH3
@UVATAWH
l$8M9L$
L$(fH
T$(H+
T$HE3
A_A\^]
@SVWATAUAVAWH
L$(H3
@A_A^A]A\_^[
@SVWATAUAVAWH
L$(H3
@A_A^A]A\_^[
l$ AVL
l$(A^
l$(A^
l$ AVL
l$(A^
l$(A^
@UWAVH
e`A^_]
@UAVAWH
A_A^]
@UAVAWH
A_A^]
t$ UWAVH
t$ UWAVH
@SUVWAVH
Authu
entiu
cAMDt
AMDiuE
sbetu=
ter!u53
0A^_^][
UVWATAUAVAWH
t$0L;
A_A^A]A\_^]
@SUVATAUAVAWH
A_A^A]A\^][
UVWATAUAVAWH
|$xL+
D$PH+
t$0H;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
t$(L;
t$(L;
@VWAVH
|$0ff
t$ H;
\$pI;
PA^_^
ATAVAWH
\$0M;
A_A^A\
\$8H;
H9l$@}
t$(H;
|$PM;
\$ WH
BA99u
@USVWAVH
A^_^[]
A^_^[]
@UVWATAUAVAWH
A_A^A]A\_^]
@UVWATAUAVAWH
A_A^A]A\_^]
WATAUAVAWH
L$(E3
L+d$0
L+l$0L
T$(L+
$L;l$P
|$8I;
|$8I;
A_A^A]A\_
AUAVAWH
D$ L;T$8
L;T$X
$$L;T$`
L;T$h
l$pM;
\$(L;
A_A^A]
WATAUAVAWH
L$8E3
H+L$ f
l$ L;
L+\$ I
$L;t$8
D$XL+
l$XL;t$`
L;t$h
l$0L;t$h
L;t$p
d$pM+
A_A^A]A\_
@SVAVH
D$PfE
|$(I+
L;\$P
L;\$`
L;\$h
L;\$p
H+D$8
L;\$x
|$(I+
L;\$@
t$0L;
L;\$@
L$XL;
WATAUAVAWH
T$ I;
L+,$L+
T$ L;l$0
L+4$H
l$8I;
0L+4$L+
L;l$H
L$(I;
t$PL;l$H
A_A^A]A\_
AUAVAWH
D$ L;T$8
L;T$X
$$L;T$`
L;T$h
l$pM;
\$(L;
A_A^A]
L$hH3
@SVWATAVAWH
L+KxM
H;s8uuH
A_A^A\_^[
H+SxH;
H+kxH
@SVWATAUAVAWH
H+CxH+
H;{8u
A_A^A]A\_^[
UVWAVAWH
L$PH;
H9L$pt
A_A^_^]
|$ ATAVAWH
A_A^A\
@SUWATAVH
L$8H+
A^A\_][
@SUWATAVH
`A^A\_][
@SVWAVH
)t$pH
D$@L;
t$XM;
T$ M;
(t$pH
A^_^[
@SVWAVH
D$hH;
A^_^[
@SVAVAWH
t$(H+
D$ H;
t$pL+
|$xL+
d$@H;
T$(H;
A_A^^[
\$ UVWATAUH
@A]A\_^]
SUVWATAUAVAWH
H+L$ A
D$ L+
8A_A^A]A\_^][
UVWATAUAVAWH
D$hfff
A_A^A]A\_^]
)l$ D
(l$ L
)l$ D
(l$ L
)l$@D
)t$0D
)|$ I
(t$0L
(|$ I
@SVWH
T$ L;
L$PH3
UVWATAUAVAWH
)|$PH
L$@H3
(|$PH
pA_A^A]A\_^]
)l$ D
(l$ D
(d$0D
(\$@D
(T$PD
(L$`D
)l$ D
(l$ L
)t$PI
)L$ D
(L$ A
(D$0A
(|$@I
@USVWATAUAVAWH
L;D$pH
CD$pE3
t$0E3
A_A^A]A\_^[]
SUWAUAVH
D$pH;
A^A]_][
UVWATAUAVAWH
D$HE3
L+d$ M
L;d$0
L;D$PuGH
H;D$Xu
A_A^A]A\_^]
UAVAWH
l$(I;
A_A^]
SVWAUAVAWH
L$ H+
HA_A^A]_^[
HA_A^A]_^[
C(H9C@u,H
HA_A^A]_^[
HA_A^A]_^[
HA_A^A]_^[
UVWATAUAVAWH
H+D$HL
D$XL+t$8L
L$hM;
L;t$p
A_A^A]A\_^]
VATAUAVAWH
A_A^A]A\^
VWAUAVAWH
l$@A_A^A]_^
VWATAUAVH
D$hE3
A^A]A\_^
VWATAVAWH
A_A^A\_^
UVWATAUAVAW
T$pH;
A_A^A]A\_^]
UVWATAUAVAW
T$ I;
A_A^A]A\_^]
WATAUAVAWH
A_A^A]A\_
WATAUAVAWH
HL$`L;
D$ fff
A_A^A]A\_
UVWATAUAVAW
A_A^A]A\_^]
UVWATAUAVAW
l$hL+
T$pL;
A_A^A]A\_^]
T$PH;
@USVATAUAVAWH
\$@H+
L$HH+
L$!I;
L$ E3
T$ L9
L$h@"
A_A^A]A\^[]
UVWATAUAVAWH
T$pH;
A_A^A]A\_^]
UWATAUAWH
D$`H;
0A_A]A\_]
UVWATAUAVAW
zcuaA
z\uZA
A_A^A]A\_^]
UVWATAUAVAW
T$heL
T$heL
A_A^A]A\_^]
@SUVWATAUAVAWH
A0t>H
xA_A^A]A\_^][
UVWATAUAVAWH
)d$pD
)l$`D
)t$PI
L$ Hk
(t$PI
A_A^A]A\_^]
)t$0I
(t$0H
L$0H3
USVWATAVAWH
A_A^A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SUVWATAUAVAWH
A_A^A]A\_^][
SATAUAWH
|$pI;
A_A]A\[
ATAUAWH
|$pI;
 A_A]A\
SATAUAWH
|$pI;
A_A]A\[
@UAUAVAWH
A_A^A]]
ATAUAWH
|$pI;
 A_A]A\
t$ WAVH
t$0A^_
@UAUAVAWH
A_A^A]]
t$ WAVH
t$0A^_
A(tzA
UVWATAUAVAW
A_A^A]A\_^]
m8fff
@SUVWATAUAVAWH
D$ M+
|$poH
A_A^A]A\_^][
UVWATAUAVAWH
)t$@I
D$8Ik
k fff
(t$@M
D$8H+
L$(L+
PA_A^A]A\_^]
UVWATAUAVAWH
T$`H;
A_A^A]A\_^]
L$ L;
D$XH;
@USVWATAUAVAW
D8R1u
} fff
A_A^A]A\_^[]
VWATAVAWH
0A_A^A\_^
UWATAUAVH
|$xE3
 A^A]A\_]
@UVAUH
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
A4XH 
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
A4XH 
A4XH 
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
b},4C
b}.<C
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
ba|H(
ba|H(
ba|H(
ba|H(
QbreH
SbreH
VbbeH
|H(L"
|H(L"
QbreH
SbreH
VbbeH
@bq|H
6bA|H
@bq|I
>bA|I
ba|H(
ba|H(
Qbr}X
Qbr}X
|H(L"
|H(L"
QbreH
|H(L"
|H(L"
QbreH
@bq|H
@bq|I
Qbr}X
Qbr}X
QbreH
SbreH
|H(L"
|H(L"
QbreH
SbreH
@bq|H
@bq|I
Qbr}X
Qbr}X
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
QbreH
|H(L"
|H(L"
QbreH
QbreH
|H(L"
|H(L"
QbreH
@bq|H
@bq|I
Qbr}X
Qbr}X
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
A5XH 
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
A5XH 
A5XH 
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
b}-4C
b}/<C
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVWAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A__^[]
HUSVH
)D$ H
A|U@ 
(D$ H
HUSVH
HUSVWATAUH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
~oL$ I
~o] I
~oL$ I
~o] I
~oL$ I
~o] I
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A]A\_^[]
~oL$ I
~o] I
~oL$ I
~o] I
~oL$ I
~o] I
HUSVWH
HUSVWATAUAVH
br}H{
~HoD$
bReX@3b
]X@#bQ}H
breHQ
~HoT2
breHQ
~HoT2
breHQ
~HoT2
breHQ
breHQ
~HoT2
~HoT2
~HoT2
0bQ~I
bReX@3bQ}H
breHQ
breHQ
breHQ
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
#bAmX
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
~HoL2
~HoTr
~HoL2
~HoTr
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
#bQ}X
breHQ
breHQ
~HoT2
breHQ
breHQ
~HoT2
breHQ
breHQ
~HoT2
breHQ
breHQ
breHQ
breHQ
~HoT2
~HoT2
~HoT2
0bQ~I
bReX@3bQ}H
bReX@{
3bQ}X
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
'bQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
bbeHQ
breHQ
bbeHQ
breHQ
~HoL2
~HoTr
~HoL2
~HoTr
~HoL2
~HoTr
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
(bQ}X
#bQ}X
breHQ
breHQ
@bQ~I
0bQ~I
bReX@3bQ}H
bReX@{
3bQ}X
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
<bQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
$@bA~H
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
6bQ}X
#bQ}X
breHQ
breHQ
~HoT2
breHQ
breHQ
}HX\I
~HoT2
breHQ
breHQ
}HX\I
~HoT2
breHQ
breHQ
}HX\I
breHQ
breHQ
~HoT2
}HX\I
~HoT2
}HX\I
~HoT2
}HX\I
0bQ~I
bReX@3bQ}H
bReX@{
3bQ}X
breHQ
breHQ
breHQ
breHQ
}HX\I
breHQ
breHQ
}HX\I
breHQ
breHQ
}HX\I
breHQ
breHQ
}HX\I
}HX\I
}HX\I
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
bBUX@k
QbQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
~HoL2
~HoTr
}HX\I
~HoL2
~HoTr
}HX\I
~HoL2
~HoTr
}HX\I
+bA~H
$@ba~H
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
bB]X@C
DbQ}X
#bQ}X
breHQ
breHQ
bbeHQ
;ba=@
;ba~H
0bQ~I
bReX@3bQ}H
bReX@{
"bQ}X
3bQ}X
breHQ
breHQ
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
bBUX@k
bB]X@C
bBUX@s
fbQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
bbeHQ
bbeHQ
u!bA-@
$@ba~H
+ba~H
~HoD$
bReX@3b
]X@#bQ}H
bReX@{
bB]X@C
bB]X@K
RbQ}X
#bQ}X
breHQ
breHQ
bbeHQ
KbbeHQ
~HoT2
breHQ
breHQ
}HX\I
bbeHQ
}HX\K
bbeHQ
~HoT2
breHQ
breHQ
}HX\I
bbeHQ
}HX\K
bbeHQ
~HoT2
breHQ
breHQ
}HX\I
bbeHQ
}HX\K
bbeHQ
breHQ
breHQ
bbeHQ
KbbeHQ
~HoT2
}HX\I
}HX\K
~HoT2
}HX\I
}HX\K
~HoT2
}HX\I
}HX\K
;ba=@
;ba~H
CbQ~I
0bQ~I
bReX@3bQ}H
bReX@{
)bQ}X
3bQ}X
breHQ
breHQ
breHQ
breHQ
}HX\I
}HX\K
breHQ
breHQ
}HX\I
}HX\K
breHQ
breHQ
}HX\I
}HX\K
breHQ
breHQ
}HX\I
}HX\K
}HX\I
}HX\K
}HX\I
}HX\K
~HoL$
~HoD$
bReX@3b
]X@#bBUX@
bReX@{
bBUX@[
bBUX@c
bBUX@k
bB]X@C
bBUX@s
bB]X@K
bBUX@{
{bQ}X
#bAmX
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
bbeHQ
bbeHQ
KbbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
bbeHQ
}HX\K
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
bbeHQ
}HX\K
bbeHQ
bbeHQ
~HoL2
~HoTr
bbeHQ
breHQ
bbeHQ
breHQ
}HX\I
bbeHQ
bbeHQ
bbeHQ
bbeHQ
}HX\K
bbeHQ
bbeHQ
bbeHQ
breHQ
bbeHQ
breHQ
IbbeHQ
bbeHQ
bbeHQ
bbeHQ
KbbeHQ
bbeHQ
~HoL2
~HoTr
}HX\I
}HX\K
~HoL2
~HoTr
}HX\I
}HX\K
~HoL2
~HoTr
}HX\I
}HX\K
u(bA-@
<CbA~H
$@ba~H
+ba~H
(|$ H
0A^A]A\_^[]
HUSVWH
bb}H{
bb}HX'H
w_^[]
bb}HX
HUSVWH
bb}HX'H
w_^[]
bb}HX
HUSVWH
)D$ D
)L$0D
)T$@H
(D$ D
(L$0D
(T$@H
X_^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
fffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffff
fffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
ffffff
fffffff
A<X@@
fffffff
A<X@@
A<X@@
A<X@@
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffff
ffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffffff
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
$IbB}H
<Nba|H
$Iba|H
IbR=P
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
fffffff
rbb}H
rbb}H
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
$IbB}H
<Nba|H
$Iba|H
IbR=P
$Nba|H
Iba|H
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
2bb}H
rbb}H
rbb}H
3bb}H
HUSVWAWAVAUATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
IbR=@
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A]A^A__^[]
HUSVWAVATH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
3bb}H
rbb}H
$IbB}H
<Nba|H
rbb}H
$Iba|H
rbb}H
rbb}H
$IbB}H
<Nba|H
$Iba|H
2bb}H
IbR=P
$Nba|H
Iba|H
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A\A^_^[]
bQ<HX@
bQ<@_
bQ<HX@
t*ba|H
bQ<@_
bQ<@_
fffff
fffff
t%ba|H
!ba|H
bQ<HX@
bQ4HXL
t1ba|H
!ba|H
bQ<@_
bQ<@_
bQ<HX@
bQ4HXL
tUba|H
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
t8ba|H
!ba|H
ffffff
bQ<HX@
bQ4HXL
bq,HXS
tJba|H
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<HX@
bQ4HXL
bq,HXS
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
fffff
tKba|H
!ba|H
bQ<HX@
bQ4HXL
bq,HXS
bq$HX\
tcba|H
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<HX@
bQ4HXL
bq,HXS
bq$HX\
!ba|H
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
bQ<@_
HUSVWAVAUATH
A\A]A^_^[]
HUSVWAVAUATH
A\A]A^_^[]
HUSVWAVAUATH
A\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
HUSVWAVAUATH
wA\A]A^_^[]
fffffff
HUSVWAVAUATH
wA\A]A^_^[]
fffff
HUSVWAVAUATH
*l$hb
wA\A]A^_^[]
@UVAVH
)|$0H
~T$ f
L$(H3
(|$0H
`A^^]
@UWAVAWH
)|$`D
)D$PH
)L$@D
)T$0H
~L$ H
~T$ H
(T$0f
L$(H3
(|$`D
(D$PH
A_A^_]
@UVAVH
)|$0H
~T$ f
L$(H3
(|$0H
`A^^]
@UWAVAWH
)|$`D
)D$PH
)L$@D
)T$0H
~L$ H
~T$ H
(T$0f
L$(H3
(|$`D
(D$PH
A_A^_]
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
b"-@,
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
USVWAVH
A^_^[]
USVWAVAWH
A_A^_^[]
USVWAVH
A^_^[]
USVWAVAWH
A_A^_^[]
)|$0D
)D$ L
bR}H|
)t$@H
(t$@I
(|$0D
(D$ D
)|$0A
)D$ D
bR}H|
)t$@H
(t$@I
(|$0D
(D$ D
)t$`I
x)D$@
x)L$0H
x)T$ Hk
$]Y`H
x(D$@
x(T$ 
x(L$0
ATAUAVH
)t$ M
@A^A]A\
ATAUAVH
)t$ M
@A^A]A\
ATAUAVH
)t$ M
@A^A]A\
ATAUAVH
|$ ff
0A^A]A\
UVWATAUAVAWH
x)T$`H
zoU H
A_A^A]A\_^]
UVWATAUAVAWH
x)T$`H
zoU H
A_A^A]A\_^]
UVWATAUAVAWH
x)T$`H
zoU H
A_A^A]A\_^]
UVWATAUAVAWH
x)T$`H
zoU H
A_A^A]A\_^]
@USVWATAUAVAW
D8R1u
EHfff
H;EpuSL
A_A^A]A\_^[]
@SVWAVH
)t$ H
(t$ H
8A^_^[
@SWAWH
(t$@L
L$ H3
PA__[
SUWATAUAVAWH
)T$PE
oD$8f
(T$PH
L$HH3
(D$pH
A_A^A]A\_][
@USVWATAUAVAW
D8R1u
H;EpuOL
A_A^A]A\_^[]
@USVWATAUAVAW
H;ExuLL
A_A^A]A\_^[]
SUATAVAWH
(t$@H
(|$0D
(D$ H
PA_A^A\][
@WAWH
(t$ L
@USVWATAUAVAW
D8R1u
uEL9RHu?E8U
u9E8U
A_A^A]A\_^[]
@USVWATAUAVAW
A_A^A]A\_^[]
@USVWATAUAVAW
D8Z1u
A_A^A]A\_^[]
@USVWATAUAVAW
H;ExuLL
A_A^A]A\_^[]
HUSVWATAUH
)|$PD
)D$`D
)L$pD
o|$0J
(|$PD
(D$`D
(L$pD
A]A\_^[]
HUSVWH
)|$PD
)D$`D
)L$pH
(|$PD
(D$`D
(L$pH
HUSVWATAUH
)|$PD
)D$`D
)L$pH
}0t$ 
}0|$0J
(|$PD
(D$`D
(L$pH
A]A\_^[]
HUSVH
HUSVWATAUH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`J
(D$ D
(L$0D
(T$@D
(\$PD
(d$`H
A]A\_^[]
HUSVWATAUH
)D$ D
)L$0D
)T$@D
)\$PJ
(D$ D
(L$0D
(T$@D
(\$PH
A]A\_^[]
HUSVWATAUH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A]A\_^[]
HUSVWATAUH
)D$ D
)L$0D
)T$@D
)\$PJ
(D$ D
(L$0D
(T$@D
(\$PH
A]A\_^[]
bQ|H[
bQ|H[
bq$HY
ba$@Y
bQ|H[
bQ|H[
bq,HY
ba,@Y
bQ|H[
bQ|H[
bq4HY
ba4@Y
o"bq=H
bQ|H[
bQ|H[
bq<HY
ba<@Y
bq$H_
ba$@_
bq$H]
ba$@]
bQ}H[
bQ}H[
bq,H_
ba,@_
bq,H]
ba,@]
bQ}H[
bQ}H[
bq4H_
ba4@_
bq4H]
ba4@]
bQ}H[
bQ}H[
bq<H_
ba<@_
bq<H]
ba<@]
bQ}H[
bQ}H[
$qbB~J
1bB~J
$0bR~J
HUSVWATAUAVAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
}HX"b
}HX$"b
}HX$*b
}HX$2b
}HX$:b
}HX"b
}HX$"b
}HX$*b
}HX$2b
}HX$:b
}HX"b
}HX$"b
}HX$*b
}HX$2b
}HX$:b
}HX"b
}HX$"b
}HX$*b
}HX$2b
}HX$:b
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A_A^A]A\_^[]
HUSVWATAUAVAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A_A^A]A\_^[]
HUSVWATAUAVAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
}HX"br]HQ
br]HQ
br]HQ
br]HQ
br]HQ
br]HQ
br]HQ
br]HQ
}HX$"b
}HX$*b
}HX$2bb]HQ
bb]HQ
bb]HQ
bb]HQ
}HX$:bb]HQ
bb]HQ
bb]HQ
bb]HQ
}HX"br]HQ
br]HQ
br]HQ
br]HQ
br]HQ
br]HQ
}HX$"b
}HX$*b
}HX$2bb]HQ
bb]HQ
bb]HQ
}HX$:bb]HQ
bb]HQ
bb]HQ
}HX"br]HQ
br]HQ
br]HQ
br]HQ
}HX$"b
}HX$*b
}HX$2bb]HQ
bb]HQ
}HX$:bb]HQ
bb]HQ
}HX"br]HQ
br]HQ
}HX$"b
}HX$*b
}HX$2bb]HQ
}HX$:bb]HQ
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A_A^A]A\_^[]
HUSVWATAUAVAWH
)D$ D
)L$0D
)T$@D
)\$PD
)d$`D
)l$pD
br}HQ
bruHQ
bb}HQ
bbuHQ
br}HQ
bruHQ
bb}HQ
bbuHQ
br}HQ
bruHQ
bb}HQ
bbuHQ
br}HQ
bruHQ
bb}HQ
bbuHQ
(D$ D
(L$0D
(T$@D
(\$PD
(d$`D
(l$pD
A_A^A]A\_^[]
WAVAWH
0A_A^_
VWAVH
0A^_^
UVWATAUAVAWH
d$ E3
d$ E3
|$ E3
|$ E3
A_A^A]A\_^]
t$HE3
UVWATAUAVAWH
A_A^A]A\_^]
@USVWAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
\$ UVWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
@USVWATAVAWH
D$0HcH
D$0HcH
D$0HcH
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$ HcH
D$ HcH
L$ HcQ
L$ HcQ
A_A^A]A\_^[]
VWATAVAWH
@A_A^A\_^
|$ AVH
SUVWH
L$0H3
t$ WH
T$ Ic
UVWAVAWH
A_A^_^]
L$0H3
UVAVH
\$ UVWATAUAVAWH
CL$(3
A_A^A]A\_^]
\$ UVWATAUAVAWH
CL$(3
A_A^A]A\_^]
L$(H3
t$ UWAVH
UVWAVAWH
A_A^_^]
t$ WH
T$0E3
CT$8H
T$HH;
CD$8H
C\$8H
L$XH3
@SUVWAVH
t"D85
A^_^][
HcD$\
L$xH3
UVWAVAWH
A_A^_^]
@USVWATAVAWH
|$pE3
CL$pL
CT$pH
L;E L
BE L+
A_A^A\_^[]
\$0H;
t$ UWAVH
t$pE3
CL$pH
CT$pH
L;E@L
BE@L+
UVWATAUAVAWH
th@8=j
@A_A^A]A\_^]
L$ SWH
T$hH+
UVWATAUAVAWH
A_A^A]A\_^]
|$ ATAVAWH
A_A^A\
WATAUAVAWH
t_fD9"tYH
fD9dB
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tgD8"tbH
D8$:u
tyfD9"tsH
fD9dB
tnD8"tiH
D8$:u
t\fD9"tV
fD9dj
 A_A^A]A\_
L$ VWAVH
`A^_^
`A^_^
t$ AWH
D$pHcH
D$pHcH
D$pHcH
D$pHcH
\$ UVWATAWH
t$`E3
 A_A\_^]
|$ AVH
L$0H3
\$ UVWATAUAVAWH
|$0I;
@A_A^A]A\_^]
@SVWATAUAVAWH
PA_A^A]A\_^[
SVWATAUAVAWH
L$XI+
H+T$HH
l$xL;|$@t
A_A^A]A\_^[
@SWATAVH
l$(E3
8A^A\_[
L$0I;
t$0ff
l$ VWATAVAWH
T$hE3
|$ H;
A_A^A\_^
A0H9A(u
VWATAVAWH
L$(E3
0A_A^A\_^
F0H9F(t
\$ UVWH
E'H;E/tBH
@USVWATAUAVAWH
9zv0H
D8t$0
D8t$0
D$8L+
A_A^A]A\_^[]
UVWATAUAVAWH
T$8E3
}0M+}(I
T$ E3
@A_A^A]A\_^]
l$ VAVAWH
|$HH+
 A_A^^
l$ VWATAVAWH
A_A^A\_^
L$(H3
L$ SH
L$xH3
t$ WH
l$ VWAVH
l$ VWAVH
@SVWATAUAVAWH
D$0I;
A_A^A]A\_^[
p WAVAWH
A_A^_
UVWATAUAVAWH
3333333
\$ E3
(D$ f
3333333
pA_A^A]A\_^]
t$ WH
UVWATAUAVAWH
T$(E3
H;D$(
\$0H;
A_A^A]A\_^]
UVWATAUAVAWH
D$PE3
H+\$ H
T$XH+T$PH
L$PH+
s~H;_
A_A^A]A\_^]
VWAVH
@SUVWH
L$HH3
X_^][
@SUVWAVH
@A^_^][
\$ UVWATAUAVAWH
PA_A^A]A\_^]
@SATAVAWH
L$(H3
HA_A^A\[
@SUVWATAUAVAWH
L$PH3
hA_A^A]A\_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
T$0H;
VWAVH
L9s`v=A
H;s`r
L$(H3
0A^_^
@SUVWAVH
)|$`D
)D$PD
)L$@H
L$0H3
(|$`D
(D$PD
(L$@H
A^_^][
t$ UWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_]
@SUVWAVH
L$0H3
@A^_^][
l$ VH
L$(H3
L$(H3
Q8H;Q@t
t$ WH
APH9AHt~
CPH+H
t$ WH
APH9AH
CPH+H
D$0H;WXt
SUVWAVH
A^_^][
@USVWATAVAWH
A_A^A\_^[]
@USVWATAWH
A_A\_^[]
@UVWAVAWH
A_A^_^]
\$ UVWATAUAVAWH
L$PH3
`A_A^A]A\_^]
@SUWATAUAVAWH
D3d$(I
D3d$(
L$XH3
`A_A^A]A\_][
UVWATAUAVAWH
T$xE3
APH9AH
|$0E3
t7fff
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
t$ UWATAVAWH
A_A^A\_]
@SUVWATAVAWH
|$hI9>tyH
A_A^A\_^][
@USVWATAUAVAWH
D$@E3
A_A^A]A\_^[]
\$ UVWATAUAVAWH
D$0H;
T$0H;
A_A^A]A\_^]
T$pH;
@USVWATAUAVAWH
D$0Li
@8|$ t
L$$D3
D$XD;
A_A^A]A\_^[]
T$ H;
L$(H3
t$ UWAWH
@VAVH
D$(Liq`@!
L$(H3
UVWATAUAVAWH
L$@E3
t$H;\$8}
A_A^A]A\_^]
t$ WH
UVWAVAWH
0A_A^_^]
L$(H;
t$;y@s
l$ VWAUAVAWH
0A_A^A]_^
\$(H;
@SUWAVH
(A^_][
(A^_][
t$ WATAUAVAWH
L$HH3
A_A^A]A\_
\$ UVWAVAWH
L$`E3
L9t$x
A_A^_^]
L$0H3
D$HE3
L$hH3
D$HE3
L$hH3
UVAVAWI
A_A^^]
UATAUAVAWH
t$ E3
|$ E3
t$ E3
t$ E3
t$ E3
D$ E3
A_A^A]A\]
L$HHcB
L$LHcJ
L$(HcB
L$,HcJ
L$(HcB
L$,HcJ
L$`H3
VWAVH
L$XHcB
L$\HcJ
L$8HcB
L$<HcJ
L$pH3
SVWATAUAVAWH
@A_A^A]A\_^[
t$ WH
L$0H3
UVWATAUAVAWH
L;E`L
BE`L+
A_A^A]A\_^]
gfffffffH
L$0H3
@SUVWATH
O(+O0
H+G8H
H+G8H
O(+O0
8OPtz
H+G8H
G(D+G0D
0A\_^][
l$ WAVAWH
D+z0A
O +O0
8OPtk
H+G8H
G D+G0D
@8oPtt
H+G8H
G D+G0D
 A_A^_
\$ UVWAVAWH
A_A^_^]
\$ UVWATAUAVAWH
I;U8v
A_A^A]A\_^]
@USVWAVH
A^_^[]
@USVWATAVAWH
A_A^A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWH
L$8H3
\$ UVWAVAWH
A_A^_^]
@USVWAVH
A^_^[]
@SUVWAVH
s(+s0
@8kPt
L$@H3
PA^_^][
@SUVWAVAWH
s(D+s0D
K(+K0
8KPtk
H+C8H
C(D+C0D
L$@H3
XA_A^_^][
@SUVWATH
s(D+s0D
H+C8H
C(D+C0D
D+s0D
s(D+s0D
@8kPto3
H+C8H
C(D+C0D
@8kPt_3
H+C8H
C(D+C0D
K(+K0
8KPtk
H+C8H
C(D+C0D
@A\_^][
@SVWAVAWH
D$8Ic@
T$0H;T$8t
T$8H+
L$@H3
PA_A^_^[
@SVWAVH
L$8E3
L$@H3
XA^_^[
@USVWATAUAVAWH
g(D+g0D
W(+W0
O(+O0
8OPtm
H+G8H
G(D+G0D
xA_A^A]A\_^[]
@SUVWAVAWH
w(D+w0D
W(+W0
O(+O0
8OPtk
H+G8H
G(D+G0D
L$hH3
xA_A^_^][
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
VWATAVAWH
@A_A^A\_^
\$ UVWATAUAVAWH
\$0E3
)D$ L
`A_A^A]A\_^]
@SVWATAUAVAWH
D$0E3
D$0E3
\$ Mk
>HkL$@XH
`A_A^A]A\_^[
t$ WH
SUWAWH
HA__][
t$ WATAUAVAWH
\$ Ii
A_A^A]A\_
L$0H;
@SUVWATAUAVAWH
3333333
(D$ f
hA_A^A]A\_^][
@SUVWATAVAWH
H#U0H
0A_A^A\_^][
H#U0H
(D$ f
H#}0H
\$ UVWATAUAVAWH
d$PE3
(D$ f
`A_A^A]A\_^]
@SUVWAVAWH
8A_A^_^][
L$8H3
L$0H3
L$(H3
{ AVH
{ AVH
{ AVH
{ AVH
)L$@H
@USVWAVH
A^_^[]
\$ UVWAVAWH
A_A^_^]
@USVWATAVAWH
A_A^A\_^[]
@USVWATAVAWH
A_A^A\_^[]
@USVWAVH
A^_^[]
@USVWAVH
T$PE3
A^_^[]
\$ ATAVAWH
t$HuAI
 A_A^A\
UVWATAUAVAWH
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
E/H;E7
\$ UVWATAUAVAWH
A_A^A]A\_^]
[ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
[ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
L$0H3
VWATAUAVH
D84:u
E84(u
@A^A]A\_^
l$0I+
t$ WH
@USVWATAUAVAWH
G8<4u
A_A^A]A\_^[]
USVWATAUAVAWH
)D$PD
)L$`H
A_A^A]A\_^[]
UVWATAUAVAWH
IcEPH
L;|$X
H;}HtBM
A_A^A]A\_^]
t$ WATAUAVAWH
t$8I;
A_A^A]A\_
@VWAVH
 A^_^
t:fff
 A^_^
 A^_^
@VWAVAWH
hA_A^_^
d$PI+
hA_A^_^
|$ AVH
t$@Ii
L$0M+
UWATAVAWH
A_A^A\_]
UWAVH
\$@H;
H#K0H
@USVWATAUAVAWH
seq(A
l$ E3
t$ E3
t$ E3
A_A^A]A\_^[]
L$PH3
|$ UATAUAVAWH
A_A^A]A\]
|$ AVH
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
UVWAVAWH
D$pH9D$@uf
D$HuC
A_A^_^]
t$ UWATAVAWH
L$DD;
A_A^A\_]
L$HD;
UVWAVAWH
D$@D;
t$H9H(u
D$@H;
A_A^_^]
@SVWH
\$ WH
\$ WH
\$ WH
[ UVWH
|$ UATAUAVAWH
A_A^A]A\]
T$`H;
T$`H;
T$`H;
T$`H;
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWATAVAWH
A_A^A\_]
T$`H;
T$`H;
T$`H;
T$`H;
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWAVH
|$ UH
USVWH
|$ UH
|$ UH
|$ UH
T$`H;
T$`H;
UWAVH
T$`H;
T$`H;
UWAVH
|$ UH
|$ UH
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
UWAVH
T$`H;
UWAVH
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
UWAVH
T$`H;
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
T$`H;
T$`H;
T$`H;
T$`H;
UWAVH
|$ UAVAWH
A_A^]
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
T$`H;
T$`H;
UWAVH
T$`H;
T$`H;
T$`H;
T$`H;
UWAVH
UWAVH
|$ UAVAWH
A_A^]
UWAVH
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
D$0E3
D$0E3
\$@E3
D$(M;
PA_A^A]A\_^[
@SVWATAUAVAWH
yxxxxxxxH
D$0E3
D$0E3
\$ Mi
yxxxxxxxH
7HiL$@
`A_A^A]A\_^[
t$ WAVAWH
 A_A^_
t$0ff
t$0H;
@SUVWAVAWH
8A_A^_^][
yxxxxxxxH
t$8H+
t$8H+
\$ WH
UWATAVAWH
A_A^A\_]
|$ UH
E0H9E
T$hH;T$pt
D$pH+
|$ UATAUAVAWH
A_A^A]A\]
t$ WAVAWH
D$xE3
A_A^_
UWATAVAWH
A_A^A\_]
UVWATAUAVAWH
C\$pH
t$ E3
CD$Pf
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
t$ WAVAWH
L$(H;
L$HH3
A_A^_
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
UVWATAUAVAWH
C\$pH
t$ E3
CD$Pf
A_A^A]A\_^]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
)t$`H
T$8H+
L$PH3
(t$`H
t$ WH
L$@H3
T$8H+
L$XH3
T$8H+
L$PH3
t$8H+
@USVWAVH
E0H9E
T$hH;T$pt
D$pH+
A^_^[]
USVWH
T$`H;
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
USVWH
T$`H;
USVWH
T$`H;
\$ WH
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
t$ UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
|$ UATAUAVAWH
t7fff
D9`(t
A_A^A]A\]
|$ UATAUAVAWH
D9h(t
A_A^A]A\]
t$ UWATAVAWH
A_A^A\_]
t$ WATAUAVAWH
D9`(t
A_A^A]A\_
|$ UH
t$ UWAVH
@USVWATAVAWH
A_A^A\_^[]
T$pH;
T$`H;
T$pH;
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
|$ UH
|$ UH
T$`H;
T$`H;
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
UWAVH
|$ UH
T$`H;
USVWH
USVWH
T$`H;
USVWH
UWAVH
UWATAVAWH
A_A^A\_]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
|$8ff
p WATAUAVAWH
A_A^A]A\_
l$ VWATAVAWH
L$@E3
uTL9~
)D$ H
A_A^A\_^
\$@E3
UWAVH
|$ UH
|$ UH
t$ WH
|$ UH
|$ UH
t$ WH
t$ UWAVH
UVWATAUAVAWH
L$PLc
l$HIc
E(H+E H
t$8H;
D$(H;}
H;t$8
HcT$HI
A_A^A]A\_^]
|$ UATAUAVAWH
L$0E3
}(D9eP~n
D$(I;
D$(L+
H;\$0
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
\$ UVWATAUAVAWH
t$ E9t$(t
t$ D;
D$`E3
D$(H;
D$(H;
D$(L;
T$(H;
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
USVWATAUAVAWH
A_A^A]A\_^[]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
|$ UAVAWH
A_A^]
UWATAVAWH
A_A^A\_]
UWAVH
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UH
|$ UH
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UH
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
Ct$XH
|$ E3
A_A^A\_]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
l$ VWAVH
T$ E3
D$HE3
D$(H;
L$XH3
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$8H+
p 9O(t
D$8H+
A_A^A]A\]
t$ WATAUAVAWH
|$ Mco
|$ A;
A_A^A]A\_
VWATAVAWH
A_A^A\_^
t$ WATAUAVAWH
A_A^A]A\_
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
t$ WATAUAVAWH
T$@E3
l$HL;l$X
A_A^A]A\_
t$ WATAUAVAWH
|$HMco
|$HA;
A_A^A]A\_
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
VWATAVAWH
H+T$xH
A_A^A\_^
|$ UATAUAVAWH
D$8H+
p 9O(t
D$8H+
A_A^A]A\]
D$@E3
L$PH3
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
B taL
t$ WATAUAVAWH
L$ Lci
A_A^A]A\_
|$ UATAUAVAWH
D$ H;]
A_A^A]A\]
H9L$0
D$(N9, 
I94$I
D$ J+4 x
|$ UATAUAVAWH
A_A^A]A\]
VWAVH
t$8I;
t$ I;
T$8H+
L$@H3
PA^_^
UWATAVAWH
t$(H;]
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
t$ WATAUAVAWH
T$`I+
L$hH3
A_A^A]A\_
|$ UATAUAVAWH
A_A^A]A\]
t$$D;u
D$HE3
SUVWAVH
uy9E(t)H
A^_^][
\$ WH
|$H9S(u
D$@H;
\$ UVWH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
(D$0f
(D$0f
D$0L;
(D$0f
A_A^A]A\]
|$ AVH
t$0fff
|$ UH
UWAVH
UWAVH
|$XH;
T$`H+
UWAVH
|$`H;
T$hH+
|$ UH
UWAVH
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
T$pH;
x UATAUAVAWH
uXL9t$h
Ct$pH
|$ E3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
T$`H;
T$`H;
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
T$`H;
T$`H;
T$`H;
|$ UH
UWAVH
|$ UH
T$`H;
USVWH
T$`H;
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
UWAVH
|$ UH
|$ UH
|$ UH
UWAVH
t$ WH
@ 9A 
C 9A 
UVWAVAWH
A_A^_^]
|$ UATAUAVAWH
L$0E3
}(D9eP~n
D$(I;
D$(L+
H;\$0
A_A^A]A\]
L$PH3
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@SVWATAUAVAWH
UUUUUUU
t$ I;
`A_A^A]A\_^[
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
L$pH;
G(A9F(
H;t$xs
A_A^A]A\]
|$ UATAUAVAWH
L$pH;
G(A9F(
H;t$xs
A_A^A]A\]
|$ UATAUAVAWH
D$pI+
D$xI+
A_A^A]A\]
|$ UATAUAVAWH
UUUUUUU
D$hH+
H;|$X
t$HL;d$h
D$0H+
A_A^A]A\]
|$ UATAUAVAWH
UUUUUUU
D$`H+
t$XI;
t$HL;d$`s
D$8H+
A_A^A]A\]
WAVAWH
0A_A^_
|$ UATAUAVAWH
UUUUUUU
t$@L;
H;U t
D$hH+
D$HI+
A9F(t.I
H;|$Pr
H;t$H
D$0I+
A_A^A]A\]
|$ UATAUAVAWH
EHH+E@H
UUUUUUU
A_A^A]A\]
t$ WATAUAVAWH
UUUUUUU
A_A^A]A\_
L$ H3
USVWH
T$`H;
|$ UH
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWATAVAWH
A_A^A\_]
UWAVH
USVWH
T$`H;
USVWH
T$`H;
|$ UH
EpH;Ex
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
|$ UH
@SVWH
@SVWH
@SVWH
@SVWH
t$ WH
|$ UH
|$ UAVAWH
A_A^]
UVWATAUAVAWH
Lcq H
A_A^A]A\_^]
|$ UATAUAVAWH
(D$0f
(D$0f
D$0L;
(D$0f
A_A^A]A\]
@USWH
@USWH
\$ UVWH
\$ UVWH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
T$`H;
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWAVH
|$ UH
UWAVH
UWAVH
T$`H;
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UH
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
UWATAVAWH
D$8E3
D$Pff
A_A^A\_]
|$ UATAUAVAWH
D$pE3
A_A^A]A\]
UWAVH
|$ UAVAWH
A_A^]
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$`E3
A_A^A]A\]
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
VWAVH
UVWATAUAVAWH
C\$pH
t$ E3
CD$Pf
A_A^A]A\_^]
t$ WH
@ 9A uxH
C 9A 
UWATAVAWH
A_A^A\_]
@USVWATAVAWH
L$8I+
A_A^A\_^[]
t$ WH
\$@Hc
T$8H;T$@t
T$@H+
L$HH3
|$ UATAUAVAWH
A_A^A]A\]
@USVWATAVAWH
L$8I+
A_A^A\_^[]
\$ UVWATAUAVAWH
Hc\$D
A_A^A]A\_^]
@USVWATAVAWH
A_A^A\_^[]
@USVWAVH
A^_^[]
UVWATAUAVAWH
A_A^A]A\_^]
|$ UH
UVWATAUAVAWH
|$HE3
t$@H9t$X
H9t$X
A_A^A]A\_^]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$pE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UAVAWH
A_A^]
UWAVH
UWAVH
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$xE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$pE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
UWATAVAWH
D$PE3
A_A^A\_]
|$ UATAUAVAWH
C\$XL
D$hL;
A_A^A]A\]
t$ WAVAWH
A_A^_
UWAUAVAWH
A_A^A]_]
|$ UATAUAVAWH
t$ HcU
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
D$@E3
L$PH3
|$ UATAUAVAWH
A_A^A]A\]
t$ WAVAWH
D$@E3
L$PH3
A_A^_
@SVWH
@ HcX H
L$HH3
|$ UATAUAVAWH
A_A^A]A\]
VWAVH
t$ WATAUAVAWH
D$@E3
L9t$H
D8t$At$A9m
D8t$@t:A9l$
l$HIcE
A_A^A]A\_
|$ UATAUAVAWH
D$8H+
p 9O(t
D$8H+
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
M'H+M
H;U't
t$ WAVAWH
D$@E3
L$PH3
A_A^_
|$ UATAUAVAWH
D$@H+
t$ D;u
L$(I+
A_A^A]A\]
|$ UATAUAVAWH
\$(H;U
A_A^A]A\]
D$@E3
L$PH3
UWAVH
D$PE3
|$ UAVAWH
D$`E3
A_A^]
UWAVH
UWAVH
|$ UH
UWAVH
|$ UAVAWH
A_A^]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
D$XE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
D$hff
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$XE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D9{(t&H
D9~(u
D9~(u
A_A^A\_]
|$ UH
U'u<I+
|$ UATAUAVAWH
H;U't
9{(t%H
A_A^A]A\]
t$ WATAUAVAWH
D$0D;
A_A^A]A\_
UWAVH
UWAVH
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
T$`H;
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
D9`(t
A_A^A]A\]
t$ UWAVH
@83tdH
|$ UH
USVWAVH
A^_^[]
UWAVH
|$XH;
T$`H+
UWAVH
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
D$PE3
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
D$XE3
A_A^A\_]
|$ UH
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
UUUUUUU
D$hH+
t$HL;d$h
D$0H+
A_A^A]A\]
|$ UATAUAVAWH
EHH+E@H
UUUUUUU
D$@H;
d$HH;U8t
}:fff
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
UWAVH
UWATAVAWH
A_A^A\_]
UWAVH
D$`E3
USVWH
|$ UATAUAVAWH
A_A^A]A\]
|$ UAVAWH
A_A^]
UWAVH
UWAVH
D$pE3
|$ UAVAWH
D$`E3
A_A^]
UWAVH
|$ UAVAWH
D$`E3
A_A^]
UWAVH
D$PE3
|$ UH
@SUVWATAVAWH
D$ L;
L$@H3
PA_A^A\_^][
\$ UVWATAUAVAWH
A_A^A]A\_^]
s WAVAWH
@A_A^_
UWATAVAWH
A_A^A\_]
|$ UATAUAVAWH
A_A^A]A\]
|$ UATAUAVAWH
A_A^A]A\]
|$ UAVAWH
A_A^]
|$ UATAUAVAWH
A_A^A]A\]
VWAVH
L$HE3
T$XH+
L$`H3
UWATAVAWH
A_A^A\_]
|$ UAVAWH
D$`E3
A_A^]
UWAVH
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
t$ UWATAVAWH
A_A^A\_]
L$8H3
L$8H3
L$8H3
L$8H3
L$8H3
VWAVH
0A^_^
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^_^[]
WAVAWH
t$(@8w
@A_A^_
\$ UVWATAUAVAWH
l$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWAVAWH
HcFXH
HcFpH
A_A^_^]
WATAUAVAWH
IcGPH
IcGhH
IcGPH
IcG8H
IcG L
A_A^A]A\_
@USVWATAVAWH
A_A^A\_^[]
HcFPH
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
UVWATAUAVAWH
l$HE3
A_A^A]A\_^]
\$@H;
UVWAVAWH
L$ E3
`A_A^_^]
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWAVH
A^_^[]
@USVWAVAWH
A_A^_^[]
@USVWATAVAWH
A_A^A\_^[]
t$ WH
gfffffffH
t$8H+
VWATAVAWH
t$8E3
D$ L;
L$XH3
A_A^A\_^
\$ UVWATAUAVAWH
A_A^A]A\_^]
8_u3I
\$ UVWAVAWH
PA_A^_^]
@USVWATAUAVAWH
8{u1H
A_A^A]A\_^[]
@USVWAVH
`A^_^[]
@USVWATAUAVAWH
XA_A^A]A\_^[]
\$ UVWH
L$@H3
\$ UVWH
D$0{H
8}tU3
L$@H3
\$ UVWATAUAVAWH
T$@L;
D$8=H
A_A^A]A\_^]
D$8[H
D$8]H
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
t$ E3
8(u!H
A_A^A]A\_^]
@SVWH
D$ H;
@USVWATAVAWH
8_u4I
A_A^A\_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@SUVWAVH
T$ E3
L$PH3
`A^_^][
C\$0D
H;\$ tk
@SUVWAVH
T$ E3
L$PH3
`A^_^][
C\$0D
H;\$ tk
@SUVWATAVAWH
L$ M+
PA_A^A\_^][
@USVWAVH
`A^_^[]
\$ UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
A_A^A]A\_^]
@USVWATAUAVAWH
8(u%H
8)u:H
A_A^A]A\_^[]
8,u%H
\$ UVWH
8_u2I
\$ UVWAVAWH
`A_A^_^]
@USVWATAUAVAWH
8<u%H
8>u:H
A_A^A]A\_^[]
8,u%H
t$ WH
L$ H;
>"t(H
L$(H3
t$ UWATAVAWH
N H;H 
A_A^A\_]
l$ VWATAVAWH
A_A^A\_^
@USVWATAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A\_^[]
@USVWATAUAVAWH
D$@HcH
D$@HcH
L$@HcQ
L$@HcQ
A_A^A]A\_^[]
@USVWATAUAVAWH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A_A^A]A\_^[]
@USVWAVH
D$0HcH
D$0HcH
L$0HcQ
L$0HcQ
A^_^[]
\$ UVWATAUAVAWH
d$8E3
(D$ f
PA_A^A]A\_^]
\$ UVWATAUAVAWH
I#W0H
0A_A^A]A\_^]
d$ E3
I#W0H
(D$ f
I#w0H
@USVWATAUAVAWH
HcGPH
t.H;O
t+H;K
A_A^A]A\_^[]
\$ UVWATAUAVAWH
|$HH;
A_A^A]A\_^]
@USVWATAUAVAWH
UUUUUUU
IcGhL
IcGPH
A_A^A]A\_^[]
@USVWATAUAVAWH
A_A^A]A\_^[]
@SVWATAUAVAWH
S H+S
S H+S
IcEPH
IcEhH
IcE8H
H;t$HtYH
|$pH;
IcE L
HcGPH
IcE H
\$HH;
A_A^A]A\_^[
[ UVWH
@ A9A 
D9O(u
D9O(u
\$ UVWATAUAVAWH
HcA8H
Lcd$XM
l$PE3
HcPhH
Hc@hH
A_A^A]A\_^]
UVWATAUAVAWH
L$PH#
I;T$(
A_A^A]A\_^]
D$0H+
D$0H+
)D$@H
|$PE3
|$ ATAVAWH
 A_A^A\
\$ AVH
t$ AVH
L$0M+
UVWATAUAVAWH
yxxxxxxxI
yxxxxxxxH
@A_A^A]A\_^]
UVWATAUAVAWH
A_A^A]A\_^]
\$ UVWATAUAVAWH
H9w u@
A_A^A]A\_^]
AVAWH
(A_A^
VWAVH
@WATAUAVAWH
@A_A^A]A\_
@SUVWATAVAWH
A_A^A\_^][
@SUWAVH
|$ D8t$(
L$@H3
XA^_][
t$ WAVAWH
 A_A^_
\$ UVWAVAWH
\$ D8|$(
L$@H3
PA_A^_^]
@SVWAUH
(A]_^[
(A]_^[
(A]_^[
VWAVH
 A^_^
@SUVWAVH
\$ D8t$(
L$@H3
PA^_^][
@SVWAVH
l$`H;
l$PtRI
(A^_^[
(A^_^[
(A^_^[
VWAVH
HcUhH
 A^_^
\$ UVWAVAWH
L$PH3
`A_A^_^]
@SUVWH
 t]I;
@t`H;
d$PtPH
(_^][
(_^][
(_^][
@SUWAVH
\$ D8t$(
L$@H3
XA^_][
l$ VH
\$8t'H
@SUVWAVH
\$ D8t$(
L$@H3
PA^_^][
\$ UVWH
t$HH;
|$PtXH
t$ E3
t$ H;
\$ UVWAVAWH
\$ D8|$(
L$@H3
PA_A^_^]
WATAUAVAWH
 A_A^A]A\_
@SUVAVH
L$PH3
hA^^][
t$ WAVAWH
L$HH3
A_A^_
@USVWATAVAWH
A_A^A\_^[]
WATAUAVAWH
r!fff
 tgH;
 A_A^A]A\_
@SUVWAVH
\$(D8t$0
L$PH3
`A^_^][
WAVAWH
 A_A^_
@SUWAVAWH
|$(D8|$0
L$HH3
PA_A^_][
l$ VH
@SVWAVH
L$@H3
XA^_^[
\$ VWAVH
d$HH;
|$PtZI
 A^_^
 A^_^
 A^_^
HcG H
@SUVAVH
L$HH3
XA^^][
HcF H
@SUVAVH
\$ D8t$(
L$@H3
XA^^][
HcG H
@SUVAVH
L$HH3
XA^^][
HcF H
@SUWAVAWH
\$ D8|$(
L$@H3
PA_A^_][
l$0t^H
@SUVAVH
L$HH3
XA^^][
t$ WAVAWH
 A_A^_
\$ UVWAVAWH
\$ D8|$(
L$@H3
PA_A^_^]
t$ WATAUAVAWH
 A_A^A]A\_
t$ WAVAWH
 A_A^_
\$ UVWAVAWH
L$`H3
pA_A^_^]
\$ UVWATAUAVAWH
 t1H;
@t1H;
0A_A^A]A\_^]
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
VWAVH
 A^_^
KhH91t
KpH91t
KxH91t
O H91t
O H91t
K H91t
t$ WH
L$(H3
L$(H3
t$ E3
t$ H;
\$ UVWAVAWH
L$HH3
PA_A^_^]
@SVWAWH
l$PtRI
(A__^[
(A__^[
(A__^[
VWAVH
HcFPH
 A^_^
@SUVWAVH
L$XH3
`A^_^][
WATAUAVAWH
IcEPH
 A_A^A]A\_
HcFHH
@SUVAVAWH
L$HH3
PA_A^^][
@t_H;
HcEHH
 t1H;
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
l$8Hc)L
\$0HcV
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
|$ AVH
 HcD$PI
L$0H3
L$0H3
L$0H3
L$0H3
WAVAWH
 A_A^_
@SUAVAWH
d$ H;
(A_A^][
(A_A^][
\$0H#
\$ WH
@UVWH
\$(E3
WATAUAVAWH
 A_A^A]A\_
T$ E3
SVWAVH
8A^_^[
WAVAWH
\$8H;
A_A^_
WAVAWH
0A_A^_
x AVH
\D$ fH
T$ H;
\L$ f
L$ A;
HcU0H
SUVWH
SUVWH
SUVWH
(_^][
@UAUH
@UAUH
@UAUH
SUVWH
SUVWH
@UAUH
@UAUH
@UAUH
Unknown exception
bad array new length
string too long
(cannot determine missing fields for lite message)
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\message_lite.cc
Can't 
 message of type "
" because it is missing required fields: 
parse
 exceeded maximum protobuf size of 2GB: 
vector too long
WARNING
ERROR
FATAL
[libprotobuf %s %s:%d] %s
00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
?456789:;<=
 !"#$%&'()*+,-./0123
456789:;<=
 !"#$%&'()*+,-./0123
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_
false
invalid string position
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - SerialArena::kBlockHeaderSize): 
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google/protobuf/parse_context.h
Can't happen
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl_lite.cc
CHECK failed: (count) >= (0): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
 BackUp() can only be called after Next().
CHECK failed: (count) <= (buffer_used_): 
 Can't back up over more bytes than were returned by the last call to Next().
 Parameter to BackUp() can't be negative.
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl.cc
close() failed: 
CHECK failed: !is_closed_: 
INVALID_ARGUMENT
map/set too long
unordered_map/set too long
invalid hash bucket count
bad allocation
 was false.
Stacktrace:
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/data_types_internal.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/tensor.h
CPUExecutionProvider
Tensor sequence must contain only primitive types
elem_type_ != nullptr
onnxruntime::TensorSeq::SetType
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/TensorSeq.h
i < tensors_.size()
onnxruntime::TensorSeq::Get
Trying to get a Tensor, but got: 
IsTensor()
OrtValue::Get
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/ort_value.h
OrtValue::GetMutable
Trying to get a TensorSeq, but got: 
IsTensorSequence()
Trying to get a SparseTensor, but got: 
IsSparseTensor()
ORT_LOAD_CONFIG_FROM_MODEL
Integer overflow
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow
D:\a\_work\1\s\onnxruntime\onnxruntime\core/common/safeint.h
tried creating tensor with negative value in shape
size overflow
, got 
not enough space: expected 
Not able to find appropriate IDataTransfer to copy sparse data
`anonymous-namespace'::GetDataTransfer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\onnxruntime_c_api.cc
Strings can only reside in CPU memory
`anonymous-namespace'::ValidateFillInputArgs
tried Filling sparse tensor with negative value in values shape
OrtApis::FillSparseTensorCoo
OrtApis::FillSparseTensorCsr
tried Filling sparse tensor with negative value in block sparse indices shape
OrtApis::FillSparseTensorBlockSparse
Can not use strings in pre-allocated memory. Use CreateSparseTensorAsOrtValue() to allocate memory inside and copy
OrtApis::UseCooIndices
OrtApis::UseCsrIndices
OrtApis::UseBlockSparseIndices
the ort_value must contain a constructed tensor
Use GetStringTensor*() API to retrieve strings
RegisterCustomOpsLibrary: Failed to load library
RegisterCustomOps
RegisterCustomOpsLibrary: Entry point RegisterCustomOps not found in library
EnableOrtCustomOps: Custom operators in onnxruntime-extensions are not enabled
onnxruntime_profile_
input name cannot be empty
output name cannot be empty
lengths allocation failed
string buffer allocation failed
Output buffer allocation failed
input array doesn't equal tensor size
element index is out of bounds
OrtValue should contain a Tensor or a Sparse Tensor
Sparse Tensor does not contain sparse data
This API supports Tensors or SparseTensors
shape is invalid
index is out of bounds
offsets buffer is not equal to tensor size
output buffer is too small. Use GetStringTensorDataLength.
buffer size is too small for string element
out of index
internal error
index out of range
Input is not of one of the supported sequence types.
Input is not of type sequence or map.
input array is too short
Input is not of one of the supported map types.
Expecting all elements to be tensors. Got: 
in[idx]->IsTensor()
OrtCreateValueImplSeqHelper
Sequences must have tensors of the same data type. There was at least one tensor in the input that was different.
Each element of the sequence should be either tensor or map.
At least one element in the sequence is of a type different from others.
Unsupported input type
For map type num_values MUST be 2
Either the key tensor or the value tensor has NumDimensions > 1
Key and value tensors have unequal number of elements.
Key type is not supported yet.
Number of values should be at least 1.
opaque(
Specified domain and type names combination does not refer to a registered opaque type
ml_type != nullptr
OrtApis::CreateOpaqueValue
Opaque type is not a non_tensor type!!!
non_tensor_base != nullptr
OrtApis::GetOpaqueValue
Specified provider is not supported.
this API does not support strings
location dimensions do not match shape size
invalid location range
max_mem
arena_extend_strategy
initial_chunk_size_bytes
max_dead_bytes_per_chunk
initial_growth_chunk_size_bytes
Invalid key found: 
The given version [%u] is not supported, only version 1 to %u is supported in this build.
1.11.1
Tensor type mismatch. 
utils::IsPrimitiveDataType<T>(dtype_)
onnxruntime::Tensor::MutableData
onnxruntime::Tensor::DataAsSpan
Invalid index requested for map type.
Tensor must always contain primitive types. Found: 
value_type != nullptr
OrtCreateValueImplMapHelper
Value type is not supported yet: 
Map is missing type entry for its value
++index < c.size()
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,double,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,__int64,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
Sequence is missing type entry for its element
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > >,class std::allocator<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > >,class std::allocator<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > > > >::check
invalid vector subscript
onnxruntime::DataTypeImpl::GetType<T>() == type_
len >= 0 && static_cast<uint64_t>(len) < std::numeric_limits<size_t>::max()
OrtCreateMapMLValue
onnxruntime::Tensor::Data
not implemented
execution_mode is not valid
graph_optimization_level is not valid
 is not implemented
onnxruntime::OpKernel::ComputeAsync
Result buffer is not large enough
' in custom op '
Unsupported version '
onnxruntime::CustomOpKernel::CustomOpKernel
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\custom_ops.cc
custom op registered at runtime
Input
all types
There must be one (and only one) dynamic typed input to the custom op. Its type info at runtime will be used to infer the type info of this dynamic typed output which is required for the success of the model loading step. More than one dynamic typed inputs are currently not supported as differing types at runtime means the output type cannot be inferred without which model loading cannot proceed.
type_id_counter == 1
onnxruntime::CreateCustomRegistry
Output
No requested allocator available
Env is null
OrtMemoryInfo is null
Provided allocator is null
Please register the allocator as OrtDeviceAllocator even if the provided allocator has arena logic built-in. OrtArenaAllocator is reserved for internal arena logic based allocators only.
Provided OrtMemoryInfo is null
Tensor type mismatch.
type == dtype_
onnxruntime::Tensor::MutableDataRaw
onnxruntime::Tensor::DataRaw
) != new size (
Tensor size (
shape_.Size() == new_shape.Size()
onnxruntime::Tensor::Reshape
Missing Input: 
onnxruntime::OpKernelContext::Input
Required input at index 
input_ptr
onnxruntime::OpKernelContext::RequiredInput
onnxruntime_providers_cuda.dll
onnxruntime_providers_rocm.dll
onnxruntime_providers_dnnl.dll
onnxruntime_providers_openvino.dll
onnxruntime_providers_tensorrt.dll
onnxruntime_providers_migraphx.dll
 is not present.
Required output at index 
output_ptr
onnxruntime::OpKernelContext::RequiredOutput
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/op_kernel_context.h
Please fetch output tensor with specified shape.
p_ml_value
onnxruntime::OpKernelContext::Output
TensorSeq: tensor to be added has a different data type.
IsSameDataType(tensor)
onnxruntime::TensorSeq::Add
invalid unordered_map<K, T> key
Attempt to use DefaultLogger but none has been registered.
onnxruntime::logging::LoggingManager::DefaultLogger
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/common/logging/logging.h
onnxruntime_providers_shared.dll
onnxruntime::ProviderSharedLibrary::Ensure
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\provider_bridge_ort.cc
Provider_SetHost
onnxruntime::ProviderSharedLibrary::Unload
onnxruntime::ProviderLibrary::Get
GetProvider
onnxruntime::ProviderLibrary::Unload
SessionOptionsAppendExecutionProvider_Tensorrt: Failed to load shared library
SessionOptionsAppendExecutionProvider_MIGraphX: Failed to load shared library
SessionOptionsAppendExecutionProvider_OpenVINO: Failed to load shared library
CUDA and/or ROCM execution provider is either not enabled or not available.
OrtSessionOptionsAppendExecutionProvider_Cuda: Failed to load shared library
OrtSessionOptionsAppendExecutionProvider_Rocm: Failed to load shared library
OrtSessionOptionsAppendExecutionProvider_TensorRT: Failed to load shared library
TensorRT execution provider is not enabled in this build.
CUDA execution provider is not enabled in this build.
optimization.minimal_build_optimizations
bad cast
invalid stoi argument
stoi argument out of range
Bad optional access
 DeviceId:
 MemoryType:
DeviceType:
Device:[
 OrtAllocatorType:
 OrtMemType:
name:
OrtMemoryInfo:[
CUDAExecutionProvider
TensorrtExecutionProvider
DmlExecutionProvider
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/graph/graph.h
 Max:
Validating no unexpected access using an invalid node_index. Got:
node_index < nodes_.size()
onnxruntime::Graph::NodeAtIndexImpl
 has already been registered.
Provider 
onnxruntime::ExecutionProviders::Add
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/execution_providers.h
onnxruntime::FeedsFetchesInfo::FeedsFetchesInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/feeds_fetches_manager.h
Compute_
Create_State_
Release_State_
D:\a\_work\1\s\onnxruntime\onnxruntime\core/session/inference_session.h
IsGraphCaptured()
onnxruntime::InferenceSession::CachedExecutionProviderForGraphReplay::ReplayGraph
Cached EP instance for graph replay is not set yet before calling ReplayGraph()
Provided type is not an optional tensor
IsOptionalTensor(type)
onnxruntime::utils::GetElementTypeFromOptionalTensor
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/mldata_type_utils.h
Provided type is not an optional sequence tensor
IsOptionalSeqTensor(type)
onnxruntime::utils::GetElementTypeFromOptionalSeqTensor
MemcpyTransformer
[json.exception.
other_error
session.use_env_allocators
session.load_model_format
session.save_model_format
session.set_denormal_as_zero
session.inter_op.allow_spinning
session.intra_op.allow_spinning
session.use_ort_model_bytes_directly
session.dynamic_block_base
memory.enable_memory_arena_shrinkage
%Y-%m-%d_%H-%M-%S
) node with name '
Could not find an implementation for 
onnxruntime::`anonymous-namespace'::VerifyEachNodeIsAssignedToAnEpImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\inference_session.cc
Node placements
onnxruntime::`anonymous-namespace'::VerifyEachNodeIsAssignedToAnEp
All nodes have been placed on [
 Provider: [
 value of 'save' is only valid when saving an ORT format model.
apply
Invalid value for 
The environment variable contained the value: 
 are '0' and '1'. 
The only supported values for the environment variable 
Reading the provided model for the ORT config
onnxruntime::FinalizeSessionOptions
ModelProto needs to be parsed to check for ORT config within it
is_model_proto_parsed
Flush-to-zero and denormal-as-zero are 
onnxruntime::InferenceSession::ConstructorCommon::<lambda_7c14b5b3ba89015b9f6468edc3832bfe>::operator ()
Could not finalize session options while constructing the inference session. Error Message: 
status.IsOK()
onnxruntime::InferenceSession::ConstructorCommon
graph_transformation_mgr_.SetSteps(session_options_.max_num_graph_transformation_steps).IsOK()
Creating and using per session threadpools since use_per_session_threads_ is true
-intra-op
session-
Dynamic block base set to 
custom join thread function not set for intra op thread pool
to.custom_join_thread_fn
-inter-op
custom join thread function not set for inter op thread pool
Failed to create the inter-op thread pool for the parallel executor, setting ExecutionMode to SEQUENTIAL
Using global/env threadpools since use_per_session_threads_ is false
When the session is not configured to use per session threadpools, the env must be created with the the CreateEnvWithGlobalThreadPools API.
session_env.EnvCreatedWithGlobalThreadPools()
CastFloat16Transformer
Given model could not be parsed while creating inference session. Error message: 
onnxruntime::InferenceSession::InferenceSession
Could not parse model successfully while constructing the inference session
result
Error during EndProfiling(): 
onnxruntime::InferenceSession::{dtor}::<lambda_2d91af5d8f3e88a3721667de76a73c43>::operator ()
Unknown error during EndProfiling()
onnxruntime::InferenceSession::~InferenceSession
Received nullptr for exec provider
Execution providers must be registered before the session is initialized. 
onnxruntime::InferenceSession::RegisterExecutionProvider
Execution providers must be registered before the session is initialized.
So disabling it for this session since it uses the DML Execution Provider.
Having memory pattern enabled is not supported while using the DML Execution Provider. 
So making the execution mode sequential for this session since it uses the DML Execution Provider.
Parallel execution mode does not support the DML Execution Provider. 
So making the execution mode sequential for this session since it uses the CUDA Execution Provider.
Parallel execution mode does not support the CUDA Execution Provider. 
onnxruntime::InferenceSession::AddCustomOpDomains
Received nullptr for custom registry
onnxruntime::InferenceSession::SaveToOrtFormat
Exception during loading: 
This session already contains a loaded model.
onnxruntime::InferenceSession::Load
Unknown exception in Load()
Encountered unknown exception in Load()
ModelProto corresponding to the model to be loaded has already been parsed. Invoke Load().
Failed to load model because protobuf parsing failed.
model_loading_array
ModelProto corresponding to the model to be loaded has not been parsed yet. This API should be called in conjunction with a ctor that takes a model abstraction.
model_loading_from_saved_proto
onnxruntime::InferenceSession::TransformGraph
onnxruntime::InferenceSession::LoadOrtModel::<lambda_165747221b83b97edb1c8980b4a934c8>::operator ()
onnxruntime::InferenceSession::LoadOrtModel
This session has already been initialized.
ORT model verification failed.
InferenceSession is null. Invalid ORT format model.
Serialized version info is null. Invalid ORT format model.
] is not supported this build 
The ORT format model version [
Missing Model. Invalid ORT format model.
SessionState is null. Invalid ORT format model.
The provided PrePackedWeightsContainer instance to be added to the session is null
The session already has a PrePackedWeightsContainer instance
onnxruntime::`anonymous-namespace'::PartitionOrtFormatModel
onnxruntime::`anonymous-namespace'::ApplyOrtFormatModelRuntimeOptimizations
) in kernel registries for 
Failed to find kernel def hash (
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashesImpl::<lambda_6d5d79dc9c3bbca8e0221531cea74284>::operator ()
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashesImpl
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashes
Exception during initialization: 
onnxruntime::InferenceSession::Initialize::<lambda_4dd40fbfce8b243a9fb43e8983477352>::operator ()
onnxruntime::InferenceSession::Initialize::<lambda_c6bff5ff6892027db42ce3633458d3ed>::operator ()
Initializing session.
onnxruntime::InferenceSession::Initialize
Model was not loaded
Model was not loaded.
Session has already been initialized.
Adding default CPU execution provider.
This session will use the allocator registered with the environment.
 as the model has control flow nodes which can't be supported by CUDA Graphs.
This session cannot use the CUDA Graph feature as requested by the user 
This session cannot use the CUDA Graph feature as requested by the user  as the model has control flow nodes which can't be supported by CUDA Graphs.
 as all the graph nodes have not been partitioned to the CUDA EP.
This session cannot use the CUDA Graph feature as requested by the user  as all the graph nodes have not been partitioned to the CUDA EP.
This session will use the CUDA Graph feature as requested by the user.
loading_ort_format && serialized_session_state != nullptr
Unable to serialize model as it contains compiled nodes. Please disable any execution providers which generate compiled nodes.
NchwcTransformer
Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.
Session successfully initialized.
Encountered unknown exception in Initialize()
session_initialization
 Please fix either the inputs or the model.
 Expected: 
 Got: 
Invalid rank for input: 
 for the following indices
Got invalid dimensions for input: 
 index: 
Unexpected input data type. Actual: (
)) , expected: (
 elements.
elements, but feeds has 
Size mismatch: feed_names has 
Invalid Feed Input Name:
 is not expected to be of type tensor.
Input with name: 
tensor
onnxruntime::InferenceSession::ValidateInputs
 is not expected to be of type sparse tensor.
sparse_tensor
 is not expected to be of type tensor sequence.
Output vector pointer is NULL
At least one output should be requested.
p_fetches->size(): 
Output vector incorrectly sized: output_names.size(): 
Invalid Output Name:
 CUDA Graph for this model with tag: 
Replaying the captured 
onnxruntime::InferenceSession::Run
Session was not initialized
Session not initialized.
Running with tag: 
Encountered unknown exception in Run()
model_run
Start the second Run() to capture the graph. The first one is for necessary memory allocation;The second one is for capturing the graph.
onnxruntime::InferenceSession::GetModelMetadata
onnxruntime::InferenceSession::GetModelInputs
onnxruntime::InferenceSession::GetOverridableInitializers
onnxruntime::InferenceSession::GetModelOutputs
onnxruntime::InferenceSession::NewIOBinding
Profiler is disabled.
onnxruntime::InferenceSession::EndProfiling
Could not write a profile because no model was loaded.
Unsupported device specified in the memory arena shrink list: 
Unsupported device id in the memory arena shrink list: 
 combination in the memory arena shrink list: 
Did not find an arena based allocator registered for device-id 
 combination is not an arena based allocator: 
The registered allocator for device-id 
 error message: 
Unable to shrink arena: 
onnxruntime::InferenceSession::ShrinkMemoryArenas
Invalid run log severity level. Not a valid onnxruntime::logging::Severity value: 
run_options.run_log_severity_level >= 0 && run_options.run_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
onnxruntime::InferenceSession::CreateLoggerForRun
Invalid session log severity level. Not a valid onnxruntime::logging::Severity value: 
session_options_.session_log_severity_level >= 0 && session_options_.session_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
onnxruntime::InferenceSession::InitLogger
onnxruntime::InferenceSession::AddPredefinedTransformers
961c151d2e87f2686a955a9be24d316f1362bf21 3.9.1
.json
model_loading_uri
 failed:
Load model from 
onnxruntime::LoadOrtModelBytes
 bytes were able to be read.
 failed. Only 
list too long
localtime_s(&local_tm, &in_time_t) == 0
onnxruntime::`anonymous-namespace'::GetCurrentTimeString
onnxruntime::IOBinding::BindInput
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\IOBinding.cc
 it.second=
 index=
Size mismatch:
mapped_feed_names_.size() == feed_names_.size()
onnxruntime::SyncProviders
onnxruntime::IOBinding::SynchronizeInputs
onnxruntime::IOBinding::SynchronizeOutputs
Size mismatch
mapped_output_names_.size() == output_names_.size()
onnxruntime::IOBinding::BindOutputImpl
p_provider
env_ptr == p_instance_.get()
OrtEnv::Release
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\ort_env.cc
session_options
value
parse error
parse_error
, column 
 at line 
invalid_iterator
type_error
out_of_range
ort_config
Unsupported value for intra_op_num_threads: 
onnxruntime::SetIntraOpNumThreads
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\inference_session_utils.cc
Setting intra_op_num_threads to 
Unsupported value for inter_op_num_threads: 
onnxruntime::SetInterOpNumThreads
Setting inter_op_num_threads to 
Unsupported execution_mode value in ORT config: 
onnxruntime::SetExecutionMode
Sequential mode
Parallel mode
Setting execution_mode to 
Setting graph_optimization_level to ORT_DISABLE_ALL
onnxruntime::SetGraphOptimizationLevel
Setting graph_optimization_level to ORT_ENABLE_BASIC
Setting graph_optimization_level to ORT_ENABLE_EXTENDED
Setting graph_optimization_level to ORT_ENABLE_ALL
Unsupported graph_optimization_level value in ORT config: 
Unsupported value for enable_profiling option: 
onnxruntime::SetEnableProfiling
Setting enable_profiling to 
Json stored in the `ort_config` key cannot be parsed. Error message: 
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto::<lambda_98c68a30f5b1cb5acbbe1d8255ff290f>::operator ()
The Model Proto has already been checked for the ORT config json.
Found session/run/environment configuration in the model file to be used while running the model
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto
ORT config json from the model: 
The Model Proto hasn't been checked for the ORT config json.
Did not find session options in the model file to be used while running the model
onnxruntime::inference_session_utils::JsonConfigParser::ParseSessionOptionsFromModelProto
intra_op_num_threads
intra_op_num_threads option in the model file must be an integer
inter_op_num_threads
inter_op_num_threads option in the model file must be an integer
execution_mode
execution_mode option in the model file must be an integer
graph_optimization_level
graph_optimization_level option in the model file must be an integer
enable_profiling
enable_profiling option in the model file must be an integer
Ignoring unsupported session option in ORT config: 
' not found
key '
cannot use at() with 
cannot use key() for non-object iterators
invalid map<K, T> key
object
array
string
boolean
binary
discarded
number
cannot compare iterators of different containers
cannot get value
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<U+%.4X>
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
vector<bool> too long
object key
object separator
number overflow parsing '
excessive array size: 
excessive object size: 
iterator does not fit current value
iterator out of range
cannot use erase() with 
type must be number, but is 
com.microsoft
org.pytorch.aten
com.microsoft.experimental
com.microsoft.nchwc
com.ms.internal.nhwc
 Target=
Mismatch between source and target type. Source=
[ShapeInferenceError] 
Unsupported Source/Target type=
unknown
tensor(uint32)
tensor(uint64)
tensor(int32)
tensor(int64)
tensor(float16)
tensor(float)
tensor(double)
tensor(bfloat16)
tensor(uint8)
tensor(uint16)
tensor(int8)
tensor(int16)
seq(tensor(uint8))
seq(tensor(uint16))
seq(tensor(uint32))
seq(tensor(uint64))
seq(tensor(int8))
seq(tensor(int16))
seq(tensor(int32))
seq(tensor(int64))
seq(tensor(float16))
seq(tensor(float))
seq(tensor(double))
tensor(string)
tensor(bool)
tensor(complex64)
tensor(complex128)
seq(tensor(string))
seq(tensor(bool))
seq(tensor(complex64))
seq(tensor(complex128))
seq(tensor(bfloat16))
Schema error: 
 line 
, but it is already registered from file 
) from file 
 version: 
 (domain: 
Trying to register schema with name 
 known by the checker.
, but its domain is not
in onnx/defs/schema.h).
forgot to update the version range in DomainToVersionRange 
bumped the operator version but 
] (usually, this means you 
in the inclusive range [
, but its version is not 
Only CPU allocators can be shared between multiple sessions for now.
An allocator for this device has already been registered for sharing.
Only CPU devices are supported for now.
Received invalid value for arena extend strategy. Valid values can be either 0, 1 or -1.
No allocator for this device has been registered for sharing.
Exception caught: 
intra-op
inter-op
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\environment.cc
MemcpyFromHost
input
output
Constrain to all fixed size tensor and sequence types. If the dtype attribute is not provided this must be a valid output type.
MemcpyToHost
onnxruntime::GraphTransformer::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer.cc
onnxruntime::GraphTransformerManager::ApplyTransformers
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer_mgr.cc
This transformer is already registered 
onnxruntime::GraphTransformer::Recurse
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/optimizer/graph_transformer.h
InsertedCast_
cast node to cast from float16 to float32 on cpu
RemoveDuplicateCastTransformer
onnxruntime::RemoveDuplicateCastTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\insert_cast_transformer.cc
onnxruntime::InsertCastTransformer::ApplyImpl
dtype
InsertCastTransformer works on the assumption that `dtype` attribute holds an integer.
dtype_attribute->second.has_i()
ACLExecutionProvider
ArmNNExecutionProvider
ROCMExecutionProvider
NhwcTransformer
QDQFinalCleanupTransformer
session.disable_quant_qdq
session.enable_quant_qdq_cleanup
optimization.enable_gelu_approximation
session.qdqisint8allowed
AttentionFusion
BiasDropoutFusion
BiasGeluFusion
BiasSoftmaxFusion
CastElimination
CommonSubexpressionElimination
ConvAddFusion
ConvBNFusion
ConvMulFusion
DivMulFusion
EliminateDropout
Dropout
DynamicQuantizeMatMulFusion
EmbedLayerNormFusion
ExpandElimination
Expand
FastGeluFusion
GeluApproximation
GeluFusion
GemmActivationFusion
GemmSumFusion
GemmTransposeFusion
EliminateIdentity
Identity
LayerNormFusion
SimplifiedLayerNormFusion
MatMulAddFusion
MatMulIntegerToFloatFusion
MatMulScaleFusion
MatmulTransposeFusion
NoopElimination
NotWhereFusion
Where
ClipQuantRewrite
QDQPropagationTransformer
QDQS8ToU8Transformer
ReluQuantRewrite
FuseReluClip
ReshapeFusion
SkipLayerNormFusion
EliminateSlice
Slice
TransposeOptimizer
UnsqueezeElimination
Unsqueeze
_RuleBasedTransformer
Level
Unsupported optimization level: 
onnxruntime::optimizer_utils::GenerateRewriteRules
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer_utils.cc
onnxruntime::optimizer_utils::GenerateRuleBasedGraphTransformer
onnxruntime::optimizer_utils::GenerateTransformers
onnxruntime::optimizer_utils::GenerateTransformersForMinimalBuild
VitisAIExecutionProvider
MIGraphXExecutionProvider
onnxruntime::Node::ForEachWithIndex
onnxruntime::MemcpyTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\transformer_memcpy.cc
onnxruntime::TransformerMemcpyImpl::ProcessDefs
' doesn't support memcpy 
Execution type '
Memcpy
Copy from/to host memory
dup_replacements.find(&arg) == dup_replacements.end()
onnxruntime::TransformerMemcpyImpl::ProcessInitializers::<lambda_055b4d24f8a1f4b549310d8384e8330c>::operator ()
onnxruntime::TransformerMemcpyImpl::ProcessInitializers
Squeeze
Gather
Transpose
ai.onnx
 does not match rank 
Permutation length 
perm.size() == gsl::narrow_cast<size_t>(shape_proto->dim_size())
onnxruntime::ApiValueInfo::PermuteDims
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\transpose_optimizer\optimizer_api_impl.cc
 out of bounds for shape 
Permutation entry 
0 <= p && p_int < shape_proto->dim_size()
Failed to get size of TensorProto
size >= 0
onnxruntime::ApiTensor::NumElements
onnxruntime::ApiTensor::Data
No NodeArg found for name 
node_arg_ != nullptr
onnxruntime::ApiGraph::GetValueInfo
Failed to find initializer for name: 
success
onnxruntime::ApiGraph::TransposeInitializer
Failed to find initializer to reshape with name 
onnxruntime::ApiGraph::ReshapeInitializer
 to have different number of elements
Cannot reshape initializer 
new_num_elts == old_num_elts
Added in transpose optimizer
 provided for op: 
Transpose optimizer is expected to add only onnx domain ops. Domain: 
domain == kOnnxDomain
onnxruntime::GetSinceVersionForNewOp
Onnx domain not found in opset imports.
opset_import_iter != domain_to_version_map.end()
An entry for this node should be added in onnx_ops_available_versions and static_kernel_hashes map.
Transpose Optimizer is adding an unexpected node: 
iter != onnx_ops_available_versions.end()
const_transpose_optimizer
Existing destination type is not compatible with source type.
dst_type->value_case() == src_type->value_case() && (!dst_data_element_type_present || dst_data_element_type == src_data_element_type)
onnxruntime::ApiGraph::CopyValueInfo
Resize
FusedConv
QLinearAveragePool
QLinearGlobalAveragePool
channels_last
Optimization after layout transformation failed: 
onnxruntime::RuleBasedGraphTransformer::ApplyRulesOnNode
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\rule_based_graph_transformer.cc
onnxruntime::RuleBasedGraphTransformer::ApplyImpl
index < nodes_.size() && ((node = nodes_[index]) != nullptr || !required)
onnxruntime::NodesToOptimize::GetNode
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/selectors_actions/helpers.h
Sigmoid
LeakyRelu
HardSigmoid
onnxruntime::`anonymous-namespace'::actions::FuseConvActivation::ExtraAttributes
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_activation_fusion.cc
activation
alpha
Failed to get Clip min/max constants.
optimizer_utils::GetClipConstantMinMax(state.graph, *activation, min, max)
activation_params
Expected Conv then Add.
conv.GetOutputEdgesCount() == 1 && conv.OutputNodesBegin()->OpType() == "Add"
onnxruntime::`anonymous-namespace'::actions::FuseConvAddRelu::ValueMoves
ConvAct
ConvAddRelu
ConvActivationFusion
onnxruntime::NhwcTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\nhwc_transformer.cc
QLinearConv
onnxruntime::QDQFinalCleanupTransformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_final_cleanup.cc
Reshape
MaxPool
dropDQ
ArgMax
AveragePool
GlobalAveragePool
Concat
MatMul
QDQSelectorActionTransformer
onnxruntime::Initializer::Initializer
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/initializer.h
size is different
size_ == size
unsupported data type: 
ReadExternalRawData() failed: 
input_indices.size() == expected_values.size() && input_indices.size() > 0
onnxruntime::AttentionFusionHelper::CheckSliceParameters
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/attention_fusion_helper.h
Slice does not have enough number of inputs
Slice ends is less than INT_MAX
Expected value:
Slice parameter is not expected. Input index:
Start MatchGemmSubgraph
onnxruntime::AttentionFusionHelper::MatchGemmSubgraph
Shape
Faild to match gemm path
Input of reshape_before_gemm is not the input of subgraph
Output edge count not expected for nodes in gemm path
Gemm does not have 3 inputs
Gemm bias is not constant
Gemm bias shape not expected
CheckSliceParameters return false
concat first input value is not -1
Faild to match concat node for Gather paths
concat_after_gather does not have expected number of inputs or output edges
concat_after_gather input 2 does not have expected value
Faild to match gemm gather path
Output edge count not expected for nodes in gemm gather path
unsqueeze_after_gather axes value not expected
gather axis value not expected
gather input 1 value is not expected
Pass MatchGemmSubgraph
Start ValidateGemmInitializer
onnxruntime::AttentionFusionHelper::ValidateGemmInitializer
Gemm bias is not constant initializer
Gemm bias shape is not expected
Gemm weight is not constant initializer
Gemm weight shape is not expected
Pass ValidateGemmInitializer
unidir mask is not constant
onnxruntime::AttentionFusionHelper::ValidateUnidirMask
unidir mask shape not expected
This optimizer does not support external data for unidirectional mask right now
Mask is neither unidirectional nor all ones
Expect mask data type is uint8 or float
Start MatchUnidirMaskSubgraph
onnxruntime::AttentionFusionHelper::MatchUnidirMaskSubgraph
Faild to match the path (Div-->Where-->Add) for unidirectional mask
Faild to match path 1 for unidirectional mask
Output edge count not expected for nodes in path 1 of unidirectional mask
Div and Shape1 does not have edge
CheckSliceParameters returns false for last_slice
CheckSliceParameters returns false for mask_slice
ValidateUnidirMask returns false for mask_slice
CheckSliceParameters returns false for slice1
Faild to match path 2 for unidirectional mask
Output edge count not expected for unsqueeze2 of unidirectional mask
Faild to match path 3 for unidirectional mask
Output edge count not expected for unsqueeze3 of unidirectional mask
Faild to match path 4 for unidirectional mask
Div and Shape does not have edge
Output edge count not expected for squeeze_2/slices2/shape2 of unidirectional mask
CheckSliceParameters return false for slice2
Pass MatchUnidirMaskSubgraph
Start MatchInputMaskSubgraph
onnxruntime::AttentionFusionHelper::MatchInputMaskSubgraph
Softmax
Failed to find Softmax node
Output edge count not expected for Softmax
Failed to find path for mask
Output edge count not expected for mask nodes
Softmax attribute axis is expected to be 3
mask_unsqueeze_1 axes not matched. Expect: 1
mask_unsqueeze_2 axes not matched. Expect: 2
mask_sub const input not matched
mask_mul const input not matched
Pass MatchInputMaskSubgraph
Start MatchInputMaskSubgraphDistilBert
Equal
Failed to find mask path
where const not matched.
Failed to find shape path
equal const not matched.
Failed to find reshape shape path 1
Failed to find reshape shape path 2
gather indices not matched.
Pass MatchInputMaskSubgraphDistilBert
Start MatchPastSubgraph
onnxruntime::AttentionFusionHelper::MatchPastSubgraph
Failed to find path for past_k
Failed to find path for present_k
Failed to find path for present_v and past_v
Failed to match v_concat
past_k_transpose perm attribute not matched
present_k_transpose perm attribute not matched
present_k_unsqueeze axes value not expected
present_v_unsqueeze axes value not expected
past_v_gather indices != 1
past_k_gather indices != 0
past_v_gather and past_k_gather does not have same past input
Output edge count not expected for nodes in past subgraph
Pass MatchPastSubgraph
onnxruntime::AttentionFusionHelper::CheckDistilBertReshapeShape
Start CheckNodesInPathV
onnxruntime::AttentionFusionHelper::CheckNodesInPathV
Output edge count not expected for nodes in path v
Failed in match Transpose attribute perm. Expected: 0, 2, 1, 3
Failed in match v_transpose attribute perm. Expected: 0, 2, 1, 3
hidden_size != num_heads * head_size
v_reshape initializer value is not expected
Pass CheckNodesInPathV
reshape initializer value is not expected
Start CheckNodesInPathQ
onnxruntime::AttentionFusionHelper::CheckNodesInPathQ
q_reshape const not matched
qk_div const not matched.
q_transpose perm attribute not matched
Pass CheckNodesInPathQ
Start CheckNodesInPathK
onnxruntime::AttentionFusionHelper::CheckNodesInPathK
k_transpose has not perm attribute
k_transpose perm attribute not matched
k_reshape const not matched
Pass CheckNodesInPathK
Mask_Int32
Cast mask from int64 to int32
MaskCast
Start FuseGptAttention
onnxruntime::AttentionFusionHelper::FuseGptAttention
Faild to find path to qkv_matmul
Split
Faild to find path v to Split
CheckNodesInPathV return false
MatchInputMaskSubgraph returns false
MatchUnidirMaskSubgraph returns NULL
Failed to find path for q
q and v are not from same Split node
CheckNodesInPathQ returns false
Using transpose optimized pattern
opt_k_transpose perm attribute not matched
Failed to find path for k
k and v are not from same Split node
CheckNodesInPathK returns false
MatchPastSubgraph returns false
Fused Attention subgraphs 
Attention
num_heads
unidirectional
Fused an attention node for GPT.
qkv_weights
qkv_bias
Mask shape is unknown or not 2D, or data type unknown
onnxruntime::ConvertMaskToInt32
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\attention_fusion.cc
Mask data type is not int32 or int64 or float32
onnxruntime::AttentionFusion::ApplyImpl
LayerNormalization
shape of layer norm bias tensor not expected
Total fused Attention node count: 
onnxruntime::FuseSubGraphQKImpl
q root should be layer normalization
q_matmul and q_add shape not matched
k root is not layer norm
k_matmul and k_add shape not matched
Failed to load Q, K and V weights, or data type is not float or float16.
Failed to load Q, K and V bias tensors, or data type is not float or float16.
Failed to convert mask to int32
onnxruntime::FuseSubGraphQK
Fused an attention node.
onnxruntime::FuseSubGraphQKDistilBert
Faild to find path v
onnxruntime::AttentionFusion::FuseSubGraph
Output edge count not expected for Add or MatMul in path v
Failed in match v_matmul and v_add input shape
Failed in match input mask subgraph
onnxruntime::BiasDropoutFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_dropout_fusion.cc
BiasDropout
fused Add-Dropout-(Add) for 
onnxruntime::BiasGeluFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_gelu_fusion.cc
FastGelu
BiasGelu
fused Add and Gelu
 and 
 is not in valid range [-
axis 
axis >= -tensor_rank && axis <= tensor_rank - 1
onnxruntime::HandleNegativeAxis
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/common.h
 into softmax(input + bias)
fused 
BiasSoftmax
softmax_axis
broadcast_axis
onnxruntime::BiasSoftmaxFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_softmax_fusion.cc
onnxruntime::CommonSubexpressionElimination::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\common_subexpression_elimination.cc
representative.output_index != kInvalidOutputIndex
] because it's the graph's output.
 of node 
Not eliminating output 
Could not find OrtValue with name '
ConstantFolding
start
DequantizeLinear
onnxruntime::ConstantFolding::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\constant_folding.cc
 node '
can't constant fold 
Could not find a CPU kernel and hence 
fetches.size() == node->OutputDefs().size()
. Can't constant fold 
Unsupported output type of 
data type is not supported
onnxruntime::Initializer::ToProto
conv_W_tensor_proto
onnxruntime::ConvAddFusion::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_add_fusion.cc
add_B_tensor_proto
conv_B_tensor_proto
ConvAddFusion_B_
ConvAddFusion_Add_B_
epsilon
bn_scale_tensor_proto
onnxruntime::ConvBNFusion::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_bn_fusion.cc
bn_B_tensor_proto
bn_mean_tensor_proto
bn_var_tensor_proto
ConvBnFusion_W_
ConvBnFusion_BN_B_
BatchNormalization
onnxruntime::ConvMulFusion::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_mul_fusion.cc
mul_B_tensor_proto
ConvMulFusion_W_
ConvMulFusion_Mul_B_
onnxruntime::DynamicQuantizeMatMulFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\dynamic_quantize_matmul_fusion.cc
MatMulIntegerToFloat
DynamicQuantizeLinear
DynamicQuantizeMatMul
+_Int32
Cast Input from int64 to int32
_Cast
Input shape is unknown or not 2D, or data type unknown
onnxruntime::CheckInput
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\embed_layer_norm_fusion.cc
Input data type is not int32 or int64
Failed to find path 1 of position shape.
onnxruntime::MatchInputToConcatSubgraph
Output edge count not expected for nodes in path 1 of position shape.
Second input of Gather in path 1 of position shape should be a constant with value 0.
Failed to find path 2 of position shape.
Output edge count not expected for nodes in path 2 of position shape.
Gather node in path 2 is not linked to another subgraph.
Second input of Gather in path 2 of position shape should be a constant with value 1.
The parent of two shape nodes are expected to be input_ids.
two paths share the same shape
NonZero
ConstantOfShape
Range
Output edge count not expected for nodes in path1.
onnxruntime::MatchPositionEmbeddingSubgraphsFromGather
The first input of Range should be a constant with value 0.
The third input of Range should be a constant with value 1.
Second input of Gather should be a constant with value 1. 
Failed to match Shape node. 
The parent of shape nodes are expected to be input_ids.
Optional position subgraph nodes number of outputs unexpected.
Optional position subgraph nodes Where node is expected to be the parent of Reshape.
Failed to match position subgraph.
position_embeddings
mask_index
fused EmbedLayerNorm subgraphs 
EmbedLayerNormalization
Word embedding shape not expected.
onnxruntime::FuseSubGraph
Input is expected to have dim value in all dimensions.
Failed to get initializer tensor.
Position embedding shape not matched.
Position embedding data type shall be float or float16.
Failed to match position embedding subgraph.
Failed to get position embedding weights.
Position embedding shape is not expected.
Input id is not valid. 
Segment id is not valid. 
Input_ids and segment id should have the same shape. 
Gamma should be of shape (hidden_size). 
Beta should be of shape (hidden_size). 
onnxruntime::FuseSubGraphDistilBert
onnxruntime::EmbedLayerNormFusion::ApplyImpl
onnxruntime::FastGeluFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\fast_gelu_fusion.cc
fast_gelu_output
fused GPT2Gelu subgraphs 
GPT2Gelu
'7=*BL?
FreeDimensionOverrideTransformer
Invalid free dimension override.
onnxruntime::FreeDimensionOverrideTransformer::FreeDimensionOverrideTransformer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\free_dim_override_transformer.cc
Conflicting free dimension overrides.
which does not equal the specified override of 
with a fixed dimension size 
The model has input '
onnxruntime::FreeDimensionOverrideTransformer::ApplyImpl
onnxruntime::GeluApproximation::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gelu_approximation.cc
Gelu approximation
Total Gelu Approximation (FastGelu) node count: 
onnxruntime::GeluFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gelu_fusion.cc
fused Gelu subgraphs 
Softplus
Softsign
ScaledTanh
ParametricSoftplus
ThresholdedRelu
onnxruntime::GemmActivationFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gemm_activation_fusion.cc
with activation 
fused Gemm 
FusedGemm
activation_
transA
transB
new_gemm_input_defs.size() == 3
onnxruntime::GemmSumFusion::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gemm_sum_fusion.cc
new_gemm_output_defs.size() == 1
Fused Gemm with Sum
_sum_transformed
gemm_input_edge.src_arg_index < 2
sum_output_edge.src_arg_index == 0
!sum_input_moved
graph.RemoveNode(gemm_node.Index())
sum_node.GetOutputEdgesCount() == 0
graph.RemoveNode(sum_node.Index())
other_sum_input != nullptr
onnxruntime::GemmSumFusion::SatisfyCondition
Fused Gemm with Transpose
_transformed
onnxruntime::LayerNormFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\layer_norm_fusion.cc
ReduceMean
fused LayerNorm subgraphs 
onnxruntime::SimplifiedLayerNormFusion::ApplyImpl
Cast_Scale
cast scale of layer norm
SimplifiedLayerNormalization
layer_norm_out
cast output of layer norm
onnxruntime::MatMulAddFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_add_fusion.cc
fused Matmul and Add 
onnxruntime::MatMulIntegerToFloatFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_integer_to_float.cc
MatMulInteger
Unsupported data type: 
Constant initializer NodeArg shape should not be null. NodeArg: 
shape
onnxruntime::`anonymous-namespace'::GetScalarConstantInitializer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_scale_fusion.cc
div_inputs.size() == 2
onnxruntime::`anonymous-namespace'::GetScaleFromNode
mul_inputs.size() == 2
input_node.InputDefs().size() == 2 && scale_and_index->second < 2
onnxruntime::`anonymous-namespace'::GetInputNodeMerges
output_node.OutputDefs().size() == 1
onnxruntime::`anonymous-namespace'::GetOutputNodeMerges
FusedMatMul
Fused MatMul and Scale
_FusedMatMulAndScale
onnxruntime::MatMulScaleFusion::ApplyImpl
onnxruntime::utils::mltype_dispatcher_internal::UnsupportedTypeDefaultPolicy<class onnxruntime::common::Status>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::BFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<double>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<float>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::MLFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<__int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<int>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned __int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned int>::operator ()
transpose_node.InputDefs().size() == 1
onnxruntime::GetTransposePerms
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_transpose_fusion.cc
!node_consumers.empty()
onnxruntime::UpdateConsumerCount
cast != nullptr
onnxruntime::ReorderCastAndTranspose
Created a new Cast node to interchange Cast and Transpose nodes
Created a new Transpose node to interchange Cast and Transpose nodes
onnxruntime::MatmulTransposeFusion::ApplyImpl
transBatchA
transBatchB
fused MatMul and Transpose 
MatMul_With_Transpose
deque<T> too long
reorder
ReorderInput
strides
dilations
kernel_shape
auto_pad
NOTSET
VALID
group
Buffer overflow
output_channels <= nchwc_output_channels
onnxruntime::NchwcTransformerImpl::TransformConv
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\nchwc_transformer.cc
_nchwc
reshape
spatial
bn_scale
_bn_nchwc
ReorderOutput
channels
nearest
linear
coordinate_transformation_mode
asymmetric
align_corners
half_pixel
nearest_mode
floor
Upsample
scales
GlobalMaxPool
onnxruntime::NchwcTransformer::ApplyImpl
Unexpected data type for QuantizeLinear input y_zero_point of 
onnxruntime::GetQConstantLowerUpper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\clip_quantizelinear.cc
QuantizeLinear
Invalid node index 
node != nullptr
onnxruntime::graph_utils::ExtendedGraphEdge::GetNodeAtEnd
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/extended_graph_edge.h
onnxruntime::graph_utils::ExtendedGraphEdge::GetMutableNodeAtEnd
node_input_def_idx >= 0 && static_cast<size_t>(node_input_def_idx) < node_inputs.size()
onnxruntime::graph_utils::ExtendedGraphEdge::TryCreateFromInputOrInitializerToNode
node_output_def_idx >= 0 && static_cast<size_t>(node_output_def_idx) < node_outputs.size()
onnxruntime::graph_utils::ExtendedGraphEdge::TryCreateFromNodeToOutput
At least one graph node must be specified in the propagation edge.
src_node || dst_node
onnxruntime::`anonymous-namespace'::InsertQDQPair
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_propagation.cc
 at NodeArg "
", index: 
node ("
Inserting Q/DQ pair between 
_pre_q
_post_dq
Inserted by QDQPropagationTransformer
Failed to set op schema for added Q node.
Failed to set op schema for added DQ node.
src_node != nullptr
onnxruntime::`anonymous-namespace'::GetPreviousPropagationEdge
dst_node != nullptr
onnxruntime::`anonymous-namespace'::GetNextPropagationEdge
onnxruntime::`anonymous-namespace'::PropagateDQForward
onnxruntime::`anonymous-namespace'::PropagateQBackward
onnxruntime::QDQPropagationTransformer::ApplyImpl
onnxruntime::QDQS8ToU8Transformer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_s8_to_u8.cc
qdq_s8_to_u8_zp_conversion
qdq_s8_to_u8_quant
is not supported.
data type 
Unexpected data type for Clip 'min' input of 
onnxruntime::FuseReluClip::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\relu_clip_fusion.cc
_min_zero_constant
FuseReluClip_
onnxruntime::ReshapeFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\reshape_fusion.cc
allowzero
Fused reshape node: 
Total fused reshape node count: 
starts
Cannot replace concat node with initializer:
onnxruntime::ReshapeFusion::Fuse_Subgraph
onnxruntime::SkipLayerNormFusion::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\skip_layer_norm_fusion.cc
fused SkipLayerNorm subgraphs 
SkipLayerNormalization
Transpose optimizer failed: 
onnxruntime::TransposeOptimizer::ApplyImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\transpose_optimizer\ort_transpose_optimizer.cc
UnsqueezeElimination_
UnsqueezeElimination cannot remove node 
onnxruntime::UnsqueezeElimination::Apply
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\unsqueeze_elimination.cc
keepdims
noop_with_empty_axes
NhwcMaxPool
storage_order
Reciprocal
Floor
Round
IsInf
IsNaN
Shrink
HardSwish
Asinh
Acosh
Atanh
PRelu
BitShift
Greater
GreaterOrEqual
LessOrEqual
CastLike
ReduceSum
ReduceLogSum
ReduceLogSumExp
ReduceMax
ReduceMin
ReduceProd
ReduceSumSquare
ReduceL1
ReduceL2
ArgMin
Hardmax
LogSoftmax
com.microsoft.QLinearReduceMean
com.microsoft.QLinearSigmoid
com.microsoft.QLinearLeakyRelu
com.microsoft.QLinearConcat
com.microsoft.QLinearAdd
com.microsoft.QLinearMul
com.microsoft.QLinearAveragePool
com.microsoft.QLinearGlobalAveragePool
com.microsoft.
Unsupported ONNX opset
GridSample
Index out of range
onnxruntime::`anonymous-namespace'::MoveInputOutputImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\helpers.cc
Node index value is too large to save to ORT format model: 
node_idx <= NodesToOptimizeIndices::kEmptyNodeIndex
onnxruntime::GetNodesToOptimizeIndices::<lambda_069fd95563047ae0c4e53fb8dd3a0690>::operator ()
A target node must be set.
target_node != NodesToOptimizeIndices::kEmptyNodeIndex
onnxruntime::NodesToOptimizeIndicesBuilder::Build
onnxruntime::MoveInputOutput
onnxruntime::MergeIntoTarget::Run
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\actions.cc
onnxruntime::CreateReplacementNode
onnxruntime::ReplaceWithNew::Run
onnxruntime::ReplaceWithNew::RunForSave
Failed to set node op schema.
Failed to remove node.
Existing registration with name 
inserted_in_name_to_entry
onnxruntime::SelectorActionRegistry::RegisterSelectorAndAction
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\selector_action_transformer.cc
Matched 
onnxruntime::MatchAndProcess
onnxruntime::SelectorActionTransformer::ApplySelectorsAndActions
Not enough produced nodes in the runtime optimization record.
onnxruntime::RegisterProducedNodesWithGraph
Too many produced nodes in the runtime optimization record.
onnxruntime::SelectorActionTransformer::ApplySavedRuntimeOptimizations
 for transformer 
Applying runtime optimization action 
Missing action 
Nodes to optimize are not valid, skipping action.
RandomUniform
RandomNormal
RandomUniformLike
RandomNormalLike
Multinomial
Unexpected data type for Clip input of 
onnxruntime::optimizer_utils::GetClipConstantMinMax::<lambda_4f21cebc490a3d885511ea724efbe189>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\utils.cc
q_or_dq_input_defs.size() >= 2
onnxruntime::QDQ::QOrDQNodeHasConstantScalarScaleAndZeroPoint
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_util.cc
generated at runtime
QLinear
init_optional_zero_point_int8_b33fd0fa-cd7b-4b10-ae5a-df64cabfe1f8
init_optional_zero_point_uint8_b33f88f7-c464-43e3-8692-97ac832bb14a
QGemm
External data type must not be UNDEFINED or STRING.
onnxruntime::Initializer::ReadExternalRawData
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\initializer.cc
model_path must not be empty. Ensure that a path is provided when the model is created or loaded.
, external_data.length: 
Computed size: 
TensorProto external data size mismatch. 
onnxruntime::OptimizerExecutionFrame::Info::{ctor}::<lambda_4de083bd9feef97ef116b9ac6f248cfc>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\optimizer_execution_frame.cc
Failed to get allocator for optimizer
allocator_ptr_
onnxruntime::OptimizerExecutionFrame::Info::Info
Tried to allocate without valid type information, ort_value index=
DnnlExecutionProvider
OpenVINOExecutionProvider
NupharExecutionProvider
NnapiExecutionProvider
RknpuExecutionProvider
CoreMLExecutionProvider
TvmExecutionProvider
onnxruntime::RegisterOnnxOperatorKernels
D:\a\_work\1\s\onnxruntime\build\Windows\RelWithDebInfo\op_reduction.generated\onnxruntime\core\providers\cpu\cpu_execution_provider.cc
onnxruntime::ml::RegisterOnnxMLOperatorKernels
onnxruntime::RegisterCPUKernels
onnxruntime::CPUExecutionProvider::GetKernelRegistry
v >= 0 && static_cast<uint64_t>(v) <= std::numeric_limits<size_t>::max()
onnxruntime::TransposeBase::TransposeBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/transpose.h
 is outside range.
Attribute perm of Transpose has an invalid value. Value 
 is repeated.
 does not align with rank of input data: 
perm: 
Method IncrementIndexAndComputeOffset assumes this value is strictly positive.
naxes > 0
onnxruntime::IncrementIndexAndComputeOffsetSetup
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\transpose.cc
(local_source >= source) && (local_source < source + num_blocks * blocksize)
onnxruntime::DoTransposeImpl
Transpose not implemented for empty tensors.
num_axes > 0
(local_source >= source) && (local_source < source + num_blocks * num_elts_in_block)
Transpose of element size not supported in this build. Size=
onnxruntime::DoTransposeEltWise
(local_source >= source) && (local_source < source + num_blocks)
Mismatched data types between input and output Tensors. 
input_tensor_ptr != nullptr
onnxruntime::Transpose::Compute
(local_source >= source) && (local_source < source + sizeof(T) * num_blocks)
onnxruntime::TypedDoTransposeEltWise
center_point_box
NonMaxSuppression
boxes_tensor
onnxruntime::NonMaxSuppressionBase::PrepareCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.cc
scores_tensor
boxes must be a 3D tensor.
scores must be a 3D tensor.
boxes and scores should have same num_batches.
boxes and scores should have same spatial_dimension.
The most inner dimension in boxes must have 4 data.
iou_threshold must be in range [0, 1].
onnxruntime::NonMaxSuppressionBase::GetThresholdsFromInputs
Missing/Invalid 'axis' attribute value
info.GetAttr<int64_t>("axis", &axis_).IsOK()
onnxruntime::GatherBase::GatherBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gatherbase.h
onnxruntime::Gather::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gather.cc
Gather Tind type not supported in this build.
 must be within the inclusive range [
indices element out of data bounds, idx=
Missing/Invalid 'axes' attribute value
info.GetAttrs("axes", axes_).IsOK()
onnxruntime::UnsqueezeBase::UnsqueezeBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/unsqueeze.h
X != nullptr
onnxruntime::UnsqueezeBase::PrepareCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\unsqueeze.cc
Axes input is null
axes_tensor != nullptr
An axes tensor must be a scalar or a 1-D tensor.
axes_tensor->Shape().NumDimensions() == 0 || axes_tensor->Shape().NumDimensions() == 1
'axes' has an out of range axis
'axes' has a duplicate axis
nullptr != p.output_tensor
onnxruntime::Unsqueeze::Compute
onnxruntime::contrib::RegisterNchwcKernels
D:\a\_work\1\s\onnxruntime\build\Windows\RelWithDebInfo\op_reduction.generated\onnxruntime\contrib_ops\cpu\cpu_contrib_kernels.cc
onnxruntime::contrib::RegisterQuantizationKernels
onnxruntime::contrib::RegisterCpuContribKernels
called_ == 1
onnxruntime::utils::mltype_dispatcher_internal::CallableDispatchableHelper::CheckCalledOnce
min_ <= max_
onnxruntime::clip_internal::Clip_6Base<float>::Clip_6Base
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/clip.h
min should be a scalar.
min->Shape().IsScalar()
onnxruntime::Clip::ComputeImpl<unsigned __int64>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\clip.cc
max should be a scalar.
max->Shape().IsScalar()
onnxruntime::Clip::ComputeImpl<__int64>::operator ()
onnxruntime::Clip::ComputeImpl<unsigned char>::operator ()
onnxruntime::Clip::ComputeImpl<signed char>::operator ()
onnxruntime::Clip::ComputeImpl<double>::operator ()
onnxruntime::Clip::ComputeImpl<float>::operator ()
'is defined.
No attribute with name:'
Attribute name and type don't match for '
input_size < std::numeric_limits<std::ptrdiff_t>::max()
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/element_wise_ranged_transform.h
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::Compute
onnxruntime::functors::ElementWiseRangedTransform<float>::Create
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\activation\activations.cc
unknown kernel type
onnxruntime::functors::ScaledTanh<float>::Init
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops/cpu/activations.h
onnxruntime::functors::ParametricSoftplus<float>::Init
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<float> >::ElementWiseKernel
onnxruntime::functors::Selu<float>::Init
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/activation/activations.h
gamma
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::ElementWiseKernel
onnxruntime::functors::HardSigmoid<float>::Init
5JCy7
~3a*~3a*~3a*~3a*A
5JCy7JCy7JCy7JCy7
8giP9giP9giP9giP9
Attempting to broadcast an axis by a dimension other than 1. 
axis == 1 || axis == largest
onnxruntime::BroadcastIterator::Init
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/element_wise_ops.h
onnxruntime::BroadcastIterator::Append
 is invalid.
Can broadcast 0 by 0 or 1. 
largest <= 1
onnxruntime::Broadcaster::Broadcaster
InputBroadcaster can only start at span boundary!
offset % span_size_ == 0
onnxruntime::InputBroadcaster::AdvanceBy
) for tensor of length:
Invalid start/ending offset [
start_offset >= 0 && real_end >= 0 && start_offset <= real_end && real_end <= len
onnxruntime::OutputBroadcaster::OutputBroadcaster
) are not at boundary of span with size:
Broadcast Output range [
start_offset % span_size == 0 && real_end % span_size == 0
onnxruntime::TensorAllocator::TensorAllocator
Unsupported X type: 
Must have 1 or more inputs
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\element_wise_ops.cc
ExpandBroadcastLooper should only have a shape for the second input.
!helper.HaveTwoTensorInputs()
onnxruntime::ExpandBroadcastLooper
Tensor with shape information must be 1 dimensional.
shape_data_tensor.Shape().GetDims().size() == 1
onnxruntime::UntypedExpand
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::Compute
Unsupported Y type: 
Invalid usage. Input 1 is a shape with no data.
onnxruntime::Expand_8<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute::<lambda_2288f63c5e7894f75698468e4f3eb00c>::operator ()
BroadcastLooper requires two tensors as input.
helper.HaveTwoTensorInputs()
onnxruntime::BroadcastLooper
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::ElementWiseKernel
direction
onnxruntime::Hardmax<float>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\hardmax.cc
Hardmax inputs N, D and N * D must be < 
onnxruntime::Softmax<float>::ComputeImplOpset13
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\softmax.cc
onnxruntime::Softmax<double>::ComputeImplOpset13
SAME_UPPER
SAME_LOWER
Unknown AutoPadType String
onnxruntime::StringToAutoPadType
Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.
ComputePad: pad type not supported.
onnxruntime::ComputePadAndOutputShape
A Conv/ConvTranspose node has both 'auto_pad' and 'pads' attributes
auto_pad == AutoPadType::NOTSET
onnxruntime::ConvAttributes::ConvAttributes
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/nn/conv_attributes.h
 kernel_shape: 
kernel_shape num_dims is not compatible with W num_dims.
kernel_shape is not compatible with W shape.
X num_dims does not match W num_dims.
 group: 
 kernel channels: 
Input channels C is not equal to kernel channels * group.
Output channels M is not divisible by group.
Not enough elements in strides. Expected: 
Not enough elements in kernel shape. Expected: 
Not enough elements in dilations. Expected: 
Not enough elements in pads. Expected: 
onnxruntime::ConvAttributes::InferOutputShape
Invalid input shape: 
onnxruntime::Conv<float>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\nn\conv.cc
`InlinedVector::at(size_type)` failed bounds check
GlobalLpPool
No kernel shape is set.
info.GetAttrs("kernel_shape", kernel_shape).IsOK()
onnxruntime::PoolAttributes::PoolAttributes
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/nn/pool_attributes.h
info.GetAttr<std::string>("auto_pad", &auto_padding).IsOK()
ceil_mode
count_include_pad
info.GetAttr<int64_t>("count_include_pad", &temp).IsOK()
info.GetAttr("storage_order", &storage_order).IsOK()
kernel_shape[dim] > 0
Pad should be smaller than kernel.
pads[dim] < kernel_shape[dim] && pads[dim + kernel_shape.size()] < kernel_shape[dim]
strides.size() == kernel_shape.size()
Dilations dimensions should match kernel shape
dilations.size() == kernel_shape.size()
Invalid input shape. Only N can be zero. Got:
input_shape.Size() > 0 || input_shape[0] == 0
onnxruntime::PoolAttributes::SetOutputSize
input_dims.size() >= 2
onnxruntime::PoolAttributes::InferOutputSize
Unsupported AutoPad Type.
onnxruntime::PoolAttributes::ComputeSizePadDilations
info.GetAttr<int64_t>("p", &p_).IsOK()
onnxruntime::PoolProcessContext::init
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/nn/pool_base.h
Input dimension cannot be less than 3.
onnxruntime::PoolBase::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\nn\pool.cc
Unsupported pooling size.
kernel_shape num_dims is not compatible with X num_dims.
LpPool
Unsupported pooling size : 
onnxruntime::MaxPoolV8::ComputeImpl
last_loop_red_size > 0
onnxruntime::ResultsNoTransposePrepareForReduce::ValidateNotEmpty
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\reduction\reduction_ops.cc
last_loop_size > 0
projected_index.size() > 0
must be overloaded.
onnxruntime::ValidateMustBeOverloaded
Only works on matrices with two dimensions.
fast_shape.size() == 2
onnxruntime::ValidateFastReduceKR
Output size mismatch.
fast_shape[0] == output.Shape().Size()
onnxruntime::ValidateFastReduceRK
fast_shape[1] == output.Shape().Size()
Only works on matrices with three dimensions.
fast_shape.size() == 3
onnxruntime::ValidateFastReduceKRK
fast_shape[0] * fast_shape[2] == output.Shape().Size()
onnxruntime::ValidateFastReduceRKR
Reduction on all axes, output size should be 1.
count == 1
onnxruntime::ValidateNoTransposeReduce
onnxruntime::ValidateCommonFastReduce
An axes tensor must be a vector tensor.
axes_tensor->Shape().NumDimensions() == 1
Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:
onnxruntime::ValidateKeepDims
info.GetAttr("keepdims", &keepdims).IsOK()
onnxruntime::ReduceKernelBase<1>::ReduceKernelBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/reduction/reduction_ops.h
select_last_index
onnxruntime::ReduceKernelBase<0>::ReduceKernelBase
 @forward
reverse
bidirectional
'. Must be one of 'forward', 'reverse', or 'bidirectional'.
Invalid 'direction' argument of '
onnxruntime::rnn::detail::MakeDirection
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/rnn/rnn_helpers.h
info.GetAttr("direction", &direction).IsOK()
onnxruntime::DeepCpuGruOp::DeepCpuGruOp
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/rnn/deep_cpu_gru.h
linear_before_reset
info.GetAttr("linear_before_reset", &int64_value).IsOK()
hidden_size
info.GetAttr("hidden_size", &int64_value).IsOK() && int64_value > 0
activations
activation_alpha
activation_beta
clip_ > 0.f
sigmoid
activation_func_names.size() == static_cast<size_t>(num_directions_) * 2
layout
Batchwise recurrent operations (layout == 1) are not supported. If you need support create a github issue with justification.
layout_ == 0
GRU operator does not support double yet
Invalid data type for GRU operator of 
onnxruntime::DeepCpuGruOp::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\deep_cpu_gru.cc
onnxruntime::DeepCpuGruOp::ComputeImpl
onnxruntime::Tensor::MutableDataAsSpan
lda >= K && ldb >= K && ldc >= N
onnxruntime::rnn::detail::ComputeGemm
A + (M * lda - (lda - K)) <= A_end
B + (N * ldb - (ldb - K)) <= B_end
C + (M * ldc - (ldc - N)) <= C_end
cur + size <= end
onnxruntime::rnn::detail::SafeRawConstPointer
offset + size <= size_t(span.size())
onnxruntime::rnn::detail::SafeRawPointer
onnxruntime::LSTMBase::LSTMBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\lstm_base.h
input_forget
activation_func_names.size() == static_cast<size_t>(num_directions_) * 3
onnxruntime::DeepCpuLstmOp::PrePack
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\deep_cpu_lstm.cc
LSTM operator does not support double yet
Invalid data type for LSTM operator of 
onnxruntime::DeepCpuLstmOp::Compute
invalid stoll argument
stoll argument out of range
invalid stoull argument
stoull argument out of range
invalid stod argument
stod argument out of range
onnxruntime::`anonymous-namespace'::GetIntermediateMLFloat16ToFloatTensor
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\cast_op.cc
Attribute to is not set.
onnxruntime::`anonymous-namespace'::Cast::Cast
snprintf() failed with return value: 
snprintf_result > 0
onnxruntime::`anonymous-namespace'::CastToString
Failed to write value with snprintf().
snprintf_result > 0 && gsl::narrow_cast<size_t>(snprintf_result) == buffer_span.size() - 1
CMust have valid 'axis' attribute
onnxruntime::ConcatBase::ConcatBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\concatbase.h
new_axis
onnxruntime::ConcatBase::PrepareForCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\concat.cc
input count mismatch
input != nullptr
Cannot concatenate scalars
 got: 
Ranks of input data are different, cannot concatenate them. expected rank: 
input_rank == reference_rank
 has mismatched dimensions of 
Non concat axis dimensions must match: Axis 
Data type mismatch
onnxruntime::ConcatBase::ComputeImpl
src and dst types must match
dst.DataType() == src.DataType()
onnxruntime::DispatchStridedCopy
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/copy.h
Unsupported input data type of 
last >= first
onnxruntime::StridedCopy::<lambda_aa638f082cd6e633ea8c394e1663fa60>::operator ()
counter.current_offset == last
onnxruntime::StridedCopy::<lambda_b92cd1be17f8632fbcc9dec212afe76b>::operator ()
src and dst must have same shape and not be rank 0.
dst_strides.size() == src_strides.size() && src_strides.size() == copy_shape.size() && !copy_shape.empty()
onnxruntime::StridedCopy
onnxruntime::StridedCopy::<lambda_d2c19ae18917b59844dd4110518387dd>::operator ()
onnxruntime::StridedCopy::<lambda_c8779530b1b47f6b819a3c840cb70825>::operator ()
onnxruntime::StridedCopy::<lambda_4f04249e04d07d50d630e12dc9f30f23>::operator ()
onnxruntime::StridedCopy::<lambda_f0ea35f12b551ef953688db40e1f4b34>::operator ()
onnxruntime::StridedCopy::<lambda_6bbfc6268021e2bfd0f1bd3e4700889b>::operator ()
onnxruntime::StridedCopy::<lambda_f563daf0e095e96808b0280be50284eb>::operator ()
onnxruntime::StridedCopy::<lambda_1a286ef6a47f06b31852d582b51b4ff5>::operator ()
onnxruntime::StridedCopy::<lambda_ab076180da33c991061bdac15a41448d>::operator ()
onnxruntime::IdentityOp<0>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/identity_op.h
Unable to get an allocator
onnxruntime::IdentityOp<1>::Compute
A dimension cannot be less than -1, got 
requested_shape[i] >= -1
onnxruntime::ReshapeHelper::ReshapeHelper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\reshape_helper.h
At most one dimension can be -1.
unknown_dim == -1
The dimension with value zero exceeds the dimension size of the input tensor.
i < input_shape.NumDimensions()
, requested shape:
The input tensor cannot be reshaped to the requested shape. Input shape:
size != 0 && (input_shape.Size() % size) == 0
gsl::narrow_cast<int64_t>(input_shape.Size()) == size
A shape tensor must be a vector tensor.
shapeTensor->Shape().NumDimensions() == 1
onnxruntime::Reshape::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/reshape.h
Missing or invalid starts and ends attribute
has_starts && has_ends && attr_starts_.size() == attr_ends_.size()
onnxruntime::SliceBase::SliceBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/slice.h
Invalid axes attribute, axes attribute (if present) should have the same size as starts/ends attributes
!has_axes || attr_axes_.size() == attr_starts_.size()
'axes' has an axis outside of the tensor dimension count
'axes' has duplicates
'step' value cannot be 0
dims.size() == extents.size() && dims.size() >= steps.size()
onnxruntime::SliceSkips::SliceSkips
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/utils.h
dims.size() == starts.size() && dims.size() == extents_.size() && dims.size() >= steps.size()
onnxruntime::SliceIteratorBase::Init
Unexpected element size of 
onnxruntime::SliceIteratorBase::CopyInnermostAxisNonSolitaryInnerStep
onnxruntime::SliceBase::PrepareForCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\slice.cc
Starts must be a 1-D array
onnxruntime::SliceBase::FillVectorsFromInput
Ends must be a 1-D array
Starts and ends shape mismatch
Starts and axes shape mismatch
Starts and steps shape mismatch
Data type for starts and ends inputs' is not supported in this build. Got 
Cannot slice scalars
onnxruntime::SliceBase::Compute
output == output_end
onnxruntime::SliceImpl::<lambda_8cc359b57ce5115b939fcfb339a96061>::operator ()
onnxruntime::SliceImpl::<lambda_0446c0939ee629ce947e593108d9f1b8>::operator ()
onnxruntime::SliceImpl::<lambda_46348fe74d258edec532e2c838ffd5ed>::operator ()
onnxruntime::SliceImpl::<lambda_278f0fd775f8a53bdddcb46b93819006>::operator ()
onnxruntime::SliceImpl::<lambda_23a04ec8efc34ba9c10f360679dafd19>::operator ()
split
Invalid value in 'split' attribute. All values must be > 0
std::all_of(split_sizes_.cbegin(), split_sizes_.cend(), [](int64_t value) { return value >= 0; })
onnxruntime::SplitBase::SplitBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/split.h
 NumOutputs=
 Axis=
Input cannot be split evenly on selected axis. Input shape=
 Sum of sizes in 'split' (must equal size of selected axis) was 
 Num entries in 'split' (must equal number of outputs) was 
 Input shape=
Cannot split using values in 'split' attribute. Axis=
Split operator does not support 
onnxruntime::Split::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\split.cc
An split tensor must be a vector tensor.
split_tensor->Shape().NumDimensions() == 1
onnxruntime::Split::ComputeImpl
. shape=
 must be 1 instead of 
Dimension of input 
input_shape[i] == 1
onnxruntime::SqueezeBase::ComputeOutputShape
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/squeeze.h
onnxruntime::Squeeze::Compute
Input count of Tile OP mismatch, the first one is empty
Input count of Tile OP mismatch, the second one is empty
the tensor to be tiled using Tile OP must be atleast 1 dimensional
'repeat' input tensor must be 1 dimensional
'repeat' input tensor must have the same length as the 'input' tensor
Tile doesn't support string type yet
!input_tensor.IsDataType<std::string>()
onnxruntime::Tile::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\tile.cc
Tile doesn't have an implementation yet for the type: 
invalid expand shape
onnxruntime::`anonymous-namespace'::ConstantOfShape::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\generator\constant_of_shape.cc
Unsupported output datatype with size: 
Must have a valid input shape.
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::PrepareCompute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/generator/constant_of_shape_base.h
Must have a single dimension
t_proto_p->dims_size() == 1
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::ConstantOfShapeBase
Must have a single dimension of 1
t_proto_p->dims()[0] == 1
Unsupported value attribute datatype with size: 
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValue
utils::HasDataType(t_proto)
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValueFromTensorProto
ONNX_NAMESPACE::TensorProto::DataType_IsValid(t_proto.data_type())
Tensor proto with external data for value attribute is not supported.
!utils::HasExternalData(t_proto)
Unsupported value attribute datatype: 
Attempt to retrieve final output before it was set.
final_output_mlvalue_
onnxruntime::scan::detail::OutputIterator::GetOutput
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/controlflow/scan_utils.h
info.GetAttr<ONNX_NAMESPACE::GraphProto>("body", &proto).IsOK()
onnxruntime::Scan<9>::Init
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\scan_9.cc
num_scan_inputs
info.GetAttr<int64_t>("num_scan_inputs", &num_scan_inputs_).IsOK()
scan_input_directions
scan_output_directions
scan_input_axes
 but expected 
Number of entries in 'scan_input_axes' was 
gsl::narrow_cast<int64_t>(input_axes_.size()) == num_scan_inputs_
scan_output_axes
Number of entries in 'scan_output_axes' was 
gsl::narrow_cast<int64_t>(output_axes_.size()) == num_scan_outputs
SetupSubgraphExecutionInfo should only be called once for each subgraph.
info_ == nullptr
onnxruntime::Scan<9>::SetupSubgraphExecutionInfo
CreateFeedsFetchesManager must be called prior to execution of graph.
feeds_fetches_manager_ && info_
onnxruntime::Scan<9>::Compute
Subgraph SessionState was not found for 'body' attribute.
session_state
onnxruntime::ScanImpl::Initialize
 dimensions or more but input had shape of 
 Expected 
Invalid scan input:
 has length of 
' dimension 
 but input '
Scan inputs have inconsistent sequence lengths. Previous value was 
. Input tensor rank was 
Invalid value in scan_input_axes for input 
onnxruntime::ScanImpl::ValidateInput
onnxruntime::ScanImpl::SetupInputs
 outputs but Scan expects 
Subgraph in 'body' produces 
onnxruntime::ScanImpl::AllocateOutputTensors
onnxruntime::ScanImpl::CreateLoopStateVariables
Output OrtValue has not been created for loop state variable output 
output_mlvalue
onnxruntime::ScanImpl::Execute
. Output tensor rank was 
Invalid value in scan_output_axes for output 
Outputs from Scan are not optional and should never be null.
onnxruntime::ScanImpl::TransposeOutput
info.GetAttr<int64_t>("transA", &temp).IsOK()
onnxruntime::GemmBase::GemmBase
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\gemm_base.h
info.GetAttr<int64_t>("transB", &temp).IsOK()
info.GetAttr<float>("alpha", &alpha_).IsOK()
left.NumDimensions() == 2 || left.NumDimensions() == 1
onnxruntime::GemmHelper::GemmHelper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\gemm_helper.h
right.NumDimensions() == 2
GEMM: Dimension mismatch, W: 
Gemm: Invalid bias shape for broadcast
M_ >= 0 && K_ > 0 && N_ >= 0
c_shape is required if c_data is provided
c_shape != nullptr
onnxruntime::GemmBroadcastBias
left_num_dims and right_num_dims must be >= 1
onnxruntime::MatMulComputeHelper::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/matmul_helper.h
MatMul dimension mismatch
Two inputs should have same rank and rank >= 3 if transBatchA or transBatchB is true
left_num_dims > 2 && left_num_dims == right_num_dims
left operand cannot broadcast on dim 
right operand cannot broadcast on dim 
num_dims_with_pad != num_output_dims
M_ == 1 && N_ == 1 was false
num_dims_with_pad - 1 != num_output_dims
num_dims_with_pad - 2 != num_output_dims
onnxruntime::MatMul<float>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\matmul.cc
onnxruntime::MatMul<double>::Compute
onnxruntime::MatMul<int>::Compute
onnxruntime::MatMul<__int64>::Compute
x_zero_point must be null or a scalar or 1D tensor or size 1.
zero_point_ptr == nullptr || IsScalarOr1ElementVector(zero_point_ptr)
onnxruntime::PrepareForQDQ
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\quantize_linear.cc
scale must be 1D tensor with size 
scale.Shape().NumDimensions() == 1 && scale.Shape()[0] == broadcast_dim
x_zero_point must be null or 1D tensor with size 
zero_point_ptr == nullptr || (zero_point_ptr->Shape().NumDimensions() == 1 && zero_point_ptr->Shape()[0] == broadcast_dim)
DequantizeLinear with type int32 should have no zero point or all zero points should be 0
zero_point == nullptr || std::all_of(zero_point, zero_point + x_zero_point->Shape().Size(), [](int32_t zp) { return zp == 0; })
onnxruntime::DequantizeLinear<int>::Compute
`@Per-column quantization parameter of batched matrix should have same dimension as the matrix,and its size by K should be equal to the matrix's size.
onnxruntime::MatMulComputeHelper::Compute::<lambda_0b24200fa934277fc2b30a9b53636fed>::operator ()
MatmulInteger : input1 zero point must be a scalar or 1D tensor of size 1
IsScalarOr1ElementVector(a_zero_point)
onnxruntime::MatMulInteger::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\matmul_integer.cc
MatmulInteger : B zero point is not valid
IsBQuantParamSupported(b_zero_point->Shape(), b ? b->Shape() : b_shape_)
ConvInteger
Must be a scalar or 1D tensor or size 1.
IsScalarOr1ElementVector(X_Zero_Point)
onnxruntime::ConvInteger::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\conv_integer.cc
Non per-tensor quantization is not supported now.
IsScalarOr1ElementVector(W_Zero_Point)
Axis tensor must be provided to the CumSum op
Axis tensor should be 0D or 1D
Axis tensor should be of type `int32_t` or `int64_t`
CumSum
Cannot apply CumSum operator on a scalar
onnxruntime::CumSum<float>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\cumsum.cc
onnxruntime::CumSum<double>::Compute
onnxruntime::CumSum<int>::Compute
onnxruntime::CumSum<__int64>::Compute
exclusive
starts.size()=
dims.size()=
dims.size() == starts.size()
onnxruntime::WritableSliceIterator<__int64>::Init
extents.size()=
dims.size() == extents_.size()
steps.size()=
dims.size() == steps.size()
onnxruntime::WritableSliceIterator<int>::Init
onnxruntime::WritableSliceIterator<double>::Init
onnxruntime::WritableSliceIterator<float>::Init
x_ptr != nullptr
onnxruntime::DynamicQuantizeLinear<unsigned char>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\dynamicquantizelinear.cc
 outputs.
 outputs which doesn't match the subgraph's 
'If' node has 
num_subgraph_outputs == static_cast<size_t>(num_outputs)
onnxruntime::If::Info::Info
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\if.cc
then_branch
info.GetAttr<ONNX_NAMESPACE::GraphProto>("then_branch", &proto).IsOK()
onnxruntime::If::Init
else_branch
info.GetAttr<ONNX_NAMESPACE::GraphProto>("else_branch", &proto).IsOK()
info == nullptr
onnxruntime::If::SetupSubgraphExecutionInfo
then_feeds_fetches_manager_ && else_feeds_fetches_manager_
onnxruntime::If::Compute
' attribute.
Subgraph SessionState was not found for '
onnxruntime::IfImpl::Initialize
Failed to create output tensor for 
Only tensors, tensor sequence, optional tensor, and optional tensor sequence types are supported
Failed to create output tensor for If output 
onnxruntime::IfImpl::Execute
reduction
ScatterND
, indices shape: 
input shape: 
input tensor and indices tensor must has rank larger than 0. 
last dimension of indices must not be larger than rank of input tensor
, data shape: 
updates shape: 
updates tensor should have shape equal to indices.shape[:-1] + data.shape[indices.shape[-1]:]. 
CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 16 when reduction is 'add'.
CPU execution provider: BFloat16 data type is not supported with ScatterND opset 16 when reduction is 'add'.
CPU execution provider: string data type is not supported with ScatterND opset 16 when reduction is 'mul'.
CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 16 when reduction is 'mul'.
CPU execution provider: BFloat16 data type is not supported with ScatterND opset 16 when reduction is 'mul'.
onnxruntime::ScatterNDDispatchTarget<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\scatter_nd.cc
onnxruntime::ScatterNDDispatchTarget<bool>::operator ()
onnxruntime::ScatterNDDispatchTarget<struct onnxruntime::BFloat16>::operator ()
onnxruntime::ScatterNDDispatchTarget<struct onnxruntime::MLFloat16>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned char>::operator ()
onnxruntime::ScatterNDDispatchTarget<signed char>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned short>::operator ()
onnxruntime::ScatterNDDispatchTarget<short>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned int>::operator ()
onnxruntime::ScatterNDDispatchTarget<int>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned __int64>::operator ()
onnxruntime::ScatterNDDispatchTarget<__int64>::operator ()
onnxruntime::ScatterNDDispatchTarget<double>::operator ()
onnxruntime::ScatterNDDispatchTarget<float>::operator ()
onnxruntime::PrepareForCompute
invalid indice found, indice = 
onnxruntime::GatherElements::GatherElements
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gather_elements.h
GatherElements
GatherElements op: Cannot operate on scalar input
GatherElements op: Rank of input 'data' needs to be equal to rank of input 'indices'
GatherElements op: 'indices' shape should have values within bounds of 'data' shape. Invalid value in indices shape is: 
GatherElements op: Data type of input 'data' should match the data type of the output
]. Actual value is 
GatherElements op: Value in indices must be within bounds [
onnxruntime::core_impl::<lambda_d8aa0ac057a171b3efa96a44f9d49b91>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gather_elements.cc
onnxruntime::core_impl::<lambda_69537c8792caaade49ceebada4159678>::operator ()
onnxruntime::core_impl::<lambda_536a6e9cd022d0c1fa0cbf0549e74cf6>::operator ()
onnxruntime::core_impl::<lambda_c278e4ec57a99b58d713632b35dd4157>::operator ()
start in Range operator should be scalar like tensor, yet got shape:
limit in Range operator should be scalar like tensor, yet got shape:
delta in Range operator should be scalar like tensor, yet got shape:
delta in Range operator can not be zero!
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\top_k.cc
op_kernel_info.GetAttr<int64_t>("axis", &axis_temp).IsOK()
onnxruntime::TopkOpset11ConstructorCommon
largest
op_kernel_info.GetAttr<int64_t>("largest", &largest_temp).IsOK()
sorted
op_kernel_info.GetAttr<int64_t>("sorted", &sorted_temp).IsOK()
] should not be greater than specified axis dim value [
k argument [
input count mismatch, expected 2 inputs - the tensor to be processed and a tensor containing k value
k tensor should be a 1D tensor of size 1
value of k must not be negative
output count mismatch, expected 2 outputs to be present for TopK operator
333333
info.GetAttr<int64_t>("channels_last", &channels_last_).IsOK()
onnxruntime::contrib::ReorderInput::ReorderInput
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\nchwc_ops.h
info.GetAttr<int64_t>("channels", &channels_).IsOK()
onnxruntime::contrib::ReorderOutput::ReorderOutput
invalid channel count
channels_ > 0
GetFusedActivationAttr(info, activation_).IsOK()
onnxruntime::contrib::NchwcConv::NchwcConv
pool_attrs_.kernel_shape.size() == 2
onnxruntime::contrib::NchwcPoolBase::NchwcPoolBase
X_rank == 4
onnxruntime::contrib::ReorderInput::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\nchwc_ops.cc
(channels % 4) == 0
onnxruntime::contrib::ReorderOutput::Compute
channels_ <= X_shape[1]
onnxruntime::contrib::NchwcConv::Compute
X_shape.NumDimensions() == 4
(static_cast<size_t>(X_shape[1]) < nchwc_block_size) || ((X_shape[1] % nchwc_block_size) == 0)
Unsupported convolution size.
output and sum shape must match
onnxruntime::contrib::NchwcPoolBase::NchwcPool
(X_shape[1] % MlasNchwcGetBlockSize()) == 0
onnxruntime::contrib::MatMulIntegerToFloatBase::ComputeCommon
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_matmul.cc
MatmulInteger : b zero point is not valid
IsBQuantParamSupported(b_zp_tensor->Shape(), b_tensor ? b_tensor->Shape() : b_shape_)
onnxruntime::contrib::DynamicQuantizeMatMul::Compute
MatMulIntegerToFloat : input a zero point must be a scalar or 1D tensor of size 1. Per-Channel is not supported yet.
IsScalarOr1ElementVector(a_zero_point_tensor)
onnxruntime::contrib::MatMulIntegerToFloat::Compute
Input 
onnxruntime::contrib::DynamicQuantizeLSTM::PrePack
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_lstm.cc
} for per-channel quantization. Actual:
} for per-tensor/layer quantization or shape {
 must have shape {
W_zero_point
R_zero_point
W_scale
R_scale
Weight zero point must be zero
DynamicQuantizeLSTM : 
Weight point must be constant
Recurrent
DynamicQuantizeLSTM
onnxruntime::contrib::FusedConvFloat::FusedConvFloat
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\fused_conv.cc
onnxruntime::contrib::FusedGemm<float>::FusedGemm
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\fused_gemm.cc
TransposeMatMul
onnxruntime::contrib::BiasGelu<float,0>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\bert\bias_gelu.cc
use_approximation
onnxruntime::contrib::LayerNorm<float,0>::Compute
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\layer_norm.cc
onnxruntime::contrib::LayerNorm<float,1>::Compute
onnxruntime::contrib::LayerNorm<double,0>::Compute
onnxruntime::contrib::LayerNorm<double,1>::Compute
op_kernel_info.GetAttr("axis", &axis_).IsOK()
onnxruntime::contrib::LayerNorm<float,0>::LayerNorm
op_kernel_info.GetAttr<float>("epsilon", &epsilon_).IsOK()
onnxruntime::contrib::LayerNorm<float,1>::LayerNorm
onnxruntime::contrib::LayerNorm<double,0>::LayerNorm
onnxruntime::contrib::LayerNorm<double,1>::LayerNorm
input is expected to have 3 dimensions, got 
skip is expected to have same shape as input
gamma is expected to have 1 dimension, got 
Last dimension of gamma and input does not match
beta is expected to have 1 dimension, got 
Last dimension of beta and input does not match
bias is expected to have 1 dimension, got 
Last dimension of bias and input does not match
onnxruntime::contrib::SkipLayerNorm<float>::SkipLayerNorm
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\skip_layer_norm.cc
epsilon_ >= 0
onnxruntime::contrib::SkipLayerNorm<double>::SkipLayerNorm
SoftmaxCPU inputs N, D and N * D must be < 
affine
leakyrelu
thresholdedrelu
scaledtanh
hardsigmoid
softsign
softplus
Input X must have 3 dimensions only. Actual:
}. Actual:
Input W must have shape {
Input R must have shape {
Input B must have shape {
Input sequence_lens must have shape {
Invalid value/s in sequence_lens. All values must be > 0 and < seq_length. seq_length=
Input initial_h must have shape {
Expecting activation to be one of Affine, Relu, LeakyRelu, ThresholdedRelu, Tanh, ScaledTanh, Sigmoid, HardSigmoid, Elu, Softsign, Softplus. Got 
onnxruntime::rnn::detail::NormalizeActivationArgumentAndGetAlphaBetaCount
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\rnn_helpers.cc
A + (M * K) <= A_end
weights.quant_para_
Quantized GEMM only support alpha equal to 1.0f and beta equal to 0.0f or 1.0f
alpha == 1.0f && (beta == 0.0f || beta == 1.0f)
Invalid activation function of 
onnxruntime::rnn::detail::deepcpu::ActivationFuncByName
Invalid LSTM merge activation function of 
onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncByName
Invalid GRU reset gate activation function: 
onnxruntime::rnn::detail::deepcpu::GruResetGateFuncByName
Invalid GRU hidden gate activation function: 
onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncByName
.Input initial_c must have shape {
Input P must have shape {
onnxruntime::LSTMBase::ComputeImpl
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\lstm_base.cc
Unsupported type
 inputs but Scan was only given 
The subgraph in 'body' requires 
num_variadic_inputs == num_subgraph_inputs
onnxruntime::scan::detail::Info::Info
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\scan_utils.cc
' was 
Number of entries in '
directions.size() == num_entries
onnxruntime::scan::detail::ReadDirections
'. 0 == forward. 1 == reverse.
Invalid values in '
valid
 did not.
Subgraph must have the shape set for all outputs but 
onnxruntime::scan::detail::AllocateOutput
onnxruntime::scan::detail::CreateFeedsFetchesManager
onnxruntime::scan::detail::IterateSequence::<lambda_2f3c8dfb82c3078faed3c459500f6cd5>::operator ()
onnxruntime::scan::detail::IterateSequence
Misuse of LoopStateVariable. Attempt to move beyond end of sequence
iteration_num_ < sequence_len_
onnxruntime::scan::detail::LoopStateVariable::Next
 is not compatible with 
Mismatch between expected shape and shape from first output
onnxruntime::scan::detail::OutputIterator::Initialize
Failed to create output tensor for output #
onnxruntime::scan::detail::OutputIterator::AllocateFinalBuffer
If shape was concrete we shouldn't be using a custom allocator
!is_concrete_shape_
onnxruntime::scan::detail::OutputIterator::AllocateFinalOutput
cur_iteration_ < num_iterations_
onnxruntime::scan::detail::OutputIterator::operator *
Expected AllocateFinalOutput to have been called to before we read the OrtValue from the iterator.
is_concrete_shape_
Expected AllocateFinalOutput to have been called to before we increment the iterator
onnxruntime::scan::detail::OutputIterator::operator ++
position_ >= 0 && position_ < sequence_length_
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::operator *
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/ort_value_tensor_slicer.h
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::operator *
unimplemented activation: 
activation_params count mismatch
Input 0 is expected to have 1 or more dimensions, got 
Input 1 is expected to have 1 dimensions, got 
Input 1 dimension 0 should have same length as the last dimension of input 0
CudaPinned
OpenVINO_GPU
onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment::<lambda_1dd79544acf23ae3afd11302d7a0d9a2>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocator.cc
Specified device is not supported.
OrtValue is TensorSequence type but has no element Tensor DataType.
Tensor types should have been handled already
 is not supported
Not implemented
the ort_value must contain a constructed tensor or sparse tensor
Argument is not a tensor
OrtApis::GetTensorTypeAndShape
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_type_and_shape.cc
Unsupported indices_format passed
`anonymous-namespace'::GetIndicesTensor
type_proto is not of type map!
type_proto is not of type sequence!
onnxruntime::IDataTransfer::CopyTensors
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_transfer.cc
onnxruntime::IDataTransfer::CopySparseTensors
src.SizeInBytes() == dst.SizeInBytes()
onnxruntime::CPUDataTransfer::CopyTensor
 dimensions.
 for SizeFromDimension. Tensor has 
Invalid dimension of 
dimension <= num_dims
onnxruntime::TensorShape::SizeToDimension
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_shape.cc
onnxruntime::TensorShape::SizeFromDimension
Invalid tensor shape slice argument.
dimstart <= dimend && dimend <= values_.size()
onnxruntime::TensorShape::Slice
expected a registered ONNX type
value_proto != nullptr
onnxruntime::data_types_internal::MapTypeHelper::Set
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/data_types.h
elem_proto != nullptr
onnxruntime::data_types_internal::SequenceTypeHelper::Set
onnxruntime::data_types_internal::OptionalTypeHelper::Set
onnxruntime::TensorTypeBase::GetElementType
onnxruntime::SparseTensorTypeBase::GetElementType
onnxruntime::OptionalTypeBase::GetDeleteFunc
onnxruntime::OptionalTypeBase::GetElementType
onnxruntime::SequenceTensorTypeBase::GetElementType
onnxruntime::data_types_internal::IsCompatible
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_types.cc
Only ONNX MLDataType can be registered
proto != nullptr
onnxruntime::data_types_internal::DataTypeRegistry::RegisterDataType
We do not expect duplicate registration of types for: 
p.second
thisProto->value_case() == TypeProto::ValueCase::kTensorType
onnxruntime::TensorTypeBase::IsCompatible
utils::HasElemType(thisProto->tensor_type())
thisProto->value_case() == TypeProto::ValueCase::kSparseTensorType
onnxruntime::SparseTensorTypeBase::IsCompatible
utils::HasElemType(thisProto->sparse_tensor_type())
thisProto->value_case() == TypeProto::ValueCase::kSequenceType
onnxruntime::SequenceTensorTypeBase::IsCompatible
utils::HasElemType(thisProto->sequence_type())
thisProto->value_case() == TypeProto::ValueCase::kOptionalType
onnxruntime::OptionalTypeBase::IsCompatible
utils::HasElemType(thisProto->optional_type())
thisProto->value_case() == TypeProto::ValueCase::kMapType
onnxruntime::NonTensorTypeBase::IsMapCompatible
utils::HasKeyType(thisProto->map_type())
onnxruntime::NonTensorTypeBase::IsSequenceCompatible
onnxruntime::NonTensorTypeBase::FromDataContainer
onnxruntime::NonTensorTypeBase::ToDataContainer
(null)
float
double
uint8
int16
uint16
int32
uint32
int64
uint64
float16
bfloat16
tensor type 
sparse tensor type 
 is not currently registered or supported
MLDataType for: 
Invalid DataTypeImpl TypeProto definition
onnxruntime::utils::ContainerChecker::ContainerChecker
p_type != nullptr
onnxruntime::Tensor::Tensor
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor.cc
shape.Size() must >=0
tensor failed memory size calculation
tensor size overflow
onnxruntime::Tensor::SizeInBytes
onnxruntime::Tensor::Init
Tensor is expected to contain one of the primitive data types. Got: 
dtype_ != nullptr
Divide by zero
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnDivZero
 dst_size: 
Must have the same size. Got src_size: 
onnxruntime::`anonymous-namespace'::CopyData
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sparse_tensor.cc
the ort_value must contain a constructed sparse tensor
onnxruntime::SparseTensor::GetSparseTensorFromOrtValue
this tensor already has populated sparse_indices
 must be less than total buffer size: 
Values size 
onnxruntime::SparseTensor::AllocateBuffer
SparseTensor Allocation failed for size: 
Must contain Coo format. Got: 
Format() == SparseFormat::kCoo
onnxruntime::SparseTensor::AsCoo
Expecting to contain one index, got: 
format_data_.size() == 1U
 must be equal to or twice the values size: 
Index size: 
values_count == index_size
onnxruntime::SparseTensor::GetCooIndexDims
Sparse format must not be set. Already contains format: 
onnxruntime::SparseTensor::UseCooIndices
Not expecting an allocator set
Use MakeCooStrings
onnxruntime::SparseTensor::MakeCooData
Expecting data type to be set as string
onnxruntime::SparseTensor::MakeCooStrings
Format() == SparseFormat::kUndefined
This method should follow a call to constructor that supplies the allocator
allocator_ != nullptr
Must contain Csr format. Contains: 
Format() == SparseFormat::kCsrc
onnxruntime::SparseTensor::AsCsr
Expecting two indices. Got: 
format_data_.size() == 2U
dense shape must 2-D. Got: 
onnxruntime::SparseTensor::ValidateCsrIndices
Inner and Outer indices must either be both zero or non-zero
 the same as values size: 
Expecting inner index size: 
 rows: 
Outer index count must be rows + 1 or zero. Got: 
This method does not expect allocator to be set
onnxruntime::SparseTensor::UseCsrIndices
Use MakeCsrStrings
onnxruntime::SparseTensor::MakeCsrData
onnxruntime::SparseTensor::MakeCsrStrings
Must contain BlockSparse format. Got: 
Format() == SparseFormat::kBlockSparse
onnxruntime::SparseTensor::AsBlockSparse
Expecting one index. Got: 
Expecting to have at lest 3-D shape. Got:
onnxruntime::SparseTensor::ValidateBlockSparseShapes
Expecting indices to have 2-D shape . Got: 
Indices shape must have dim[0] == 2
 to be equal to values blocks: 
Expecting index blocks: 
Expecting fully sparse tensors to have value shape {0}
Expecting fully sparse tensors to have indices shape {0}
onnxruntime::SparseTensor::UseBlockSparseIndices
Use MakeBlockSparseStrings
onnxruntime::SparseTensor::MakeBlockSparseData
onnxruntime::SparseTensor::MakeBlockSparseStrings
 to device type: 
Unable to find a data transfer for copying from device type: 
onnxruntime::SparseTensor::Copy
This instance should not be empty
Destination should be empty
Destination must have a CPU allocator set
X-device copy of strings not supported
Src and Dst must be of the same type
Must have the same shape
Config key is empty or longer than maximum length 128
Config value is longer than maximum length 1024
]. It will be overwritten
] already exists with value [
Config with key [
onnxruntime::ConfigOptions::AddConfigEntry
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\config_options.cc
Received nullptr for name.
Received nullptr for OrtValue.
Received OrtValue is not a tensor. Only tensors are supported.
Buffer containing the initializer must be owned by the user.
An OrtValue for this name has already been added.
InternalTestingExecutionProvider
invalid allocator.
Unsupported OrtValue type.
Failed to find allocator for device 
allocator != nullptr
onnxruntime::utils::BatchOrCopyMLValue
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\utils.cc
Unsupported OrtValue type to copy between device.
onnxruntime::utils::FindMemoryInfoForValue
exec_plan_ptr
onnxruntime::utils::CalculateStaticCopyInfoForFeed
onnxruntime::utils::CalculateStaticCopyInfoForFeeds
onnxruntime::utils::InitializeFeedFetchCopyInfo
feed_locations.size() == copy_info.size()
onnxruntime::utils::FinalizeCopyInfoForFeeds
fetch_alloc_info.size() == copy_info.size()
onnxruntime::utils::FinalizeCopyInfoForFetches
copy_info.size() == num_feeds
onnxruntime::utils::CopyInputsAcrossDevices
onnxruntime::utils::CopyOneInputAcrossDevices
onnxruntime::utils::CopyOutputsAcrossDevices
Only one thread was configured for parallel execution. Hence will use sequential execution.
onnxruntime::utils::ExecuteGraphImpl
onnxruntime::utils::ExecuteGraph
input_offset >= 0 && output_offset >= 0
onnxruntime::KernelDefBuilder::VariadicAlias
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\kernel_def_builder.cc
cannot find allocator
onnxruntime::OpKernelInfo::GetMemoryInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\op_kernel_info.cc
node_offsets_index < node_offsets_size_
onnxruntime::NodeIndexInfo::GetNodeOffset
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/node_index_info.h
Execution frame was null
frame != nullptr
onnxruntime::OpKernelContext::OpKernelContext
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\op_kernel.cc
OpKernel was null
kernel != nullptr
onnxruntime::OpKernelContext::OutputMLValue
TempSpace allocator not found
CPU allocator not found
onnxruntime::OpKernelContext::GetOrCreateOutputMLValue
Attibute name and type don't match
No attribute with this name is defined.
 is defined.
No attribute with name: 
 but is of type: 
 expected to be of type: 
Attribute: 
Received invalid value of arena_extend_strategy 
onnxruntime::CreateAllocator
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocatormgr.cc
duplicated allocator
onnxruntime::AllocatorManager::InsertAllocator
data_transfer registered is nullptr.
Tensor size mismatch
There's no data transfer registered for copying tensors from 
onnxruntime::DataTransferManager::CopyTensors
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_transfer_manager.cc
onnxruntime::DataTransferManager::CopySparseTensors
onnxruntime::IExecutionProvider::InsertAllocator
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\execution_provider.cc
duplicated allocator: 
onnxruntime::IExecutionProvider::TryInsertAllocator
IExecutionProvider::Compile with fused Node is not implemented by 
IExecutionProvider::Compile with fused Node and dll path is not implemented by 
IExecutionProvider::Compile with FusedNodeAndGraph is not implemented by 
IExecutionProvider constructor must be called with true for use_metadef_id_creator
metadef_id_generator_
onnxruntime::IExecutionProvider::GenerateMetaDefId
 constraint was not found for 
onnxruntime::`anonymous-namespace'::TypeBindingResolver::Resolve
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\kernel_registry.cc
 kernel_end_version: 
 kernel start version: 
 node_version: 
 Version mismatch.
 and type (
Op with name (
 This op has been implemented only for the following types (
 However the types are incompatible.
 (node_version: 
 in the supported version range
Found kernel for Op with name (
 but the node in the model has the following type (
onnxruntime::KernelRegistry::TryCreateKernel
 Encountered following errors: (
 kernel is not supported in 
Kernel not found
kernel def can't be NULL
: Conflicting with a registered kernel with op versions.
Failed to add kernel for 
: Conflict with existing kernel def hash.
onnxruntime::KernelRegistry::Register
len <= op_schema.inputs().size()
onnxruntime::`anonymous-namespace'::TraverseFormalParametersWithTypeProto
Candidate for fallback CPU execution: 
onnxruntime::GetCpuPreferredNodes::<lambda_8811b8e0b984fa7408be2a8e645ea91e>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\fallback_cpu_capability.cc
kernel_info != nullptr
onnxruntime::GetCpuPreferredNodes
 capable of executing this node
 because the CPU execution path is deemed faster than overhead involved with execution on other EPs 
ORT optimization- Force fallback to CPU execution for node: 
Currently do not support dims higher than 2 dimensions: 
Unable to convert strings tensor to a sparse tensor that not on CPU
onnxruntime::sparse_utils::DenseTensorToSparseCsr
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sparse_utils.cc
Unsupported element size: 
Support 2-D matrices only
Input must be of CSR format
Unable to convert strings tensor to a sparse tensor that is not on CPU
Expecting inner indices to be same as nnz. Got: 
inner_num == src.Values().Shape().Size()
onnxruntime::sparse_utils::SparseCsrToDenseTensor
Outer indices must be M + 1. Got: 
outer_num == (rows + 1)
Input must be of COO format
Expecting indices to be equal the number of values or be twice as many
onnxruntime::sparse_utils::SparseCooToDenseTensor
 > dense_size: 
Invalid index: 
onnxruntime::sparse_utils::DenseTensorToSparseCoo
 type: 
UnpackTensor: the pre-allocated size does not match the raw data size, expected 
Tensor does not have external data to read from.
`anonymous-namespace'::GetExternalDataInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensorprotoutils.cc
External data type cannot be UNDEFINED or STRING.
TensorProto external data size mismatch. Computed size: 
`anonymous-namespace'::ReadExternalDataForTensor
nullptr == p_data
onnxruntime::utils::UnpackTensorWithExternalDataImpl
) in proto
) does not match the data size(
corrupted protobuf data: tensor shape size(
UnpackTensor: the pre-allocate size does not match the size in proto
data overflow
onnxruntime::utils::GetFileContent
TensorProtoToTensor() tensor shape mismatch!
 can not be writen into Tensor type 
TensorProto type 
onnxruntime::utils::TensorProtoToTensor
string tensor can not have raw data
tensor can't contain negative dims
Initialized tensor with unexpected type: 
TensorProtoToMLValue() must take a pre-allocated MemBuffer!
string tensor can not use pre-allocated buffer
, Got 
The preallocated buffer is too small. Requires 
onnxruntime::utils::TensorProtoToMLValue
onnxruntime::utils::ConstantNodeProtoToTensorProto
 in 'Constant' node '
Unsupported attribute value type of 
Sparse Indices raw data size does not match expected.
onnxruntime::utils::CopySparseData
Sparse indices int64 data size does not match expected
Sparse indices int32 data size does not match expected
Invalid SparseTensor indices. INT16 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. INT8 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. Should one of the following types: int8, int16, int32 or int64
indices_shape[1] > 0 && static_cast<size_t>(indices_shape[1]) == dims.size()
cur_index == &*indices_data.cend()
Invalid SparseTensor indices. Should be rank 0 or 1. Got:
onnxruntime::utils::SparseTensorProtoToDenseTensorProto
 is not supported.
Element_size of: 
Unsupported sparse tensor data type of 
Must have a valid data type
HasDataType(dense_proto)
onnxruntime::utils::DenseTensorToSparseTensorProto
 data_type: 
onnxruntime::utils::UnpackInitializerData
Unsupported type: 
Invalid TensorProto
 in KernelRegistryManager
found duplicated provider 
 (node 
The node is not placed on any Execution Provider. 
Failed to find kernel for 
onnxruntime::FeedsFetchesInfo::MapNamesToMLValueIdxs
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\feeds_fetches_manager.cc
Error mapping feeds: 
Error mapping output names: 
input_copy_needed != DeviceCopyCheck::Unknown && output_copy_needed != DeviceCopyCheck::Unknown
onnxruntime::FeedsFetchesManager::SetDeviceCopyChecks
Caught exception while destructing CustomOpsLoader with message: 
onnxruntime::ExLibLoader::{dtor}::<lambda_3229e3f829fe3a5ff7c7841155b8b8df>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\ex_lib_loader.cc
Unloading DSO 
onnxruntime::ExLibLoader::~ExLibLoader
Failed to unload DSO: 
Caught exception while loading custom ops with message: 
 has already been loaded.
A dso with name 
onnxruntime::ExLibLoader::LoadExternalLib
Could not find OrtValue with idx '
session.disable_prepacking
. Ignoring allocator from 
Allocator already registered for 
onnxruntime::SessionState::SetupAllocators
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\session_state.cc
SaveMLValueNameIndexMapping
onnxruntime::SessionState::CreateGraphInfo
Done saving OrtValue mappings.
onnxruntime::SessionState::PopulateKernelCreateInfo
entry != kernel_create_info_map_.cend()
onnxruntime::SessionState::GetNodeKernelCreateInfo
onnxruntime::SessionState::CreateKernels
. Do you have duplicated calls to SessionState::AddInitializedTensor function?
duplicated ort_value index:
onnxruntime::KernelUseSharedPrePackedBuffers
 doesn't have an implementation that can consume provided pre-packed weights
The kernel corresponding to the node 
allocator_for_caching.get() != nullptr
onnxruntime::SessionState::PrepackConstantInitializedTensors::<lambda_4b2c19fdf6db3770ba085ad29d6de2dd>::operator ()
 doesn't have an implementation that can cache computed pre-packed weights
weights_to_be_filled_in.buffers_.size() > 0
The op type of a node cannot be empty
!op_type.empty()
 which is of op type: 
 used in the node: 
Using cached version of pre-packed weight for constant initializer: 
Unable to write the provided PrePackedWeights instance into the container
) and node 
 is used by node 
Using an input in multiple nodes on different devices is not supported currently. Input:
Failed to find input name in the mapping: 
Only one node should produce an output. Existing entry for 
output_names_to_nodeinfo.empty()
onnxruntime::SessionState::AddOutputNameToNodeInfoMapping
 for attribute 
Entry exists in node 
existing_entries.find(attribute_name) == existing_entries.cend()
onnxruntime::SessionState::AddSubgraphSessionState
SetGraphAndCreateKernels must be called prior to GetExecutionInfo.
node_index_info_
onnxruntime::SessionState::GetNodeIndexInfo
onnxruntime::SessionState::UpdateToBeExecutedNodes
onnxruntime::GetSubGraphSessionStatesOrtFormat
onnxruntime::SessionState::SaveToOrtFormat
Main Graph instance should have populated all subgraphs when being resolved.
subgraph
onnxruntime::SessionState::CreateSubgraphSessionState
onnxruntime::SessionState::LoadFromOrtFormat::<lambda_22285d577ae7f88bffc3c4e6bbbe514e>::operator ()
onnxruntime::SessionState::LoadFromOrtFormat
 optype:
Unable to find kernel hash for node:
Unable to find compiled kernel hash for node '
onnxruntime::SessionState::FinalizeSessionState
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_a191614639fd357df18cb9db7ec0bbb0>::operator ()
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_23cd650266f5b996762e121f69bcde45>::operator ()
onnxruntime::OuterScopeNodeArgLocationAccumulator
subgraphs_kernel_create_info_maps.find(local_subgraph_kernel_create_info_map_key) == subgraphs_kernel_create_info_maps.end()
onnxruntime::AccumulateAllNestedSubgraphsInfo
onnxruntime::SessionState::FinalizeSessionStateImpl
 Attribute:
 Index:
' OpType:
Missing session state for subgraph. Node:'
entry != node_to_subgraph_ss.second.cend()
p_op_kernel
MaxAllocSize:             
NumArenaShrinkages:       
NumArenaExtensions:       
NumReserves:              
NumAllocs:                
MaxInUse:                 
TotalAllocated:           
InUse:                    
Limit:                    
 | in_use: 
 | Requested Size: 
  Size: 
, prev: 
, next: 
0 == memory_size % kMinAllocationSize
onnxruntime::BFCArena::AllocationRegion::AllocationRegion
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/bfc_arena.h
p_int >= base_int
onnxruntime::BFCArena::AllocationRegion::IndexFor
p_int < base_int + memory_size_
Could not find Region for: 
entry != regions_.end()
onnxruntime::BFCArena::RegionManager::RemoveAllocationRegion
Could not find Region for 
onnxruntime::BFCArena::RegionManager::RegionFor
 arena_extend_strategy: 
 memory limit: 
 initial_growth_chunk_size_bytes: 
 max_dead_bytes_per_chunk: 
 with following configs: initial_chunk_size_bytes: 
Creating BFCArena for 
onnxruntime::BFCArena::BFCArena
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\bfc_arena.cc
 bins of max chunk size 
Creating 
BinForSize(bin_size) == BinFromIndex(b)
BinForSize(bin_size + 255) == BinFromIndex(b)
BinForSize(bin_size * 2 - 1) == BinFromIndex(b)
BinForSize(bin_size * 2) != BinFromIndex(b)
h < chunks_.size()
onnxruntime::BFCArena::ChunkFromHandle
cudaMalloc
hipMalloc
Incorrect arena extend strategy.
onnxruntime::BFCArena::Extend::<lambda_6bf74fe8c2f6f409bb5a2a70c054cf56>::operator ()
 is smaller than requested bytes of 
Available memory of 
Failed to allocate memory for requested buffer of size 
 bytes.
Extended allocation by 
onnxruntime::BFCArena::Extend
Total allocated bytes: 
Allocated memory at 
 size: 
Reserving memory in BFCArena for 
onnxruntime::BFCArena::Reserve
reserved_chunks_.find(ptr) == reserved_chunks_.end()
h != kInvalidChunkHandle
tried to allocate 0 bytes
onnxruntime::BFCArena::AllocateRawInternal
 (actual) rounded_bytes:
 (requested) num_bytes: 
. bin_num:
Extending BFCArena for 
Failed to find a free memory block despite calling Extend. rounded_bytes=
.  Current allocation summary follows.
BFC Arena ran out of memory trying to allocate 
!chunk->in_use()
onnxruntime::BFCArena::FindChunkPtr
!c->in_use() && (c->bin_num == kInvalidBinNum)
onnxruntime::BFCArena::SplitChunk
 The total allocated bytes is now 
 bytes. 
 BFC Arena shrunk by 
onnxruntime::BFCArena::Shrink
onnxruntime::BFCArena::DeallocateRawInternal
!c1->in_use() && !c2->in_use()
onnxruntime::BFCArena::Merge
c2->prev == h1
onnxruntime::BFCArena::InsertFreeChunkIntoBin
!c->in_use() && (c->bin_num != kInvalidBinNum)
onnxruntime::BFCArena::RemoveFreeChunkIterFromBin
onnxruntime::BFCArena::RemoveFreeChunkFromBin
Could not find chunk in bin
BinFromIndex(c->bin_num)->free_chunks.erase(h) > 0
c->in_use() && (c->bin_num == kInvalidBinNum)
onnxruntime::BFCArena::FreeAndMaybeCoalesce
bin->free_chunks.count(h) == 1
onnxruntime::BFCArena::get_bin_debug_info
c->bin_num == bin_num
Allocator:
onnxruntime::BFCArena::DumpMemoryLog
Bin size: Chunks in_use/total (if not zero). Allocated bytes in_use/total. Requested bytes.
b->free_chunks.size() == bin_info.total_chunks_in_bin - bin_info.total_chunks_in_use
Requested 
. Bytes 
: Chunks 
Diff between in-use and requested bytes is 
, Chunk State: 
 bytes has max bytes of 
Bin for 
Overall chunks summary:
 of size 
  Chunk
  Free 
Summary of in-use chunks by size: 
. Total 
 chunks of size 
Sum Total of in-use chunks: 
Stats: 
fff?@
onnxruntime::FunctionKernel::Create
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/func_kernel.h
Create state function failed. Return value:
API VERSION 
 and are not expected to remain in the graph post partitioning. This is a bug in layout transformer.
. These are temporary nodes added during layout transformations 
 with domain: 
 Op Type: 
Graph contains an invalid node: 
onnxruntime::GetCapabilityForEP
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\graph_partitioner.cc
1 == capability.nodes.size()
onnxruntime::PlaceNode
onnxruntime::PartitionOnnxFormatModelImpl
Must use Function based fusion when exporting compiled nodes to dll.
fusion_style == IExecutionProvider::FusionStyle::Function
 did not return correct number of compiled functions
onnxruntime::InlineNodes
onnxruntime::GraphPartitioner::PartitionOnnxFormatModel
onnxruntime::PartitionOrtFormatModelImpl
single_node_compute_func should have 1 element.
. Execution Provider must generate unique names across the entire model.
Existing entry in compiled kernel hashes for 
onnxruntime::GraphPartitioner::PartitionOrtFormatModel
No provider specified.
onnxruntime::GraphPartitioner::Partition
Compiled kernel hashes must be provided
compiled_kernel_hashes != nullptr
nullptr != type_proto
onnxruntime::utils::GetMLDataType
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\mldata_type_utils.cc
SessionState for subgraphs is null. Invalid ORT format model.
Kernel create info is null. Invalid ORT format model.
Kernel create info node indices are null. Invalid ORT format model.
Kernel create info hashes are null. Invalid ORT format model.
Size mismatch for kernel create info node indexes and hashes. Invalid ORT format model.
 is missing. Invalid ORT format model.
Subgraph SessionState entry for 
 is null. Invalid ORT format model.
Subgraph SessionState for 
Transpose_1
Transpose_13
Squeeze_1
Squeeze_11
Squeeze_13
UnSqueeze_1
UnSqueeze_11
UnSqueeze_13
Gather_1
Gather_11
Gather_13
Identity_1
Identity_13
Identity_14
Identity_16
offset >= 0 && static_cast<size_t>(offset) < node_values_size_
onnxruntime::NodeIndexInfo::GetMLValueIndex
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < all_values_size_
onnxruntime::IExecutionFrame::GetMLValue
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/execution_frame.h
node_index_info and ort_value_idx_map are out of sync and cannot be used
node_index_info_.GetMaxMLValueIdx() == ort_value_idx_map.MaxIdx()
onnxruntime::IExecutionFrame::IExecutionFrame
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\execution_frame.cc
 Requested shape:
OrtValue shape verification failed. Current shape:
shape && tensor.Shape() == *shape
onnxruntime::IExecutionFrame::GetOrCreateNodeOutputMLValue
shape && sp_tensor.DenseShape() == *shape
invalid index 
feeds.size() == feed_mlvalue_idxs.size()
onnxruntime::IExecutionFrame::Init
fetches.empty() || fetches.size() == fetch_mlvalue_idxs_.size()
 entries which doesn't match the number of fetches the frame was initialized with of 
Fetches vector passed to GetOutputs contains 
 failed. Error:
Allocation of memory pattern buffer for 
onnxruntime::ExecutionFrame::{ctor}::<lambda_7d7605caeb4f06ba6e5ae22b6401d8c8>::operator ()
buffers_.find(location) == buffers_.end()
onnxruntime::ExecutionFrame::ExecutionFrame
 returned nullptr
Trying to allocate memory for unused optional inputs/outputs
Tensor shape cannot contain any negative value
ort_value.Fence() == nullptr
onnxruntime::ExecutionFrame::AllocateMLValueTensorSelfOwnBufferHelper
, fall back to default allocation behavior
 but the actually size is: 
, block in memory pattern size is: 
For ort_value with index: 
. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.
Shape mismatch attempting to re-use buffer. 
onnxruntime::ExecutionFrame::AllocateMLValueTensorPreAllocateBuffer
mlvalue.Fence() == nullptr
onnxruntime::AllocateSparseTensor
onnxruntime::ExecutionFrame::AllocateReusedOrtValueIfNotAllocatedHelper
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < alloc_plan.size()
onnxruntime::ExecutionFrame::AllocateAsPerAllocationPlan
We don't expect custom allocators for non-tensor types, so a shape is mandatory here.
Allocation of tensor types requires a shape.
Invalid allocation kind: 
 for output 
 does not match actual shape of 
Expected shape from model of 
onnxruntime::ExecutionFrame::VerifyOutputSizes
onnxruntime::ExecutionFrame::ReleaseMLValueImpl
ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < alloc_plan.size()
onnxruntime::ExecutionFrame::GetAllocationPlan
 failed: 
 size=
TraceAllocation for ort_value_idx=
onnxruntime::ExecutionFrame::TraceAllocate
onnxruntime::ExecutionFrame::TraceFree
TraceFree for ort_value_idx=
Memory pattern planner is not enabled on this execution framework.
model format error! Need a key for the external data info
model format error! Need a value for the external data info
location
offset
 failed
parsing 
length
checksum
model format error!
model format error! Missing 'location'
onnxruntime::NodeIndexInfo::Init::<lambda_1123ca3288c22333dcfbc6780e56f3b6>::operator ()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\node_index_info.cc
onnxruntime::NodeIndexInfo::Init::<lambda_4404716c35945f1da6a07154c932397d>::operator ()
Can't slice a non-tensor OrtValue. Type was 
ort_value.IsTensor()
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Create
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\ort_value_tensor_slicer.cc
OrtValue has not been allocated so can't be sliced.
ort_value.IsAllocated()
. Shape:
Insufficient dimensions to slice on 
gsl::narrow_cast<int64_t>(tensor_shape.NumDimensions()) >= slice_dimension
. Dimension 0 is 
Invalid dim0_offset of 
dim0_offset < dim0_size
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::Iterator
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Create
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::Iterator
 does not.
All implicit inputs should have OrtValue instances by now. 
entry != nullptr
onnxruntime::OpKernelContextInternal::OpKernelContextInternal
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/op_kernel_context_internal.h
Multiple errors were found.
onnxruntime::ParallelExecutor::Execute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\parallel_executor.cc
ParallelExecutor::Execute
Begin execution
onnxruntime::ParallelExecutor::RunNodeAsync
Exiting due to terminate flag being set to true.
Got nullptr from GetKernel for node: 
op_name
_fence_before
' Status Message: 
 node. Name:'
Non-zero status code returned while running 
provider
thread_scheduling_stats
_kernel_time
_fence_after
Unknown exception was caught by catch-all handler.
Exception running nodes starting at 
onnxruntime::SequentialExecutor::Execute
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sequential_executor.cc
graph_index
exec_plan_index
activation_size
parameter_size
output_size
input_type_shape
output_type_shape
SequentialExecutor::Execute
onnxruntime::ReleaseNodeMLValues
source and destination buffer size mismatch
onnxruntime::utils::detail::CopyLittleEndian
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\endian_utils.cc
Previous entry was not terminated.
starts_.size() == ends_.size()
onnxruntime::AllocPlanPerValue::ProgramCounter::AddStart
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/sequential_execution_plan.h
Invalid 'start'. Value is smaller than previous 'end'.
starts_.empty() || start > ends_.back()
No matching 'start' entry.
starts_.size() == ends_.size() + 1
onnxruntime::AllocPlanPerValue::ProgramCounter::AddEnd
Invalid 'end'. Value is larger than 'start'.
end >= starts_.back()
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocation_planner.cc
SessionState should have saved the KernelCreateInfo prior to this running. NodeIndex:
entry != kernel_create_info_map.cend()
onnxruntime::GetKernelCreateInfo
onnxruntime::PlannerImpl::Index
n >= 0 && static_cast<size_t>(n) < ort_value_info_.size()
onnxruntime::PlannerImpl::UseCount
onnxruntime::PlannerImpl::Buffer
n >= 0 && static_cast<size_t>(n) < plan_.allocation_plan.size()
onnxruntime::PlannerImpl::AllocPlan
id >= 0 && static_cast<size_t>(id) < ort_value_info_.size()
onnxruntime::PlannerImpl::ProcessDef
reused != reused_for
onnxruntime::PlannerImpl::Reuse
nullptr != tensor_type_base
onnxruntime::PlannerImpl::GetElementSize
There is no location for this node arg in the outer scope location map
found_in_outer_scope_location_map
onnxruntime::PlannerImpl::ComputeUseCounts::<lambda_c7328f9d78ba121fe15792ce469c1b69>::operator ()
Can not find the node 
Should not have entry in kernel create info with nullptr for kernel_def
p_kernel_def
onnxruntime::PlannerImpl::ComputeUseCounts
Can not find the execution provider 
allocator
onnxruntime::PlannerImpl::GetLocationForNodeInput
specific_subgraph_kernel_create_info_map != subgraphs_kernel_create_info_maps_.end()
onnxruntime::PlannerImpl::GeneratePlanForWeightsHelper
onnxruntime::PlannerImpl::ComputeReusePlan
Only tensors are supported for external outputs for now.
!IsNonTensor(*node_output)
Invalid program_counter entries at index 
entry.program_counter.HasValidEntries()
onnxruntime::PlannerImpl::VerifyMemoryTimeSchedule
AllocPlan(ml_value_idx).program_counter.Ends().back() == program_counter
onnxruntime::PlannerImpl::GenerateDeallocationPlan
onnxruntime::PlannerImpl::CreatePlan
buffers_.size() == buffer_sizes_.size()
onnxruntime::PrePackedWeights::GetHash
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\prepacked_weights.cc
Unsupported device allocator in the context of pre-packed weights caching: 
onnxruntime::PrepackedWeightsContainer::GetOrCreateAllocator
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\prepacked_weights_container.cc
Failed to get allocator for location: 
duplicated location
onnxruntime::TensorAllocatorWithMemPattern::FinalizePlan
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_allocator_with_mem_pattern.h
Internal error.
 is not found
Mem pattern for initializer 
' is not found
Weight buffer for initializer '
' failed
Get preallocated buffer for initializer '
onnxruntime::TensorAllocatorWithMemPattern::Trace
session.use_device_allocator_for_initializers
Failed memory size calculation
DeserializeTensorProto() takes either pre-allocated buffer or an allocator!
Internal error. The preallocated buffer is too small. Requires 
onnxruntime::session_state_utils::DeserializeTensorProto
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\session_state_utils.cc
string tensor is not supported for copying between allocators
Failed to copy tensor to 
 ) is different from what is supplied (
) because the ORT planned memory location device 
Cannot use user supplied initializer with name: (
onnxruntime::session_state_utils::SaveInitializedTensors::<lambda_6c4003787d982facc3e4a14cc0a1fb45>::operator ()
Saving initialized tensors.
onnxruntime::session_state_utils::SaveInitializedTensors
OrtValue indexes should have been populated.
ort_value_name_idx_map.MaxIdx() > -1
entry != initialized_tensors_to_allocate.end() && entry->second->data_type() != ONNX_NAMESPACE::TensorProto_DataType_STRING
 bytes for 
[Memory] SessionStateInitializer statically allocates 
Using user supplied initializer with name (
 failed.
Deserialize tensor 
Done saving initialized tensors
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_f663e1cb5f92583d40a80c3711b532b4>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping
 is not used by any node.
 input with name 
Subgraph
Graph
 already exist.
func info for node: 
Can't use func with null ptr
 not found.
onnxruntime::FuncManager::GetFuncs
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\fuse_nodes_funcs.cc
!using_counters_
onnxruntime::MemPatternPlanner::TraceAllocation
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/mem_pattern_planner.h
current <= buffer_size_
ALLOW_RELEASED_ONNX_OPSET_ONLY
ai.onnx.ml
ai.onnx.training
ai.onnx.preview.training
[TypeInferenceError] 
Constant
TypeProto must have shape for this to run
shape != nullptr
onnxruntime::utils::GetShape
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/tensorprotoutils.h
 are '0' and '1'. The environment variable contained the value: 
onnxruntime::model_load_utils::IsAllowReleasedONNXOpsetsOnlySet
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/model_load_utils.h
Output:
Source and target must both be tensors
 , or optional typed entities
 , or sparse tensors
. Falling back to lenient merge.
 target:
' source:
Error merging shape info for output. '
onnxruntime::MergeShapeInfo
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph.cc
Tensor element type mismatch. 
 Input=
Type mismatch. Current=
onnxruntime::NodeArg::UpdateTypeAndShape
 . Got: 
Optional Type mismatch. Expected: 
] op_type [
Node [
Serialization of fused function body is not currently supported, 
does not have the graph for key 
onnxruntime::Node::SaveToOrtFormat
fbs_node_arg_names cannot be null
onnxruntime::Node::LoadFromOrtFormat::<lambda_6f09c8359fd46aaa68c171497d71a319>::operator ()
node_arg_name cannot be null
], could not find NodeArg 
LoadNodeArgsFromOrtFormat: Node [
onnxruntime::Node::LoadFromOrtFormat
fbs_attr cannot be null
Serialization error. Graph attribute was serialized without Graph instance
Node::LoadFromOrtFormat, input_arg_counts is missing
Node::LoadEdgesFromOrtFormat, edge is missing for 
onnxruntime::Node::LoadEdgesFromOrtFormat::<lambda_801af3d4b18b804a1ada0ca03a24b550>::operator ()
 is not the same as this node's index:
input index: 
onnxruntime::Node::LoadEdgesFromOrtFormat
input edges
output edges
This is an invalid model. The sum of input arg count is not equal to size of input defs in node (
graph_proto cannot be null
graph_proto != nullptr
onnxruntime::Graph::Graph
' Model is invalid.
Duplicate constant node sparse initializer name: '
Sparse initializer must have a name. This model is invalid
utils::HasName(sparse_tensor)
Duplicate sparse_tensor_initializer: '
. Please, fix your model.
' the model will use the latest encountered initializer
Duplicate initializer (dense, sparse or ConstantNode): '
This is an invalid model. Tensor does not have type information.
or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.
by either re-generating the model with latest exporter/converter 
Move it out of graph inputs if there is no need to override it, 
This may prevent some of the graph optimizations, like const folding. 
 appears in graph inputs and will not be treated as constant value/weight. 
Initializer 
Graph state to be loaded into must be empty.
graph_inputs_excluding_initializers_.empty() && graph_inputs_including_initializers_.empty() && value_info_.empty() && graph_outputs_.empty()
onnxruntime::Graph::InitializeStateFromModelFileGraphProto
Graph ctor should have created NodeArg for initializer. Missing:
node_arg
) does not exist in the graph.
This is an invalid model. Graph output (
This is an invalid model. Error: two nodes with same node name (
This is an invalid model. Error: Duplicate definition of name (
onnxruntime::Graph::SetOuterScopeNodeArgs
Invalid node indexes specified when adding edge.
onnxruntime::Graph::AddEdge
Invalid source node arg slot specified when adding edge.
Invalid destination node arg slot specified when adding edge.
Argument type mismatch when adding edge.
Invalid node indexes specified when removing edge.
onnxruntime::Graph::RemoveEdge
Invalid source node arg slot specified when removing edge.
Invalid destination node arg slot specified when removing edge.
Argument mismatch when removing edge.
onnxruntime::Graph::BuildConnections
 Graph may not conform to the ONNX spec and contain initializers that are not graph inputs.
This is an invalid model. At top level graph without matching NodeArg that subgraph consumes. Name=
This is an invalid model. Failed to find NodeArg in all parent graphs. Name=
' is not a graph input, initializer, or output of a previous node.
Invalid model. Node input '
Some nodes are not included in the topological sort, graph have a cycle.
onnxruntime::Graph::KahnsTopologicalSort
This is an invalid model. Error: the graph is not acyclic.
Graph attribute inferencing failed: 
 in node 
No Graph instance was found for attribute 
 inputs. Either provide all subgraph inputs, or just the required inputs.
 inputs and requires 
 inputs but subgraph has 
Size mismatch validating subgraph inputs. Got 
Node:
Subgraph input missing type.
onnxruntime::Graph::InferAndVerifySubgraphTypes
UpdateTypeShapeInference is not intended to be used with control flow nodes containing subgraphs
node.GetAttributeNameToMutableSubgraphMap().empty()
onnxruntime::Graph::UpdateShapeInference
) Op (
Node (
) does not have type information set by parent node.
) input arg (
This is an invalid model. Node (
) is invalid.
) in node (
) of operator (
' of input parameter (
This is an invalid model. Type Error: Type '
 in node (
) bound to different types (
) of Optype (
Type Error: Type parameter (
onnxruntime::Graph::InferAndVerifyTypeMatch
) type inference failed
) output arg (
) does not match expected type (
) of node (
) of output arg (
Type Error: Type (
) does not have type information.
This is an invalid model. Model input (
 but usage of initializer in graph expects 
' has element type 
Type Error: Data in initializer '
 does not match. 
Type Error: Shape of initializer 
, Error 
This is an invalid model. In Node, 
onnxruntime::Graph::VerifyNodeAndOpMatch
 is not a registered function/op
Fatal error: 
) is required but not specified.
) attribute (
. Execution will fail if ORT does not have a specialized kernel for this op
. Error message 
' optype 
Function body initialization failed for node '
onnxruntime::Graph::InitFunctionBodyForNode
Error: Duplicate definition-site for (
onnxruntime::Graph::InitInputsInitializersOutputs
onnxruntime::Graph::PerformTypeAndShapeInferencing
onnxruntime::Graph::ForThisAndAllSubgraphs
onnxruntime::Graph::Resolve
Shouldn't be possible to have NodeArgs that haven't been handled already.
outer_scope_node_args_consumed.empty()
 but different TensorProto.
AddInitializedTensor already has tensor with name 
existing->second == &tensor
onnxruntime::Graph::AddInitializedTensor
sparse_tensor_names_ not in sync with name_to_initial_tensor_
sparse_tensor_names_.count(tensor_name) == 0
onnxruntime::Graph::RemoveInitializedTensor
graph_proto_ is not in sync with name_to_initial_tensor_.
!found
onnxruntime::Graph::SaveToOrtFormat
_token_
 as it still has output edges.
Can't remove node 
node->GetOutputEdgesCount() == 0
onnxruntime::Graph::RemoveNode
Failed to convert dense initializer to sparse
onnxruntime::Graph::ToGraphProto
'was added but does not exist. 
Outer scope node arg name '
onnxruntime::Graph::ToGraphProtoInternal
Cannot find NodeArgs for [
initializer_node_arg != nullptr
onnxruntime::Graph::CleanUnusedInitializersAndNodeArgs
'. It is not used by any node and should be removed from the model.
Removing initializer '
'. It is no longer used by any node.
outer_scope_node_arg != nullptr
Removing NodeArg '
 must be either specified in graph inputs or graph initializers.
nodes_.size() < static_cast<unsigned int>(std::numeric_limits<int>::max())
onnxruntime::Graph::AllocateNode
nullptr != func_meta_def
onnxruntime::Graph::CreateFusedSubGraphNode
onnxruntime::Graph::FinalizeFuseSubGraph
dst_implicit_input_idx < (int)node->ImplicitInputDefs().size()
onnxruntime::Graph::InlineFunction
Input to set must exist.
input->Exists()
onnxruntime::Graph::SetInputs
) : (
) -> (
onnxruntime::Graph::LoadFromOrtFormat
NodeArg Name is missing. Invalid ORT format model.
onnxruntime::Graph::LoadFromOrtFormat::<lambda_24d691d3e5f81c7bd3c40ac3ff7d1f76>::operator ()
Initializer tensor is missing. Invalid ORT format model.
Duplicate initializer (dense or ConstantNode): '
Sparse Initializer tensor is missing. Invalid ORT format model.
NodeArg is missing. Invalid ORT format model.
Node is missing. Invalid ORT format model.
Node index is out of range
NodeEdge is missing. Invalid ORT format model.
index < data_.size()
onnxruntime::ConstPointerContainer<class std::vector<class onnxruntime::NodeArg *,class std::allocator<class onnxruntime::NodeArg *> > >::at
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/common/const_pointer_container.h
Domain already set in registry
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSet
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\schema_registry.cc
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSchemaInternal
known by the checker.
, but it its domain is not
than the operator set version 
, but it its version is higher
IndexedSubGraph contains values not present in the Graph
graph_->GetNode(idx) != nullptr
onnxruntime::GraphViewer::GraphViewer
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_viewer.cc
Mismatch between Graph and IndexedSubGraph. Input not found:
nodearg
Mismatch between Graph and IndexedSubGraph. Output not found:
Mismatch between Graph and IndexedSubGraph. Node not found: 
Invalid ExecutionOrder
onnxruntime::GraphViewer::GetNodesInTopologicalOrder
Not supported with filtered graph.
filter_info_ == nullptr
onnxruntime::GraphViewer::GetRootNodes
 is till opset 
 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 
onnxruntime::model_load_utils::ValidateOpsetForDomain
 is under development and support for this is limited. The operator schemas and or other functionality could possibly change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
ModelProto does not have a graph.
onnxruntime::Model::Model
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\model.cc
Missing opset in the model. All ModelProtos MUST have at least one entry that specifies which version of the ONNX OperatorSet is being imported.
Missing model IR version.
, max supported IR version: 
Unsupported model IR version: 
 model may run depending upon legacy support of some older opset version operators.
ONNX Runtime only *guarantees* support for models stamped with opset version 7 or above for opset domain 'ai.onnx'. Please upgrade your model to opset 7 or higher. For now, this opset 
Failed to load model with error: 
No graph was found in the protobuf.
onnxruntime::Model::Load
Protobuf parsing failed.
<p_fd> less than 0.
<p_fd> is less than 0.
onnxruntime::Model::Save
Protobuf serialization failed.
onnxruntime::Model::SaveToOrtFormat
Null entry in metadata_props. Invalid ORT format model.
onnxruntime::Model::LoadFromOrtFormat
Graph is null. Invalid ORT format model.
onnxruntime::SaveModel
 failed. File doesn't exist
Load model 
system error number 
Input tensor must have at least 2 dimensions
Output tensor must have at least 2 dimensions
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\nhwc_schema_defs.cc
Input data tensor from the previous operator; According to channels_last, dimensions for image case are (N x C x H x W), or (N x H x W x C) where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), or (N x D1 X D2 ... Dn x C) where N is the batch size.
Scale of quantized input 'X'. It must be a scalar.
x_scale
Zero point tensor for input 'X'. It must be a scalar.
x_zero_point
Scale of quantized output 'Y'. It must be a scalar.
y_scale
Zero point tensor for output 'Y'. It must be a scalar.
y_zero_point
Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. with the N and C value keep it value, while the otherdimensions are all 1.
Constrain input and output types to singed/unsigned int8 tensors.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
inputs are expected to have tensor type.
Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.
The size of the kernel along each axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.
Whether to use ceil or floor (default) to compute the output shape.
Works on NHWC layout or not? Default not.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input scale. It's a scalar, which means a per-tensor/layer quantization.
Input zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Output scale. It's a scalar, which means a per-tensor/layer quantization.
Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used
Constrain input and output types to 8 bit tensors.
input and zero_point pair is expected to have be same type.
weight and zero_point pair is expected to have same type.
w_scale
w_zero_point
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G.
Optional 1D bias to be added to the convolution, has size of M.
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
Constrain input and output types to float tensors.
The shape of the convolution kernel. If not present, should be inferred from input W.
dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.
Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis.
number of groups input channels and output channels are divided into.
NhwcConv
QLinearLeakyRelu takes quantized input data (Tensor), an argument alpha, and quantize parameter for output,
and produces one output data (Tensor<T>) where the function `f(x) = quantize(alpha * dequantize(x)) for dequantize(x) < 0`,
`f(x) = quantize(dequantize(x)) for dequantize(x) >= 0`, is applied to the data tensor elementwise.
QLinearSigmoid takes quantized input data (Tensor), and quantize parameter for output, and produces one output data 
(Tensor<T>) where the function `f(x) = quantize(Sigmoid(dequantize(x)))`, is applied to the data tensor elementwise.
Wwhere the function `Sigmoid(x) = 1 / (1 + exp(-x))` 
Output 
Attribute expected to have tensor or sparse tensor type
 is null
 expected to have tensor or sparse tensor type: 
 expected to have tensor or sparse type
 expected to have tensor type
Incompatible dimensions
 Dimension=
Can't merge shape info. Both source and target dimension have values but they differ. Source=
Input data type does not match the expected data type
Input data type does not match the expected data type. Current data type is 
Scale and Zero-point must be a scalar
Scale and Zero-point must be of rank 1
Scale and Zero-point must be of rank 1 and the number of elements should be equal to the number of rows of the corresponding input.
Performs element-wise binary {name} on 8 bit data types (with Numpy-style broadcasting support).
{additionalDocumentation}
{name}
{additionalDocumentation}
First operand.
Input A's scale. It's a scalar, which means a per-tensor/layer quantization.
A_scale
Input A zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
A_zero_point
Second operand.
Input B's scale. It's a scalar, which means a per-tensor/layer quantization.
B_scale
Input B zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
B_zero_point
C_scale
C_zero_point
Result, has same element type as two inputs
Constrain input and output types to 8 bit signed and unsigned tensors.
The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.
N-D full precision Input tensor to be quantized.
Scale for doing quantization to get 'y'. It could be a scalar or a 1-D tensor,which means a per-tensor or per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for doing quantization to get 'y'. It could be a scalar or a 1-D tensor, which means a per-tensoror per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
N-D quantized output tensor. It has same shape as input 'x'.
Constrain 'x', 'y_scale' to float tensors.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\quantization_defs.cc
N-D quantized Input tensor to be de-quantized.
Scale for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
N-D full precision output tensor. It has same shape as input 'x'.
Constrain 'x' and 'x_zero_point' to 8-bit integer tensors.
Constrain 'y', 'x_scale' to float tensors.
An input tensor.
Reduced output tensor.
reduced
Constrain input type to 8-bit integer tensor.
Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.
Keep the reduced dimension or not, default 1 mean keep reduced dimension.
ReduceSumInteger
Constrain output to 32 bit tensor
Constrain input types to 8 bit signed and unsigned tensors.
Constrain output types to 32 bit tensors.
MulInteger
N-dimensional matrix A
N-dimensional matrix B
Scale of quantized input 'B'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
b_scale
Zero point tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
b_zero_point
1D input tensor, whose dimension is same as B's last dimension
Matrix multiply results from A * B
Constrain input A, b_scale and output Y data type as float tensor.
Constrain input B data type to 8-bit integer tensor.
Scale of quantized input 'A'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
a_scale
Zero point tensor for input 'A'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
a_zero_point
Constrain input A data type to 8-bit integer tensor.
Constrain input a_scale, b_scale and output Y data type as float tensor.
C = (A_scale * (A - A_zero_point) + B_scale * (B - B_zero_point))/C_scale + C_zero_point
addition
QLinearAdd
C = ((A - A_zero_point) * (B - B_zero_point)) * (A_scale * B_scale)/C_scale + C_zero_point
multiplication
QLinearMul
axis must be in [-rank, rank-1]. input rank was 
data_scale
data_zero_point
reduced_scale
reduced_zero_point
QLinearReduceMean
Coefficient of leakage.
Input tensor
Input X's scale. It's a scalar, which means a per-tensor/layer quantization.
X_scale
Input X's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
X_zero_point
Output Y's scale. It's a scalar, which means a per-tensor/layer quantization.
Y_scale
Output Y's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Y_zero_point
Output tensor
QLinearLeakyRelu
QLinearSigmoid
Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.
Number of neurons in the hidden layer
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.
Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.
A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
Couple the input and forget gates if 1.
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, input_size, 4*hidden_size]`.
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, hidden_size, 4*hidden_size]`.
The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]`.
sequence_lens
Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
initial_h
Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
initial_c
The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.
W's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
W's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
R's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
R's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. 
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.
Constrain seq_lens to integer tensor.
Constrain weights types to 8 bit tensors.
Required attribute axis is missing
axis must be in [-rank, rank)
All inputs to Concat must have same rank
Which axis to concat on
Y's scale.
Y's zero point.
List of tensors/scale/zero_point for concatenation
inputs
Concatenated tensor
Constrain scale types to any float tensor type.
Sequence of (Tensor, Scale, ZeroPoint) tuples. The type is sequence of (T8, TF, T8).
QLinearConcat
First input does not have rank 2
Second input does not have rank 2
Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.
Scale of quantized input 'A'. It is a scalar,which means a per-tensor quantization.
Zero point tensor for input 'A'. It is a scalar.
Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.
Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). Its type is int32_t and must be quantized with zero_point = 0 and scale = alpha / beta * a_scale * b_scale.
Scale of output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
Zero point tensor for output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
Output tensor of shape (M, N).
Whether A should be transposed
Whether B should be transposed
Scalar multiplier for the product of input tensors A * B.
Constrain scale types to float tensors.
Constrain input A and its zero point types to 8 bit tensors.
Constrain input B and its zero point types to 8 bit tensors.
Constrain input C to 32 bit integer tensors.
Constrain output zero point types to 8 bit tensors.
Constrain output type to float32 or 8 bit tensors.
Number of attention heads
Whether every token can only attend to previous tokens. Default value is 0.
3D input tensor with shape (batch_size, sequence_length, input_hidden_size)
2D input tensor with shape (input_hidden_size, 3 * hidden_size), hidden_size = num_heads * head_size
weight
1D input tensor with shape (3 * hidden_size)
scale of quantized input tensor. It's a scalar, which means a per-tensor/layer quantization.
input_scale
scale of weight scale. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
weight_scale
Attention mask index with shape (batch_size)
zero point of quantized input tensor.It's a scalar, which means a per-tensor/layer quantization.
input_zero_point
zero point of quantized weight tensor. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
weight_zero_point
past state for key and value with shape (2, batch_size, num_heads, past_sequence_length, head_size).
3D output tensor with shape (batch_size, sequence_length, hidden_size)
present state for key and value with shape (2, batch_size, num_heads, past_sequence_length + sequence_length, head_size)
present
Constrain input and output types to int8 tensors.
Constrain mask index to integer types
QAttention
The epsilon value to use to avoid division by zero.
2D words IDs with shape (batch_size, sequence_length)
input_ids
2D segment IDs with shape (batch_size, sequence_length)
segment_ids
2D with shape (,hidden_size)
word_embedding_quant
2D with shape (, hidden_size)
position_embedding_quant
segment_embedding
1D gamma tensor for layer normalization with shape (hidden_size)
gamma_quant
1D beta tensor for layer normalization  with shape (hidden_size)
beta_quant
Scale for word embeddings
word_embedding_scale
Scale for position embeddings
position_embedding_scale
Scale for segment embeddings
segment_embedding_scale
Scale for 1D gamma tensor
gamma_scale
Scale for 1D beta tensor
beta_scale
Zero point for word embeddings
word_embedding_zero_point
Zero point for position embeddings
position_embedding_zero_point
Zero Point for segment embeddings
segment_embedding_zero_point
Zero Point for 1D gamma tensor
gamma_zero_point
Zero Point for 1D beta tensor
beta_zero_point
LayerNorm Output
layernorm_out
Mask Index Output
mask_index_out
Constrain input and output types to float32 tensors.
QEmbedLayerNormalization
+Error parsing node:
Error unexpected extra input in node:
 = Constant()
key and value cache shall be 4 dimensions
Hidden layer sizes of Q, K, V paths in Attention
qkv_hidden_sizes
2D input tensor with shape (input_hidden_size, 3 * hidden_size), where hidden_size = num_heads * head_size
Attention mask with shape (batch_size, 1, max_sequence_length, max_sequence_length), (batch_size, past_sequence_length + sequence_length)or (batch_size, sequence_length, past_sequence_length + sequence_length), or index with shape (batch_size) or (2 * batch_size).
additional add to QxK' with shape (batch_size, num_heads, sequence_length, sequence_length).
extra_add
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\bert_defs.cc
One sided attention windows length W, or half of total window length
window
3D input tensor with shape (batch_size, sequence_length, hidden_size), hidden_size = num_heads * head_size
2D input tensor with shape (hidden_size, 3 * hidden_size)
Attention mask with shape (batch_size, sequence_length)
global_weight
global_bias
Global attention flags with shape (batch_size, sequence_length)
global
Constrain to integer types
LongformerAttention
3D input tensor with shape (sequence_length, batch_size, hidden_size), hidden_size = num_heads * head_size
query
3D input tensor with shape (total_sequence_length, batch_size, hidden_size)
2D input tensor with shape (hidden_size, hidden_size)
q_weight
2D input tensor with shape (hidden_size, 2 * hidden_size)
kv_weight
2D input tensor with shape (batch_size, total_sequence_length)
key_padding_mask
input tensor with shape (batch_size, num_heads, sequence_length or total_sequence_length, head_size)
key_cache
value_cache
If static_kv = true, cross-attention; else self-attention
static_kv
If use_past = true, use cache; else no cache
use_past
If has_layer_state = true, layer_state = {} or [a,b]; else layer_state = None
has_layer_state
has_key_padding_mask or not
has_key_padding_mask
3D output tensor with shape (sequence_length, batch_size, hidden_size)
output tensor with shape (batch_size, num_heads, new sequence_length, head_size)
new_key_cache
new_value_cache
Constrain input and output types to float and float16 tensors.
Constrain key_padding_mask to bool tensors.
DecoderAttention
word_embedding
position_embedding
2D attention mask with shape (batch_size, sequence_length)
2D position ids with shape (batch_size, sequence_length)
position_ids
1D mask_index tensor with shape (batch_size)
sum of word_embedding and position_embedding without layer normalization
embedding_sum
Constrain input and output integer tensors types
Constrain input and output float tensors types.
X_bias = Add (X, bias)
X_bias = Identity (X)
                T1 = Mul (X_bias, X_bias)
                T2 = Mul (c, T1)
                T3 = Add (b, T2)
                T4 = Mul (X_bias, T3)
                T5 = Tanh (T4)
                T6 = Add (one, T5)
                T7 = Mul (X_bias, T6)
                Y = Mul (a, T7)
            
input tensor
bias tensor
output tensor
Constrain input and output types to float or half tensors.
3D input tensor with shape (batch_size, sequence_length, hidden_size)
3D skip tensor with shape (batch_size, sequence_length, hidden_size)
1D input tensor with shape (hidden_size)
1D skip tensor with shape (hidden_size
1D bias tensor with shape (hidden_size
Saved mean used during training to speed up gradient computation
Saved inverse standard variance used during training to speed up gradient computation.
inv_std_var
Constrain mean and inv_std_var to float tensors.
The NGram size.
ngram_size
2D input tensor with shape (batch_size, sequence_length)
2D input tensor with shape (batch_size, vocab_size)
scores
2D output tensor with shape (batch_size, vocab_size)
scores_out
Constrain indices to integer types
Constrain scores input and output types to float tensors.
NGramRepeatBlock
The minimum NGram size for suffix matching.
min_ngram_size
The maximum NGram size for suffix matching.
max_ngram_size
Encoder input ids.
src_tokens
Decoder input ids.
cur_tokens
Previous suffix match index
prev_suffix_match_idx
Predicted token ids from aggressive decoding
pred_tokens
Decoder input ids after merging predicted tokens
tokens
new suffix match index
suffix_match_idx
Constrain to integer types.
BifurcationDetector
&TpxAD
? but has rank 
 expected to have rank 
Dimension mismatch in unification between 
 expected to have rank >
'pads' input must be a 1D (shape: [2 * n_input_dims]) tensor of type int64
Pads has incorrect number of values
output_shape
output_padding
Input tensors of wrong rank (0).
Incompatible dimensions for matrix multiplication
Inputs 0 shall be 2 dimensions
Failed to parse max_length or it is not positive integer scalar
Failed to parse num_beams or it is not positive integer scalar
Failed to parse num_return_sequences or it is not positive integer scalar
                CX = Mul (C, X)
                ERFCX = Erf (CX)
                ERFCXPlus1 = Add (ERFCX, One)
                PhiX = Mul (ERFCXPlus1, Half)
                Y = Mul (X, PhiX)
            
The input data as Tensor.
The output.
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\contrib_defs.cc
The normal input data.
The bias input data that is a 1D tensor.
Input rank must be >= 2.
 != mat_h:
The inner-most 2 dimensions must have the same size (mat_w:
Input tensor. Every matrix in the batch must be invertible.
Output tensor of the same type and shape as the input tensor.
Inverse
The embedding matrix of size N x M. 'N' is equal to the maximum possible index + 1, and 'M' is equal to the embedding size
Long tensor containing the indices to extract from embedding matrix.
indices
A 0-D scalar tensor. If specified, the entries at `padding_idx` do not contribute to the gradient; therefore, the embedding vector at `padding_idx` is not updated during training, i.e. it remains as a fixed pad.
padding_idx
A 0-D bool tensor. If given, this will scale gradients by the inverse of frequency of the indices (words) in the mini-batch. Default  is ``False``
scale_grad_by_freq
Output tensor of the same type as the input tensor. Shape of the output is * x M, where '*' is the shape of input indices, and 'M' is the embedding size.
Constrain input and output types to all numeric tensors.
TorchEmbedding
Boolean. Indicates whether upper or lower part of matrix is retained. Default is true.
upper
Input tensor of rank 2 or higher.
A 0-D tensor containing a single value corresponding to the number diagonals above or the main diagonal to exclude or include.Default value is 0 if it's not specified.
Constrain input and output types to all numeric tensors and bool tensors.
Trilu
apply softmax to elements for dimensions softmax_axis or higher
broadcast bias across input for dimensions broadcast_axis to softmax_axis-1
The bias (or mask) as Tensor.
(Optional) Seed to the random generator, if not specified we will auto generate one.
The bias input, a vector with the same shape as last dim of data OR same shape with data
The residual input, must have the same shape as data
residual
The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of input, which is typically the case during training.
ratio
If set to true then it indicates dropout is being used for training. It is an optional value hence unless specified explicitly, it is false. If it is false, ratio is ignored and the operation mimics inference mode where nothing will be dropped from the input data and if mask is requested as output it will contain all ones.
training_mode
The output mask of dropout.
Constrain input 'ratio' types to float tensors.
Constrain output 'mask' types to boolean tensors.
isinf_only
isnan_only
Both attributes isinf_only and isnan_only cannot be set. Unset both to check for both conditions.
IsAllFinite
If true, check only for Inf, -Inf.
If true, check only for NaN.
Constrain the output to a boolean tensor.
Input tensors to check.
The output scalar. Its value is true if all input tensors are finite. Otherwise, the output value would be false.
bilinear
Three interpolation modes: bilinear (default), nearest and bicubic.
zeros
Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations.
padding_mode
If align_corners=1, the extrema (-1 and 1) are considered as referring to the center points of the input's corner pixels. If align_corners=0, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.
4-D tensor of shape (N, C, H, W), where N is the batch size, C is the numbers of channels, H and W are the height and width of the input data.
Input offset, 4-D tensor of shape (N, H_out, W_out, 2), where H_out and W_out are the height and width of grid and output, Grid specifies the sampling pixel locations normalized by the input spatial dimensions. Therefore, it should have most values in the range of [-1, 1]. If grid has values outside the range of [-1, 1], the corresponding outputs will be handled as defined by padding_mode.
4-D tensor of shape (N, C, H_out, W_out).
Constrain input types to all tensor types.
Constrain output types to float tensors.
The id of the end-of-sequence token
eos_token_id
The id of the padding token
pad_token_id
no repeat ngrams size
no_repeat_ngram_size
early stop or not
early_stopping
model type: 0 for GPT-2; 1 for encoder decoder like T5
model_type
subgraph for initialization of encoder and decoder. It will be called once before decoder subgraph.
encoder_decoder_init
Decoder subgraph to execute in a loop.
decoder
The sequence used as a prompt for the generation. Shape is (batch_size, sequence_length)
The maximum length of the sequence to be generated. Shape is (1)
max_length
The minimum length below which the score of eos_token_id is set to -Inf. Shape is (1)
min_length
Number of beams for beam search. 1 means no beam search. Shape is (1)
num_beams
The number of returned sequences in the batch. Shape is (1)
num_return_sequences
The value used to module the next token probabilities. Accepts value > 0.0. Shape is (1)
temperature
Exponential penalty to the length. Default value 1.0 means no penalty.Value > 1.0 encourages longer sequences, while values < 1.0 produces shorter sequences.Shape is (1,)
length_penalty
The parameter for repetition penalty. Default value 1.0 means no penalty. Accepts value > 0.0. Shape is (1)
repetition_penalty
Mask of vocabulary. Words that masked with 0 are not allowed to be generated, and 1 is allowed. Shape is (vacab_size)
vocab_mask
Mask of vocabulary for first step. Words that masked with 0 are not allowed to be generated, and 1 is allowed. Shape is (batch_size, vocab_size)
prefix_vocab_mask
Word IDs of generated sequences. Shape is (batch_size, num_return_sequences, max_sequence_length)
sequences
Final beam score of the generated sequences. Shape is (batch_size, num_return_sequences)
sequences_scores
Processed beam scores for each vocabulary token at each generation step.Beam scores consisting of log softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam.Shape is (max_length - sequence_length, batch_size, num_beams, vocab_size)
Constrain mask to integer types
BeamSearch
Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.
SampleOp
Constrain input0 and output types to float tensors
MaxpoolWithMask
signal_ndim
normalized
onesided
Irfft
input_0
input_1
ComplexMul
ComplexMulConj
Constrain input and output types to float tensors
ConvTransposeWithDynamicPads
Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).
Constrain input and output types to float/int tensors.
Scalar multiplier for input tensor C.
activation_gamma
Input axis is invalid: 
Specified axis to insert a dimension
ExpandDims
Input dimensions are either [C] or [N][C] allowed
Strings to tokenize
Tokenized strings
Input/Output is a string tensor
Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).
The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.
pad_value
An optional string. Token's regular expression in basic POSIX format (pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.
tokenexp
an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.
separators
Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored
mincharnum
Tokenizer
inputs are expected to have tensor type and output type should not be null.
Constrain input A data types as 16-bit integer tensor
Constrain input B data types as 16-bit integer tensor
Constrain output Y data types as 32-bit integer tensor.T3 must be tensor(uint32) when both T1 and T2 are tensor(uint16),or must be tensor(int32) when either T1 or T2 is tensor(int16).
MatMulInteger16
Scalar multiplier for the product of the input tensors.
Whether A should be transposed on the last two dimensions before doing multiplication
Whether B should be transposed on the last two dimensions before doing multiplication
Matrix multiply results
Whether A should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication
Whether B should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication
2-dimensional sparse matrix A. Either COO or CSR format
N-dimensional dense matrix B
sparse_tensor(float)
sparse_tensor(double)
sparse_tensor(int64)
sparse_tensor(int32)
sparse_tensor(uint64)
sparse_tensor(uint32)
SparseToDenseMatMul
positive
An input tensor to hash.
32-bit hash value.
Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.
Constrain output type to unsigned and signed 32-bit integer tensor.
Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.
If value is 1, output type is uint32_t, else int32_t. Default value is 1.
MurmurHash3
both data and indices tensor need to have rank larger than zero.
last dimension of indices must not be larger and rank of data tensor
Tensor of rank r >= 1.
Tensor of rank q >= 1.
Tensor of rank q-1+r-indices[-1].
Constrain input and output types to any tensor type.
Constrain indice type to int32 or int64
GatherND
Integer representing the embedding vector size for each word.If not provide, use the fileter size of conv weight
embedding_size
This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernal shape.
conv_window_size
Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.
char_embedding_size
Specify batchs of sequence words to embedding
Sequence
Specify weights of conv
Specify bias of conv
Specify embedding vector of char
Constrain to tensor(int32).
Constrain to tensor(float).
WordConvEmbedding
'pads' input must be a 1D (shape: [input_rank]) or 2D tensor (shape: [1, input_rank]) of type int64
constant
Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array
Input tensor.
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
(Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).
Tensor after padding.
A 1-D input tensor that is to be processed.
A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'
A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'
A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'
counts
Input can be of any tensor type.
Unique
sqeuclidean
The distance metric to use. If a string, the distance function can be "braycurtis", "canberra", "chebyshev", "cityblock", "correlation", "cosine", "dice", "euclidean", "hamming", "jaccard", "jensenshannon", "kulsinski", "mahalanobis", "matching", "minkowski", "rogerstanimoto", "russellrao", "seuclidean", "sokalmichener", "sokalsneath", "sqeuclidean", "wminkowski", "yule".
metric
2D matrix with shape (M,N)
2D matrix with shape (K,N)
A 2D Matrix that represents the distance between each pair of the two collections of inputs.
Constrains input to only numeric types.
CDist
first input tensor has wrong dimension
rois input tensor has wrong dimension
batch_indices shape input tensor has wrong dimension
crop_size shape input tensor has wrong dimension
The pooling method. Two modes are supported: 'bilinear' and 'nearest'. Default is 'bilinear'.
Value used for extrapolation, when applicable. Default is 0.0f. 
extrapolation_value
Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[y1, x1, y2, x2], ...]. The RoIs' coordinates are normalized in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.
batch_indices
1-D tensor of 2 elements: [crop_height, crop_width]. All cropped image patches are resized to this size. Both crop_height and crop_width need to be positive.
crop_size
RoI pooled output, 4-D tensor of shape (num_rois, C, crop_height, crop_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
Constrain types to float tensors.
Constrain types to int tensors.
CropAndResize
stash_type
Epsilon
XShape = Shape (X)
Rank = Size (XShape)
Zero1D = Constant()
Axis1D = Constant()
PrefixShape = Slice (XShape, Zero1D, Axis1D)
NumReducedAxes = Sub (Rank, Axis1D)
NumReducedAxes = Neg (Axis1D)
SuffixShape = ConstantOfShape (NumReducedAxes)
ReducedShape = Concat <axis = 0> (PrefixShape, SuffixShape)
X2D = Flatten (X)
XU = Cast (X2D)
Mean2D = ReduceMean <axes = [1]> (XU)
Square = Mul (XU, XU)
MeanOfSquare = ReduceMean <axes = [1]> (Square)
SquareOfMean = Mul (Mean2D, Mean2D)
Var = Sub (MeanOfSquare, SquareOfMean)
VarPlusEpsilon = Add (Var, Epsilon)
StdDev = Sqrt (VarPlusEpsilon)
Deviation = Sub (XU, Mean2D)
Normalized = Div (Deviation, StdDev)
NormalizedT = Cast (Normalized)
Scale2D = Flatten <axis = 0> (Scale)
Scaled = Mul (NormalizedT, Scale2D)
B2D = Flatten <axis=0> (B)
Biased = Add (Scaled, B2D)
Biased = Identity (Scaled)
Y = Reshape (Biased, XShape)
InvStdDev2D = Reciprocal (StdDev)
Mean = Reshape (Mean2D, ReducedShape)
InvStdDev = Reshape (InvStdDev2D, ReducedShape)
max_output_boxes
Attribute 'max_output_boxes' must be >= 1.
pooled_size
Attribute 'pooled_size' must be >= 1.
AttnLSTM
The first normalization dimension: normalization will be performed along dimensions axis : rank(inputs).
type used for stash mean/inv_std_var
Input data tensor from the previous layer.
Scale tensor.
Scale
Bias tensor.
Output data tensor.
Saved inverse standard deviation used during training to speed up gradient computation.
InvStdDev
Constrain input types and output Y type to float tensors.
Type of Mean and InvStdDev tensors.
scale
Constrain input and output types (except mean and inv_std_var) to float tensors.
Constrain mean and inv_std_var to be float tensors.
EfficientNMS_TRT
The boxes input tensor.
boxes
The scores input tensor.
The anchors input tensor.
anchors
The num_detections output tensor.
num_detections
The detection_boxes output tensor.
detection_boxes
The detection_scores output tensor.
detection_scores
The detection_classes output tensor.
detection_classes
Background class ID.
background_class
Encoding type for the boxes or anchors inputs.
box_coding
Box IOU threshold value.
iou_threshold
Max detections to output.
Version number of the TRT plugin.
plugin_version
Activation function to apply to the scores input.
score_activation
Score threshold value.
score_threshold
MultilevelCropAndResize_TRT
The first feature map input tensor.
feature_map_0
The second feature map input tensor.
feature_map_1
The third feature map input tensor.
feature_map_2
The fourth feature map input tensor.
feature_map_3
The cropped patches output tensor.
patches
Image size.
image_size
Pooled size.
PyramidROIAlign_TRT
Attribute 
 should specify a shape
Negative values are not allowed in a shape specification
Value of alpha
Value of beta
1D input tensor
1D output tensor
Affine
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\onnx_deprecated_operators.cc
Bias applied to each channel, same size as C.
The scale to apply.
Input tensor of shape [N,C,H,W]
Result, has same shape and type as input
ImageScaler
A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).
border
A 1-D values of (height, width).
Result, has same type as input, with H and W dimensions reduced.
Threshold value
Tensor of data to extract slices from.
1-D tensor of starting indices of corresponding axis in `axes`
1-D tensor of ending indices (exclusive) of corresponding axis in axes
1-D tensor of axes that `starts` and `ends` apply to.
Sliced data tensor.
Constrain input and output types to all tensor types.
DynamicSlice
input_as_shape
extra_shape
The shape of filled tensor
The filled tensor
values
GivenTensorFill
Input data to be scaled
Output data after scaling
Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length.
drop_states
The previous GRU hidden state.
hidden_prev
Unactivated gate outputs from forget, update, and output gates, pre-activation.
gates
Array of sequence lengths.  len(seq_lengths) should equal batch size N.
seq_lengths
The timestep for this operation.
The new GRU hidden state calculated by this op.
hidden
GRUUnit
If 1, mean and variance are computed across channels. Default is 0.
across_channels
If 0, normalize the mean only.  Default is 1.
normalize_variance
MeanVarianceNormalization
Scaling value
The scaled hyperbolic tangent values of the input tensor computed element-wise
Input's shape must be 4-D
'Border' attribute must be present and must contain exactly 4 values - (left_border, top_border, right_border, bottom_border)
'Scale' must contain exactly 2 values - (height, width)
) + bottom_border (
) needs to be greater than or equal to the top_border (
Input's height (
) + right_border (
) needs to be greater than or equal to the left_border (
Input's width (
) + scale[0] (
) + scale[1] (
for node: 
Attempting to get index by a name which does not exist:
itr != node_args.end()
onnxruntime::graph_utils::GetIndexFromName
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_utils.cc
std::count_if(subgraph_node.InputEdgesBegin(), subgraph_node.InputEdgesEnd(), [input_slot_index](const Node::EdgeEnd& entry) { return entry.GetDstArgIndex() == input_slot_index; }) == 0
onnxruntime::graph_utils::UpdateImplicitInputNameInSubgraph
 in one of the subgraphs.
 cannot be safely updated to 
 Implicit input name 
onnxruntime::graph_utils::CanUpdateImplicitInputNameInSubgraphs
Node must only have one used output
std::all_of(output_edges.cbegin(), output_edges.cend(), [&src_idx](const GraphEdge& edge) { return edge.src_arg_index == src_idx; })
onnxruntime::graph_utils::RemoveNodeWithSingleNodeInSingleUsedOutput
Initializer with same name exists. Name:
!graph.GetInitializedTensor(new_initializer.name(), existing)
onnxruntime::graph_utils::AddInitializer
Attempting to get an input that does not exist.
index >= 0 && static_cast<size_t>(index) < inputs.size()
onnxruntime::graph_utils::GetNodeInputName
Attempting to get an output that does not exist.
index >= 0 && static_cast<size_t>(index) < outputs.size()
onnxruntime::graph_utils::GetNodeOutputName
Should be unreachable if CanRemoveNodeAndMergeEdges is in sync with the logic here.
onnxruntime::graph_utils::RemoveNode
 ImplicitInputs:
 ExplicitInputs:
. Index:
Invalid input index for node 
onnxruntime::graph_utils::ReplaceNodeInput
Can only add a new input at the end of the current ones.
num_explicit_inputs == static_cast<size_t>(target_input_idx)
onnxruntime::graph_utils::AddNodeInput
Failed since multiple edges matched:
onnxruntime::graph_utils::FindPath
onnxruntime::RuntimeOptimizationRecordContainer::SaveToOrtFormat
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\runtime_optimization_record_container.cc
onnxruntime::RuntimeOptimizationRecordContainer::LoadFromOrtFormat
Attempting to load runtime optimization records for a previously loaded optimizer: 
Not supported
onnxruntime::ViewerFunctionImpl::Body
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/function_impl.h
onnxruntime::ViewerFunctionImpl::MutableBody
 is out of bounds.
GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.
 does not contain a graph.
 optype 
 referenced by function body node 
. No opset import for domain
Cannot infer type and shape for function
 in function opset imports.
No opset registered for domain 
domain_version != -1
onnxruntime::IOTypeConstraintHelper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\function.cc
'. Error message 
Function body initialization failed for Function '
onnxruntime::InitNestedModelLocalFunction
A node with a function body within a subgraph within another function body is currently not supported in ORT
onnxruntime::UpdateSubgraphsWithinFunctionBody
input_arg->Type() != nullptr
onnxruntime::CreateSchema
fused_function_subgraph
 is not found or is not constant initializer.
initializer != nullptr
onnxruntime::FunctionImpl::FunctionImpl
_dummy
Resolve subgraph failed:
's number of inputs is different from function body graph's number of input.
Node 
node_in_parent_graph->InputDefs().size() == function_body_graph.GetInputsIncludingInitializers().size()
's number of outputs is different from function body graph's number of outputs.
node_in_parent_graph->OutputDefs().size() == function_body_graph.GetOutputs().size()
TENSOR
UNDEFINED
FLOAT
STRING
GRAPH
FLOATS
STRINGS
TENSORS
GRAPHS
SPARSE_TENSOR
SPARSE_TENSORS
onnxruntime::fbs::utils::SaveInitializerOrtFormat
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_flatbuffers_utils.cc
onnxruntime::fbs::utils::SaveSparseInitializerOrtFormat
onnxruntime::fbs::utils::SaveAttributeOrtFormat
Graph attribute value was null. Invalid ORT format model.
SaveAttributeOrtFormat: Unsupported attribute type: 
Missing dimensions for initializer. Invalid ORT format model.
onnxruntime::fbs::utils::LoadInitializerOrtFormat
Missing string data for initializer. Invalid ORT format model.
Missing raw data for initializer. Invalid ORT format model.
Missing values for sparse initializer. Invalid ORT format model.
onnxruntime::fbs::utils::LoadSparseInitializerOrtFormat
Missing name for SparseTensor initializer. Invalid ORT format model.
Invalid ORT format model.
Missing indicies for sparse initializer: 
Missing dims for sparse initializer: 
Null string attribute. Invalid ORT format model.
onnxruntime::fbs::utils::LoadAttributeOrtFormat
Null tensor attribute. Invalid ORT format model.
Null graph attribute. Invalid ORT format model.
Empty graph proto from deserialization of ORT format model
Null floats attribute. Invalid ORT format model.
Null ints attribute. Invalid ORT format model.
Null strings attribute. Invalid ORT format model.
Null string in strings attribute. Invalid ORT format model.
Null tensors attribute. Invalid ORT format model.
Null tensor in tensors attribute. Invalid ORT format model.
input_ids shall be 2 dimensions
segment_ids input shall be 2 dimensions
word_embedding should have 2 dimensions and dimension size is known.
position_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
segment_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
gamma should have 2 dimension, dimension size known, and same hidden size as word_embedding.
beta should have 1 dimension, dimension size known, and same hidden size as word_embedding.
Inputs 0 shall be 3 dimensions
Invalid bias shape
qkv_hidden_sizes should have 3 elements
Inputs 4 shall be 5 dimensions
tensor rank too small
invalid scales dimension
invalid scales value
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\nchwc_schema_defs.cc
Couple the input and forget gates if 1, default 0.
Number of neurons in the hidden layer.
Constrain seq_lens to integral tensors.
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, 4*hidden_size, input_size]`.
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 4*hidden_size, hidden_size]`.
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]` 
The weight tensor of the query layer in the attention mechanism. Should be of shape `[num_directions, am_query_depth(hidden_size of lstm), am_attn_size]` 
The weight tensor of the memory layer in the attention mechanism. Should be of shape `[num_directions, memory_depth, am_attn_size]` 
The attention_v tensor in the attention mechanism. Should be of shape `[num_directions, am_attn_size]` 
The sequence of the memory (input) for attention mechanism. Should be of `[batch_size, max_memory_step, memory_depth]` 
The sequence length of the input memory for the attention mechanism. Should be of `[batch_size]` 
memory_seq_lens
The weights of attention layer in the attention wrapper. If exists, should be of shape `[num_directions, memory_depth+hidden_size, aw_attn_size]. Please note that attention mechanism context depth is also memory_depth in the attention mechanism.` 
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`. 
Can not get shape initializer data!
Unsupported type:
Constrain input and output types.
Tensor(scalar, or dims=[1]). First entry in the range.
Tensor(scalar, or dims=[1]). Upper limit of sequence, exclusive.
limit
Tensor(scalar, or dims=[1]). Number that increments start. Defaults to 1.
delta
1-D Tensor of the range.
Unsupported non-raw-data data type!
custom join thread function not set
onnxruntime::concurrency::CreateThreadPoolHelper
D:\a\_work\1\s\onnxruntime\onnxruntime\core\util\thread_utils.cc
Received null OrtThreadingOptions
Received invalid value for allow_spinning. Valid values are 0 or 1
dims[d_i] < d_max
onnxruntime::math::NextPosition
D:\a\_work\1\s\onnxruntime\onnxruntime\core\util\math_cpu.cc
Gemv found an unexpected CBLAS_TRANSPOSE input of
onnxruntime::math::Gemv
AQ5@.
<2?~>
=4?~?
++Q5@.{
=2?~>4?~?
++Q5@.Q5@.Q5@.Q5@.{
=2?~>2?~>2?~>2?~>4?~?4?~?4?~?4?~?
\3JCy7
?33{@
l?33{@33{@33{@33{@
bad dimensions
) is not supported on this device
), BIsSigned(
Quant GEMM format: AIsSigned(
SUCCESS
NO_SUCHFILE
NO_MODEL
ENGINE_ERROR
RUNTIME_EXCEPTION
INVALID_PROTOBUF
MODEL_LOADED
NOT_IMPLEMENTED
INVALID_GRAPH
EP_FAIL
GENERAL ERROR
code != static_cast<int>(common::OK)
onnxruntime::common::Status::Status
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\status.cc
SystemError
[ONNXRuntimeError]
Exception
ReturnHr
LogHr
FailFast
%hs(%u)\%hs!%p: 
%hs!%p: 
(caller: %p) 
%hs(%d) tid(%x) %08X %ws
Msg:[%ws] 
CallContext:[%hs] 
[%hs(%hs)]
[%hs]
std::exception: %hs
generic
system
unknown error
custom_create_thread_fn returned invalid handle.
onnxruntime::`anonymous-namespace'::WindowsThread::WindowsThread
D:\a\_work\1\s\onnxruntime\onnxruntime\core\platform\windows\env.cc
onnxruntime
Fatal error: 0 count processors from GetSystemInfo
onnxruntime::`anonymous-namespace'::WindowsEnv::GetNumCpuCores
Fatal error: 0 count processors from GetLogicalProcessorInformation
 fail, errcode = 
open file 
GetFileSizeEx 
Invalid fd was supplied: 
Received negative size from stat call
file_path == nullptr
onnxruntime::`anonymous-namespace'::WindowsEnv::ReadFileIntoBuffer
offset < 0
length > buffer.size()
SetFilePointerEx 
ReadFile 
 fail: unexpected end
MapFileIntoMemory is not implemented on Windows.
, error code: 
DeleteFile() failed - path: 
onnxruntime::`anonymous-namespace'::WindowsEnv::DeleteFolder
RemoveDirectory() failed - path: 
GetFinalPathNameByHandle() failed: 
onnxruntime::`anonymous-namespace'::WindowsEnv::GetCanonicalPath
" when trying to load "
LoadLibrary failed with error 
FreeLibrary failed with error 
 in library, error code: 
Failed to find symbol 
onnxruntime::`anonymous-namespace'::WindowsEnv::FormatLibraryFileName
onnxruntime::LoopDir
D:\a\_work\1\s\onnxruntime\onnxruntime\core/platform/path_lib.h
Failed to parse path root: 
onnxruntime::`anonymous-namespace'::ParsePathRoot
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\path.cc
onnxruntime::Path::Parse
onnxruntime
System
ISink must be provided.
onnxruntime::logging::LoggingManager::LoggingManager
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\logging\logging.cc
default_logger_id must be provided if instance_type is InstanceType::Default
Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.
Default logger already set. 
onnxruntime::logging::LoggingManager::CreateDefaultLogger
N@length overflow
onnxruntime::ToUTF8String
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\helper.cc
onnxruntime::ToWideString
Session
Kernel
enabled_
onnxruntime::profiling::Profiler::Start
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\profiler.cc
session_logger != nullptr
onnxruntime::profiling::Profiler::Initialize
Maximum number of events reached, could not record profile event.
onnxruntime::profiling::Profiler::EndTimeAndRecordEvent
Writing profiler data to file 
onnxruntime::profiling::Profiler::EndProfiling
{"cat" : "
"pid" :
"tid" :
"dur" :
"ts" :
"ph" : "X",
"name" :"
"args" : {
" : "
unnamed_thread_pool
Profiler not started yet
onnxruntime::concurrency::ThreadPoolProfiler::Stop
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\threadpool.cc
}, "sub_threads": {
"thread_pool_name": "
{"main_thread": {
LogStart must pair with LogEnd
!points_.empty()
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEnd
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEndAndStart
points_.empty()
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::Reset
", "block_size": [
"thread_id": "
], "core": 
Distribution
DistributionEnqueue
WaitRevoke
UnknownEvent
"core": 
"num_run": 
Nested parallelism not supported
!current_parallel_section
onnxruntime::concurrency::ThreadPool::ParallelSection::ParallelSection
n >= 0
onnxruntime::concurrency::ThreadPool::ParallelFor
More work items than threads
n <= num_threads_+1
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallel
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/platform/EigenNonBlockingThreadPool.h
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallelSection
unexpected failure
illegal input path:
VIWEF
 is not a valid date
 is not a valid year
 is not a valid day
tensor_type
sequence_type
map_type
onnxruntime::fbs::utils::SaveSequenceTypeOrtFormat
D:\a\_work\1\s\onnxruntime\onnxruntime\core\flatbuffers\flatbuffers_utils.cc
onnxruntime::fbs::utils::SaveMapTypeOrtFormat
onnxruntime::fbs::utils::SaveTensorTypeAndShapeOrtFormat
onnxruntime::fbs::utils::SaveTypeInfoOrtFormat
] for now
We do not support type [
onnxruntime::fbs::utils::SaveValueInfoOrtFormat
 is missing type info.
SaveValueInfoOrtFormat: value_info_proto for 
dim_param value with no name. Invalid ORT format model.
onnxruntime::fbs::utils::LoadTensorDimensionOrtFormat
Null entry in dimensions. Invalid ORT format model.
onnxruntime::fbs::utils::LoadTensorShapeOrtFormat
onnxruntime::fbs::utils::LoadTensorTypeAndShapeOrtFormat
Null value type info in fbs::SequenceType. Invalid ORT format model.
onnxruntime::fbs::utils::LoadSequenceTypeOrtFormat
Null value type info in fbs::MapType. Invalid ORT format model.
onnxruntime::fbs::utils::LoadMapTypeOrtFormat
Null tensor type info. Invalid ORT format model.
onnxruntime::fbs::utils::LoadTypeInfoOrtFormat
Null sequence type info. Invalid ORT format model.
Null map type info. Invalid ORT format model.
 is not supported currently
Type:
. Invalid ORT format model.
Null type info for 
onnxruntime::fbs::utils::LoadValueInfoOrtFormat
Model must have opset imports. Invalid ORT format model.
onnxruntime::fbs::utils::LoadOpsetImportOrtFormat
opset id is null. Invalid ORT format model.
opset import domain is null. Invalid ORT format model.
, has unsupported type: 
 typestr: 
 has inconsistent type 
 has unsupported type 
' has been deprecated since version 
Operator '
, max=
 not in range [min=
) has input size 
 not in allowed input sizes.
) has output size 
 not in allowed output sizes.
has output size 
) in op definition.
) than declared (
) has more inputs (
 is marked single but has an empty string in the graph
)'s input 
) has more outputs (
)'s output 
' appeared multiple times.
Attribute '
 for operator 
Unrecognized attribute: 
Mismatched attribute type in '
' is expected to have field 't'
' is expected to have field 'sparse_tensor'
' is expected to have field 'g'
' is expected to have field 'type_proto'
' is expected to have field 'floats'
' is expected to have field 'ints'
' is expected to have field 'strings'
' is expected to have field 'tensors'
' is expected to have field 'graphs'
' is expected to have field 'type_protos'
 has unknown expected type
' is missing.
Required attribute '
Attribute specification type mismatch.
Duplicate type constraint name
Error parsing function body:
Extra unparsed input unexpected.
(inputs_.size() - 1) == i
: failed validating the check: 
ONNX Schema 
(outputs_.size() - 1) == i
!(it.GetName().empty())
Invalid data type 
tensor(
optional(
sparse_tensor(
Unsuported type proto value case.
Invalid tensor data type 
optional
opaque
DataTypeUtils::FromDataTypeString - Received invalid data type string 
complex64
complex128
Input type was null
 expected to have tensor or sparse tensor type. Got: 
 unknown
Element type of input 
 expected to have sequence type
Element type of sequence input 
 expected to have optional type
Element type of optional input 
 expected to have map type
Key type of map input 
Value type of map input 
 expected to have type but instead is null
Mismatch between number of source and target dimensions. Source=
 target=
 source=
Mismatched type:
Mismatched tensor element type:
Mismatched sparse tensor element type:
source sequence type missing element type.
target sequence type missing element type.
source optional type missing element type.
target optional type missing element type.
source map type missing key type.
target map type missing key type.
Mismatched map tensor key type:
source map type missing value type.
target map type missing value type.
Element type of tensor or sparse tensor input was unknown
Input was expected to have tensor or sparse tensor type. Got 
 does not match existing output type of 
Input element type of 
Output was expected to have tensor type. Got 
Input was expected to have sequence type. Got 
Element type of sequence input was unknown
Input was expected to have optional type. Got 
Element type of optional input was unknown
Input was expected to have map type. Got 
Key type of map input was unknown
Value type of map input was unknown
Input was expected to have either tensor, sequence, optional or map type. Got 
Type of reduction to apply to loss: none, sum, mean(default). 'none': no reduction will be applied, 'sum': the output will be summed. 'mean': the sum of the output will be divided by the number of elements in the output.
If necessary the right-hand-side argument will be broadcasted to match the
shape of left-hand-side argument. When broadcasting is specified, the second
tensor can either be of element size 1 (including a scalar tensor and any
tensor with rank equal to or smaller than the first tensor), or having its
shape as a contiguous subset of the first tensor's shape. The starting of the
mutually equal shape is specified by the argument "axis", and if it is not set,
suffix matching is assumed. 1-dim expansion doesn't work yet.
For example, the following tensor shapes are supported (with broadcast=1):
  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
Attribute `broadcast=1` needs to be passed to enable broadcasting.
Pow takes input data (Tensor<T>) and exponent Tensor, and
produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,
is applied to the data tensor elementwise.
This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md).
Constrain input and output types to high-precision numeric tensors.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\math\old.cc
subtraction
division
]. Its actual value is: 
'axis' must be in [
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
The input tensor that's coerced into a 2D matrix of size (NxD) as described above.
The output values with the same shape as input tensor (the original size without coercion).
normalized exponential
softmax
log of softmax
logsoftmax
1 for the first maximum value, and 0 for all others
hardmax
Whether the operator should behave like fmod (default=0 meaning it will do integer mods); Set this to 1 to force fmod treatment
Dividend tensor
Divisor tensor
Remainder tensor
Constrain input and output types to signed numeric tensors.
The exponential of the input tensor computed element-wise
The natural log of the input tensor computed element-wise
The hyperbolic tangent values of the input tensor computed element-wise
First operand, base of the exponent.
Second operand, power of the exponent.
Constrain input X and output types to float/int tensors.
Constrain input Y types to float/int tensors.
Output tensor.
List of tensors for 
data_0
Constrain input and output types to numeric tensors.
Input tensor whose elements to be clipped
Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape).
Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape).
Output tensor with clipped input elements
Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N).
'shape' input must be 1D tensor
A 1-D tensor indicates the shape you want to expand to, following the broadcast rule
Constrain input and output types to all tensors.
The sign of the input tensor computed element-wise. It has the same shape and type of the input.
The error function of the input tensor computed element-wise. It has the same shape and type of the input.
If set to 1 will return exclusive sum in which the top element is not included. In other terms, if set to 1, the j-th output element would be the sum of the first (j-1) elements. Otherwise, it would be the sum of the first j elements.
If set to 1 will perform the sums in reverse direction.
An input tensor that is to be processed.
A 0-D tensor. Must be in the range [-rank(x), rank(x)-1]. Negative value means counting dimensions from the back.
Output tensor of the same type as 'x' with cumulative sums of the x's elements
axis tensor can be int32 or int64 only
const_zero
const_one
target
expanded_target
ignore_index
input_gather_element
loss_NCdd
loss_N1dd
loss_Ndd
weight_gather
loss_unweighted
loss_sum
weight_gather_sum
const_ignore_index
const_zero_target_typed
expanded_target_int64
transform_targets
const_zero_float
const_zero_casted
input_gather_element_transform
squeeze_mask
const_one_float
const_one_casted
weight_gather_temp
weight_gather_temp_1
Target rank must be 1 less than the input rank.
Input and target dimension value mismatch.
Weight rank must be 1.
Input tensor of shape (N, C) or (N, C, d1, d2, ..., dk).
Target tensor of shape (N) or (N, d1, d2, ..., dk). Target element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the target values should either be in the range [0, C) or have the value ignore_index.
Optional rescaling weight tensor. If given, it has to be a tensor of size C. Otherwise, it is treated as if having all ones.
The negative log likelihood loss
Type of reduction to apply to loss: none, sum, mean (default). 'none': the output is the loss for each sample. 'sum': the output will be summed. 'mean': the sum of the output will be divided by the sum of applied weights.
Specifies a target value that is ignored and does not contribute to the input gradient. It's an optional value.
Constrain input, weight, and output types to floating-point tensors.
Constrain target to integer types
NegativeLogLikelihoodLoss
Shape3D
X_NCD
X_NDC
X_LogSM
X_LogSM_NCD
X_shape
X_Log
log_prob
labels
weights
The predicted outputs with shape [batch_size, class_size], or [batch_size, class_size, D1, D2 , ..., Dk], where K is the number of dimensions.
The ground truth output tensor, with shape [batch_size], or [batch_size, D1, D2, ..., Dk], where K is the number of dimensions. Labels element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the label values should either be in the range [0, C) or have the value ignore_index.
A manual rescaling weight given to each class. If given, it has to be a 1D Tensor assigning weight to each of the classes. Otherwise, it is treated as if having all ones.
Weighted loss float Tensor. If reduction is 'none', this has the shape of [batch_size], or [batch_size, D1, D2, ..., Dk] in case of K-dimensional loss. Otherwise, it is a scalar.
Log probability tensor. If the output of softmax is prob, its value is log(prob).
SoftmaxCrossEntropyLoss
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
Pass 1 to enable broadcasting
broadcast
legacy optimization attribute.
consumed_inputs
If set, defines the broadcast dimensions. See doc for details.
First operand, should share the type with the second operand.
Second operand. With broadcasting can be of smaller size than A. If broadcasting is disabled it should be of the same size.
Result, has same dimensions and type as A
Input tensor of any shape, base of the exponent.
Input tensor of any shape broadcastable to X shape, the exponent component.
Output tensor (same size as X)
Coefficient of leakage default to 0.01.
Coefficient of SELU default to 1.6732.
Coefficient of SELU default to 1.0507.
Coefficient of ELU default to 1.0.
1-D input tensor
Slope tensor. If `Slope` is of size 1, the value is sharedacross different channels
slope
Slope tensor. The shape of slope can be smaller then first input X; if so, its shape must be unidirectional broadcastable to X
Value of alpha default to 0.2
Value of beta default to 0.5
List of tensors for Max.
Output tensor. Same dimension as inputs.
List of tensors for Min
List of tensors for Sum.
List of tensors for Mean.
Minimum value, under which element is replaced by min
Maximum value, above which element is replaced by max
Input tensor A
Input tensor B
Input tensor C, can be inplace.
Whether C should be broadcasted
Scalar multiplier for the product of input tensors A * B, the default value is 1.0.
Scalar multiplier for input tensor C, the default value is 1.0.
Input tensor C
Invalid value for attribute axis
Invalid value for attribute k
Tensor of shape [a_1, a_2, ..., a_n, r]
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing top K values from the input tensor
Values
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing the corresponding input tensor indices for the top K values.
Indices
Constrain index tensor to int64
Number of top elements to retrieve
Dimension on which to do the sort.
K input must be a one-dimensional tensor of size 1.
K input must be of type int64.
Axis has less than the requested k elements.
A 1-D tensor containing a single positive value corresponding to the number of top elements to retrieve
First input operand for the logical operator.
Second input operand for the logical operator.
Result tensor.
greater
Constrains input types to all numeric tensors.
Constrains output to boolean tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\logical\old.cc
equal
Enable broadcasting
If set, defines the broadcast dimensions.
Left input tensor for the logical operator.
Right input tensor for the logical operator.
Constrains input to boolean tensor.
Constrains input to float tensors.
Constrains input to integral tensors.
less_equal
        {
            O1 = Less (A, B)
            O2 = Equal (A, B)
            C = Or (O1, O2)
        }
        
greater_equal
        {
            O1 = Greater (A, B)
            O2 = Equal (A, B)
            C = Or (O1, O2)
        }
        
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor. Accepted range is [-r, r-1] where r = rank(data).
Constrain input and output types to high-precision and 8 bit numeric tensors.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\reduction\old.cc
sum square
product
log sum
log sum exponent
L1 norm
L2 norm
'axis' must be in [-rank(indices), rank(indices)-1]
The axis in which to compute the arg indices. Accepted range is [-r, r-1] where r = rank(data).
Whether to select the last index or the first index if the {name} appears in multiple indices, default is False (first index).
Reduced output tensor with integer data type.
The axis in which to compute the arg indices.
Computes the indices of the {name} elements of the input tensor's element along the
provided axis. The resulting tensor has the same rank as the input if keepdims equal 1.
If keepdims equal 0, then the resulting tensor have the reduced dimension pruned.
The type of the output tensor is integer.
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
Carries out batch normalization as described in the paper
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
there are multiple cases for the number of outputs, which we list below:
Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #2: Y (test mode)
For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
Carries out batch normalization as described in the paper
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
There are five required inputs 'X', 'scale', 'B', 'input_mean' and
'input_var'.
Note that 'input_mean' and 'input_var' are expected to be the estimated
statistics in inference mode (training_mode=False, default),
and the running statistics in training mode (training_mode=True).
There are multiple cases for the number of outputs, which we list below:
Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (training_mode=False)
When training_mode=False, extra outputs are invalid.
The outputs are updated as follows when training_mode=True:
running_mean = input_mean * momentum + current_mean * (1 - momentum)
running_var = input_var * momentum + current_var * (1 - momentum)
Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
where:
current_mean = ReduceMean(X, axis=all_except_channel_index)
current_var =  ReduceVar(X, axis=all_except_channel_index)
Notice that ReduceVar refers to the population variance, and it equals to
sum(sqrd(x_i - x_avg)) / N
where N is the population size (this formula does not use sample size N - 1).
When training_mode=False:
Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.
Ratio of Dropout must be a scalar.
training_mode of Dropout must be a scalar.
The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of the scaled input, which is typically the case during training. It is an optional value, if not specified it will default to 0.5.
The output mask.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\nn\old.cc
) for attribute 'axis'
Invalid value(
A tensor of rank >= axis.
A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output.
Constrain input and output to all tensor types.
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value means counting dimensions from the back. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
Flatten
The number of channels to sum over
Scaling parameter.
The exponent.
Output tensor, which has the shape and type as input tensor
Constrain input and output  types to float tensors.
A list of integers, along which to reduce. The default is to caculate along axes [0,2,3] for calculating mean and variance along each channel. Two variables with the same C-coordinate are associated with the same mean and variance.
Exponent
EX_squared
X_squared
E_Xsquared
Variance
X_variance
Processed_STD
Input tensor must have atleast 2 dimensions
Attribute dilations has incorrect size
Attribute strides has incorrect size
Attribute kernel_shape has incorrect size
Attribute kernel_shape must be specified
Attribute pads has incorrect size
Second input tensor has wrong dimension
Stride along each spatial axis.
The output of each pooling window is divided by the number of elements exclude pad.
average
The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).
The output of each pooling window is maximum number of elements exclude pad.
The storage order of the tensor. 0 is row major, and 1 is column major.
Indices tensor from max pooling across the input tensor. The dimensions of indices are the same as output tensor. The values in indices of are the indices of the selected values during pooling. The indices are computed as flatten 1-D tensor, and the indices do not consider padding. So the values in indices are in [0, N x C x D1 x ... x Dn).
Dilation value along each spatial axis of filter.
Dilation value along each spatial axis of filter. If not present, the dilation defaults to 1 along each spatial axis.
MaxUnpool op must have either two or three inputs.
Input tensor X must have atleast 2 dimensions.
Attribute pads has incorrect size.
Attribute strides has incorrect size.
Attribute kernel_shape has incorrect size.
Attribute kernel_shape must be specified.
'output_shape' must be rank 1 tensor.
'output_shape' must have same number of elements as the shape of input tensor X.
Input data tensor that has to be unpooled. This tensor is typically the first output of the MaxPool op.Dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non-image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor containing the indices corresponding to elements in the first input tensor X.This tensor is typically the second output of the MaxPool op.Dimensions must be the same as input tensor X. The indices are linear, i.e. computed considering the tensor as flattened 1-D tensor, assuming row-major storage. Also, the linear indices should not consider padding. So the values in indices are in the range [0, N x C x D1 x ... x Dn).
The shape of the output can be explicitly set which will cause pads values to be auto generated. If 'output_shape' is specified, 'pads' values are ignored.
Output data tensor that contains the result of the unpooling.
MaxUnpool
Stride along each axis.
p value of the Lp norm used to pool over the input data, default is 2.0.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimension are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Output data tensor from Lp pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes.
p value of the Lp norm used to pool over the input data.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices for the shape array). Or in other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL. 
dilation value along each spatial axis of the filter.
a filter
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn)
The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, pad lengths and group count. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads
The zero-padding added to one side of the output. This is also called adjs/adjustment in some frameworks.
ConvTranspose
Output data tensor from pooling across the input tensor. Dimensions will be N x C x 1 x 1
If true, compute the mean and variance across all spatial elements If false, compute the mean and variance across per feature.Default is 1.
If set to nonzero, run spatial batch normalization in test mode, default is 0.
is_test
The epsilon value to use to avoid division by zero, default is 1e-5f.
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum), default is 0.9f.
momentum
The input 4-dimensional tensor of shape NCHW.
The scale as a 1-dimensional tensor of size C to be applied to the output.
The bias as a 1-dimensional tensor of size C to be applied to the output.
The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size C.
The running variance (training) or the estimated variance (testing) as a 1-dimensional tensor of size C.
The output 4-dimensional tensor of the same shape as X.
The running mean after the BatchNormalization operator. Must be in-place with the input mean. Should not be used for testing.
The running variance after the BatchNormalization operator. Must be in-place with the input var. Should not be used for testing.
Saved mean used during training to speed up gradient computation. Should not be used for testing.
saved_mean
Saved variance used during training to speed up gradient computation. Should not be used for testing.
saved_var
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).
Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1
Scale tensor of shape (C).
Bias tensor of shape (C).
running (training) or estimated (testing) mean tensor of shape (C).
running (training) or estimated (testing) variance tensor of shape (C).
The output tensor of the same shape as X
The running mean after the BatchNormalization operator.
The running variance after the BatchNormalization operator.
Saved mean used during training to speed up gradient computation.
Saved variance used during training to speed up gradient computation.
This number of op outputs should be 3 when Training_mode = True, but it is not.
This number of op outputs should be 1 when Training_mode = False, but it is not.
If set to true, it indicates BatchNormalization is being used for training, and outputs 1, 2, 3, and 4 would be populated.
input_mean
input_var
running_mean
The running variance after the BatchNormalization operator. This op uses the population size (N) for calculating variance, and not the sample size N-1.
running_var
Constrain mean and variance types to float tensors. It allows all float type for U.
The input 1-dimensional scale tensor of size C.
The input 1-dimensional bias tensor of size C.
The output 4-dimensional tensor of the same shape as input.
InstanceNormalization
(float, default 0.5) the ratio of random dropout
(int, default 0) if nonzero, run dropout in test mode where the output is simply Y = X.
The output mask. If is_test is nonzero, this output is not filled.
The ratio of random dropout
Constrain output mask types to boolean tensors.
The output tensor of the same shape as X.
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [0, R], where R is the rank of the input tensor. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
If true, compute the mean and variance across per activation. If false, compute the mean and variance across per feature over each mini-batch.
If spatial is true, the dimension of scale is (C). If spatial is false, the dimensions of scale are (C x D1 x ... x Dn)
If spatial is true, the dimension of bias is (C). If spatial is false, the dimensions of bias are (C x D1 x ... x Dn)
If spatial is true, the dimension of the running mean (training) or the estimated mean (testing) is (C). If spatial is false, the dimensions of the running mean (training) or the estimated mean (testing) are (C x D1 x ... x Dn).
If spatial is true, the dimension of the running variance(training) or the estimated variance (testing) is (C). If spatial is false, the dimensions of the running variance(training) or the estimated variance (testing) are (C x D1 x ... x Dn).
Return elements, either from X or Y, depending on condition.
Where behaves like
[numpy.where](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html)
with three parameters.
This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
if coordinate_transformation_mode is "half_pixel", <br/>
x_original = (x_resized + 0.5) / scale - 0.5, <br/>
if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
if coordinate_transformation_mode is "align_corners", <br/>
x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
if coordinate_transformation_mode is "asymmetric", <br/>
x_original = x_resized / scale, <br/>
if coordinate_transformation_mode is "tf_half_pixel_for_nn", <br/>
x_original = (x_resized + 0.5) / scale, <br/>
if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
type: 
 does not match type of output: 
Input: 
 expected to have tensor or sparse tensor type
 and Output 
 not specified
Value of attribute 
 should be of integer type and specify a type.
 does not specify a valid type.
The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto
Input tensor to be cast.
Output tensor with the same shape as input with type specified by the 'to' argument
Constrain input types. Casting from complex is not supported.
Constrain output types. Casting to complex is not supported.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\tensor\old.cc
Target shape may not have multiple -1 dimensions
Invalid position of 0
Invalid dimension value: 
Invalid Target shape product of 0
Dimension could not be inferred: incompatible shapes
Specified shape for output.
Reshaped data.
reshaped
Shape of the input tensor
Input tensor can be of arbitrary type.
Constrain output to int64 tensor.
Total number of elements of the input tensor
Constrain output to int64 tensor, which should be a scalar though.
axis must be in [-rank, rank-1].
 has rank 
All inputs to Concat must have same rank. Input 
Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs)..
List of tensors for concatenation
concat_result
Constrain output types to any tensor type.
 Value=
Invalid value of attribute 'axis'. Rank=
) and outputs (
Mismatch between number of splits (
) and the split dimension of the input (
Mismatch between the sum of 'split' (
The input is not evenly splittable
The tensor to split
One or more outputs forming list of tensors after splitting
outputs
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1] where r = rank(input).
length of each output. Values should be >= 0.
Only supports `int32_t` or `int64_t` inputs for starts/ends/axes/steps
Slice op must have either three, four or five inputs.
Incorrect or missing input value for starts and ends
Input axes has incorrect length
Input steps has incorrect length
Input axes has invalid data
'step' cannot be 0
1-D tensor of ending indices (exclusive) of corresponding axis in `axes`
1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1.
steps
Invalid attribute perm {
}, input shape = {
Attribute perm for Transpose has repeated value: 
A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given.
Transposed output.
transposed
Tensor of rank q + r - indices_shape[-1] - 1.
updates
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Tensor of int32/int64 indices, of r >= 1 (same rank as input). All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of rank r >=1 (same rank and shape as indices)
Tensor of rank r >= 1 (same rank as input).
Input and output types can be of any tensor type.
ScatterElements
data tensor must have rank >= 1
axis must be in [-r, r-1]
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of rank q + (r - 1).
Tensor of int32/int64 indices, with the same rank r as the input. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of the same shape as indices.
List of integers indicating the dimensions to squeeze. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Tensors with at least max(dims) dimensions.
Reshaped tensor with same data as input.
squeezed
'axes' attribute must not contain any duplicates
values in 'axes' are beyond the bounds of the computed output shape
List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded).
Original tensor
expanded
blocksize
Blocksize must be positive
Input tensor must be 4-dimensional
Blocks of [blocksize, blocksize] are moved.
Input tensor of [N,C,H,W], where N is the batch axis, C is the channel or depth, H is the height and W is the width.
Output tensor of [N, C * blocksize * blocksize, H/blocksize, W/blocksize].
SpaceToDepth
DCR (default) for depth-column-row order re-arrangement. Use CRD for column-row-depth order.
Output tensor of [N, C/(blocksize * blocksize), H * blocksize, W * blocksize].
DepthToSpace
'Repeats' input must be 1D tensor of type int64
'Repeats' input has incorrect number of values. The number of values in 'repeats' must be equal to the number of input dimensions.
Input tensor of any shape.
1D int64 tensor of the same length as input's dimension number, includes numbers of repeated copies along input's dimensions.
repeats
Output tensor of the same dimension and type as tensor input. output_dim[i] = input_dim[i] * repeats[i]
Constrain repeat's type to int64 tensors.
Three interpolation modes: nearest (default), linear and cubic. The "linear" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The "cubic" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor).
The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if "mode" is "cubic".
cubic_coeff_a
If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0.
exclude_outside
round_prefer_floor
Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get "nearest" pixel in input tensor from x_original, so this attribute is valid only if "mode" is "nearest".
When coordinate_transformation_mode is "tf_crop_and_resize" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f.
N-D tensor
1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is "tf_crop_and_resize"
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor.
The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor.
sizes
N-D tensor after resizing
Constrain input 'X' and output 'Y' to all tensor types.
Constrain roi type to float or double.
Tensor to copy input into.
Constrain input types to float tensors.
Constrain output types to boolean tensors.
Constrain to all tensor types.
batch_dims
Both `data` and `indices` input tensors in GatherND op need to have rank larger than 0.
Last dimension of `indices` input tensor in GatherND op must not be larger than the rank of `data` tensor
The number of batch dimensions. The gather of indexing starts from dimension of data[batch_dims:]
Tensor of rank q >= 1. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
'pads' input must be a 1D (shape: [2 * input_rank]) tensor of type int64
Supported modes: `constant`(default), `reflect`, `edge`
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank]. `pads` format should be: [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pad values added at the beginning of axis `i` and xi_end, the number of pad values added at the end of axis `i`.
(Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0).
constant_value
Constrains input and output to only numeric types.
Constrain input types. Casting from strings and complex are not supported.
Constrain output types. Casting to strings and complex are not supported.
Which axis to concat on.  Default value is 1.
rank must be greater than axis
Optional list of output lengths (see also arg 'split')
outputs...
Which axis to split on
length of each output
List of integers indicate the padding element count at the beginning and end of each axis, for 2D it is the number of pixel. `paddings` rank should be double of the input's rank. `paddings` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
paddings
Three modes: constant(default), reflect, edge
One float, indicates the value to be filled, default is 0
New shape
Number of repeated copies to make of the input tensor.
tiles
Axis along which to repeat.
Output tensor of same shape and type as input.
Constrain tiles and axis's type to int64 tensors.
The scale along width dimension. It takes value greater than or equal to 1.
width_scale
The scale along height dimension. It takes value greater than or equal to 1.
height_scale
Two interpolation modes: nearest(default), bilinear
4-D tensor, [N,C,H,W]
4-D tensor after resizing, [N,C,H,W]
Constrain output types to bool, int32, int64, float16, float, double tensors.
) is not equal to the existing rank value (
Ranks inferred (
Number of elements of attribute 'scales' must be same as rank of input 'X'
Attribute 'scales' must have floats type.
Attribute 'scales' is required.
The scale array along each dimension. It takes value greater than or equal to 1. The number of elements of 'scales' should be the same as the rank of input 'X'.
Two interpolation modes: nearest (default), and linear (including bilinear, trilinear, etc)
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'.
Incorrect or missing attribute value for starts and ends
Attribute axes has incorrect length
Axes that `starts` and `ends` apply to. It's optional. If not present, will be treated as [0, 1, ..., len(`starts`) - 1].
Starting indices of corresponding axis in `axes`
Ending indices (exclusive) of corresponding axis in axes`
1-D tensor of slice step of corresponding axis in `axes`. Default to 1. 
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Tensor of int32/int64 indices, of r >= 1 (same rank as input).
Scatter
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds. It is an error if any of the index values are out of bounds.
List of non-negative integers, indicate the dimensions to squeeze.
List of non-negative integers, indicate the dimensions to be inserted
OneHot node must have three inputs.
Input 'depth' must be a scalar or rank 1 tensor.
Input 'depth' must have exactly one element.
Input 'values' must be rank 1 tensor.
Input 'values' must have exactly two elements.
Indices tensor must have rank >= 1
'axis' must be in [-rank(indices)-1, rank(indices)]
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor.
Input tensor containing indices. The values must be non-negative integers. Any entries in the 'indices' input tensor with values outside the range [0, depth) will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [0, depth). In case 'depth' is of non-integer type, it will be casted to int64 before use.
depth
Rank 1 tensor containing exactly two elements, in the format [off_value, on_value], where 'on_value' is the value used for filling locations specified in 'indices' input tensor, and 'off_value' is the value used for filling locations other than those specified in 'indices' input tensor. 
Tensor of rank one greater than input tensor 'indices', i.e. rank(output) = rank(indices) + 1. The data type for the elements of the output tensor is the same as the type of input 'values' is used.
Constrain to any tensor type.
OneHot
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected.
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length alone the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
condition
Tensor of rank r if axis is specified. Otherwise output is a Tensor of rank 1.
Constrains to boolean tensors.
Compress
Which axis to split on. 
Attribute value for pads is required
Attribute pads has incorrect length
List of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D it is the number of pixels. `pads` rank should be double of the input's rank. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
One float, indicates the value to be filled.
Constrain input and output types to all tensor and sequence types.
When True (nonzero), yield X, otherwise yield Y
values selected at indices where condition is True
values selected at indices where condition is False
Tensor of shape equal to the broadcasted shape of condition, X, and Y.
Constrain to boolean tensors.
sparse_value
value_int
value_ints
value_float
value_floats
value_string
value_strings
One and only one of the attributes 'value', 'value_*' or 'sparse_value' must be specified for a Constant node.
Attribute 'value_int' expect an integer.
Attribute 'value_ints' expect a list of integers.
Attribute 'value_float' expect a float.
Attribute 'value_floats' expect a list of floats.
Attribute 'value_string' expect a string.
Attribute 'value_strings' expect a list of strings.
TypeAndShapeInferenceFunction implementation incomplete: this line should never be reached.
The value for the elements of the output tensor.
The value for the elements of the output tensor in sparse format.
The value for the sole element for the scalar, int64, output tensor.
The values for the elements for the 1D, int64, output tensor.
The value for the sole element for the scalar, float32, output tensor.
The values for the elements for the 1D, float32, output tensor.
The value for the sole element for the scalar, UTF-8 string, output tensor.
The values for the elements for the 1D, UTF-8 string, output tensor.
Output tensor containing the same value of the provided tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\generator\old.cc
Attribute 'value' of Constant node must exist with 'Tensor' data.
Only one of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
One of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
Computes an one-layer simple RNN. This operator is usually supported
via some custom implementation such as CuDNN.
Notations:
`X` - input tensor
`i` - input gate
`t` - time step (t-1 means previous time step)
`Wi` - W parameter weight matrix for input gate
`Ri` - R recurrence weight matrix for input gate
`Wbi` - W parameter bias vector for input gate
`Rbi` - R parameter bias vector for input gate
`WBi` - W parameter weight matrix for backward input gate
`RBi` - R recurrence weight matrix for backward input gate
`WBbi` - WR bias vectors for backward input gate
`RBbi` - RR bias vectors for backward input gate
`H` - Hidden state
`num_directions` - 2 if direction == bidirectional else 1
Activation functions:
  Relu(x)                - max(0, x)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  Sigmoid(x)             - 1/(1 + e^{-x})
  (NOTE: Below are optional)
  Affine(x)              - alpha*x + beta
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  ThresholdedRelu(x)     - x if x >= alpha else 0
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  Softsign(x)            - x/(1 + |x|)
  Softplus(x)            - log(1 + e^x)
Equations (Default: f=Tanh):
  - Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)
Computes an one-layer GRU. This operator is usually supported via some custom
implementation such as CuDNN.
Notations:
`X` - input tensor
`z` - update gate
`r` - reset gate
`h` - hidden gate
`t` - time step (t-1 means previous time step)
`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates
`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates
`Wb[zrh]` - W bias vectors for update, reset, and hidden gates
`Rb[zrh]` - R bias vectors for update, reset, and hidden gates
`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates
`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates
`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates
`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates
`H` - Hidden state
`num_directions` - 2 if direction == bidirectional else 1
Activation functions:
  Relu(x)                - max(0, x)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  Sigmoid(x)             - 1/(1 + e^{-x})
  (NOTE: Below are optional)
  Affine(x)              - alpha*x + beta
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  ThresholdedRelu(x)     - x if x >= alpha else 0
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  Softsign(x)            - x/(1 + |x|)
  Softplus(x)            - log(1 + e^x)
Equations (Default: f=Sigmoid, g=Tanh):
  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)
  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)
  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0
  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0
  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
Computes an one-layer LSTM. This operator is usually supported via some
custom implementation such as CuDNN.
Notations:
`X` - input tensor
`i` - input gate
`o` - output gate
`f` - forget gate
`c` - cell gate
`t` - time step (t-1 means previous time step)
`W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates
`R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates
`Wb[iofc]` - W bias vectors for input, output, forget, and cell gates
`Rb[iofc]` - R bias vectors for input, output, forget, and cell gates
`P[iof]`  - P peephole weight vector for input, output, and forget gates
`WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates
`RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates
`WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates
`RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates
`PB[iof]`  - P peephole weight vector for backward input, output, and forget gates
`H` - Hidden state
`num_directions` - 2 if direction == bidirectional else 1
Activation functions:
  Relu(x)                - max(0, x)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  Sigmoid(x)             - 1/(1 + e^{-x})
  (NOTE: Below are optional)
  Affine(x)              - alpha*x + beta
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  ThresholdedRelu(x)     - x if x >= alpha else 0
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  Softsign(x)            - x/(1 + |x|)
  Softplus(x)            - log(1 + e^x)
Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):
  - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)
  - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)
  - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)
  - Ct = ft (.) Ct-1 + it (.) ct
  - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)
  - Ht = ot (.) h(Ct)
foward
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM.
The sequence output for the hidden is optional if 0. Default 0.
output_sequence
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. It is optional if `output_sequence` is 0.
A list of 2 (or 4 if bidirectional) activation functions for update, reset, and hidden gates. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
The weight tensor for the gates. Concatenation of `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, input_size]`.
The recurrence weight tensor. Concatenation of `R[zrh]` and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, hidden_size]`.
The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 6*hidden_size]`. Optional: If not specified - assumed to be 0
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\rnn\old.cc
One (or two if bidirectional) activation function for input gate. The activation function must be one of the activation functions specified above. Optional: Default `Tanh` if not specified.
The weight tensor for input gate. Concatenation of `Wi` and `WBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, input_size]`.
The recurrence weight tensor. Concatenation of `Ri` and `RBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, hidden_size]`.
The bias tensor for input gate. Concatenation of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has shape `[num_directions, 2*hidden_size]`. Optional: If not specified - assumed to be 0.
When computing the output of the hidden gate, apply the linear transformation before multiplying by the output of the reset gate.
First input tensor must have rank 3
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = input_shape[i] * strides[i]` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
Carries out batch normalization as described in the paper
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
There are five required inputs 'X', 'scale', 'B', 'input_mean' and
'input_var'.
Note that 'input_mean' and 'input_var' are expected to be the estimated
statistics in inference mode (training_mode=False, default),
and the running statistics in training mode (training_mode=True).
There are multiple cases for the number of outputs, which we list below:
Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (training_mode=False)
When training_mode=False, extra outputs are invalid.
The outputs are updated as follows when training_mode=True:
running_mean = input_mean * momentum + current_mean * (1 - momentum)
running_var = input_var * momentum + current_var * (1 - momentum)
Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
where:
current_mean = ReduceMean(X, axis=all_except_channel_index)
current_var =  ReduceVar(X, axis=all_except_channel_index)
Notice that ReduceVar refers to the population variance, and it equals to
sum(sqrd(x_i - x_avg)) / N
where N is the population size (this formula does not use sample size N - 1).
The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.
When training_mode=False:
Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
For previous (depreciated) non-spatial cases, implementors are suggested
to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
Constrain input and output types to float and 8 bit tensors.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\nn\defs.cc
The output of each pooling window is maximum number of elements exclude pad. 
RoIs tensor must have 2 dimensions
pooled_shape
Attribute pooled_shape has incorrect length
Attribute pooled_shape must be specified
ROI pool output shape (height, width).
Multiplicative spatial scale factor to translate ROI coordinates from their input scale to the scale used when pooling.
spatial_scale
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
RoIs (Regions of Interest) to pool over. Should be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2, y2], ...].
RoI pooled output 4-D tensor of shape (num_rois, channels, pooled_shape[0], pooled_shape[1]).
MaxRoiPool
Scale tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Zero point tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Scale tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
Optional 1D bias to be added to the convolution, has size of M. Bias must be quantized using scale = x_scale * w_scale and zero_point = 0
Constrain filter type to 8-bit integer tensor.
Constrain output type to 8-bit integer tensor.
Constrain bias type to 32-bit integer tensor.
The shape of the convolution kernel. If not present, should be inferred from input 'w'.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0.The value represent the number of pixels added to the beginning and end part of the corresponding axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaultsto 0 along start and end of each spatial axis.
number of groups input channels and output channels are divided into. default is 1.
Zero point tensor for input 'x'. It's optional and default value is 0. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for input 'w'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M)
Constrain input x and its zero point data type to 8-bit integer tensor.
Constrain input w and its zero point data type to 8-bit integer tensor.
Constrain output y data type to 32-bit integer tensor.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each axis.
The pads attribute cannot be used simultaneously with auto_pad attribute
Additional elements added to the side with higher coordinate indices in the output. Each padding value in "output_padding" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If "output_shape" is explicitly provided, "output_padding" does not contribute additional size to "output_shape" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks.
Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1.
lp pool
Constrain scale and bias types to float tensors.
Constrain mean and variance types to float tensors.
The output tensor of the same shape as input.
Input matrix
Matrix after normalization
The axis on which to apply normalization, -1 mean last axis.
The order of the normalization, only 1 or 2 are supported.
LpNormalization
The lambd value for the Shrink formulation. Default is 0.5.
lambd
The bias value added to output. Default is 0.
ngram_indexes
ngram_indexes must be non-empty with no negative values
Input tensor must have rank 1 or 2
Input for n-gram extraction
Ngram results
Input is ether string UTF-8 or int32/int64
1-D tensor of floats
Maximum n-gram length. If this value is 3, 3-grams will be used to generate the output.
max_gram_length
Minimum n-gram length. If this value is 2 and max_gram_length is 3, output may contain counts of 2-grams and 3-grams.
min_gram_length
Maximum number of items (integers/strings) to be skipped when constructing an n-gram from X. If max_skip_count=1, min_gram_length=2, max_gram_length=3, this operator may generate 2-grams with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and skip_count=1
max_skip_count
List of strings n-grams learned from the training set. Either this or pool_int64s attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
pool_strings
List of int64 n-grams learned from the training set. Either this or pool_strings attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
pool_int64s
The starting indexes of 1-grams, 2-grams, and so on in pool. It is useful when determining the boundary between two consecutive collections of n-grams. For example, if ngram_counts is [0, 17, 36], the first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36. This format is essentially identical to CSR (or CSC) sparse matrix format, and we choose to use this due to its popularity.
ngram_counts
list of int64s (type: AttributeProto::INTS). This list is parallel to the specified 'pool_*' attribute. The i-th element in ngram_indexes indicate the coordinate of the i-th n-gram in the output tensor.
list of floats. This attribute stores the weight of each n-gram in pool. The i-th element in weights is the weight of the i-th n-gram in pool. Its length equals to the size of ngram_indexes. By default, weights is an all-one tensor.This attribute is used when mode is "IDF" or "TFIDF" to scale the associated word counts.
The weighting criteria. It can be one of "TF" (term frequency), "IDF" (inverse document frequency), and "TFIDF" (the combination of TF and IDF)
TfIdfVectorizer
Input shape must have either [C] or [1,C] dimensions where C > 0
UTF-8 strings to normalize
UTF-8 Normalized strings
string enum that cases output to be lowercased/uppercases/unchanged. Valid values are "LOWER", "UPPER", "NONE". Default is "NONE"
case_change_action
Boolean. Whether the identification of stop words in X is case-sensitive. Default is false
is_case_sensitive
List of stop words. If not set, no word would be removed from X.
stopwords
Environment dependent string that denotes the locale according to which output strings needs to be upper/lowercased.Default en_US or platform specific equivalent as decided by the implementation.
locale
StringNormalizer
        {
          Exponent = Constant <value = float {2.0}>()
          Epsilon = Constant <value = float {1e-9}>()
          X_RM = ReduceMean <axes : ints = @axes> (X)
          EX_squared = Pow (X_RM, Exponent)
          X_squared = Pow (X, Exponent)
          E_Xsquared = ReduceMean <axes : ints = @axes> (X_squared)
          Variance = Sub (E_Xsquared, EX_squared)
          STD = Sqrt (Variance)
          X_variance = Sub (X, X_RM)
          Processed_STD = Add (STD, Epsilon)
          Y = Div (X_variance, Processed_STD)
        }
        
 was not a tensor.
Scan input 
 outputs. Expected 
Graph attribute inferencing returned type information for 
 was not
Scan 'body' subgraph outputs should all be tensors but output 
 is invalid for a tensor of rank 
 axis value 
) is not equal to number of scan inputs (
Number of scan input axes specified (
) is not equal to number of scan outputs (
Number of scan output axes specified (
Optional tensor specifying lengths of the sequences in a batch. If this input is not specified, all sequences are assumed to be of the maximum sequence length (the dimension of the sequence axis of the scan_input tensors).
Initial values of the loop's N state variables followed by M scan_inputs
initial_state_and_scan_inputs
Final values of the loop's N state variables followed by K scan_outputs
final_state_and_scan_outputs
The graph run each iteration. It has N+M inputs: (loop state variables..., scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...). Each scan_output is created by concatenating the value of the specified scan_output_elt value at the end of each iteration of the loop. It is an error if the dimensions of these values change across loop iterations.
An attribute specifying the number of scan_inputs M. 
An optional list of M flags. The i-th element of the list specifies the direction to be scanned for the i-th scan_input tensor: 0 indicates forward direction and 1 indicates reverse direction. If omitted, all scan_input tensors will be scanned in the forward direction.
directions
Int64 tensor
All Tensor types
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\controlflow\old.cc
 was 
Loop 'body' subgraph outputs should all be tensors but output 
A maximum trip-count for the loop specified at runtime. Optional. Pass empty string to skip.
A boolean termination condition. Optional. Pass empty string to skip.
The initial values of any loop-carried dependencies (values that change across loop iterations)
v_initial
Final N loop carried dependency values then K scan_outputs
v_final_and_scan_outputs
The graph run each iteration. It has 2+N inputs: (iteration_num, condition, loop carried dependencies...). It has 1+N+K outputs: (condition, loop carried dependencies..., scan_outputs...). Each scan_output is created by concatenating the value of the specified output value at the end of each iteration of the loop. It is an error if the dimensions or data type of these scan_outputs change across loop iterations.
tensor of int64, which should be a scalar.
tensor of bool, which should be a scalar.
An optional list of K flags, one for each scan_output. The i-th element of the list specifies whether the i-th scan_output should be constructed by appending or prepending a new value in each iteration: 0 indicates appending and 1 indicates prepending. If omitted, all scan_output tensors will be produced by appending a value in each iteration.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
then_branch and else_branch produce different number of outputs. 
 but subgraphs produce 
If node has 
 else=
 then=
Mismatched type for output 
Mismatched tensor element type for output 
Condition for the if
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same shape and same data type.
Graph to run if condition is true. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the else_branch.
Graph to run if condition is false. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the then_branch.
Only bool
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same data type. The `then_branch` and `else_branch` may produce tensors with the same element type and different shapes. If corresponding outputs from the then-branch and the else-branch have static shapes S1 and S2, then the shape of the corresponding output variable of the if-node (if present) must be compatible with both S1 and S2 as it represents the union of both possible shapes.For example, if in a model file, the the first output of `then_branch` is typed float tensor with shape [2] and the first output of `else_branch` is another float tensor with shape [3], If's first output should have (a) no shape set, or (b) a shape of rank 1 with neither `dim_value` nor `dim_param` set, or (c) a shape of rank 1 with a unique `dim_param`. In contrast, the first output cannot have the shape [2] since [2] and [3] are not compatible.
All Tensor and Sequence types
Loop 'body' subgraph outputs should all be tensors or sequences but output 
Loop 'body' subgraph scan outputs should all be tensors but output 
Final N loop carried dependency values then K scan_outputs. Scan outputs must be Tensors.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1].
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\logical\defs.cc
Constrains input/output to boolean tensors.
First operand, input to be shifted.
Second operand, amounts of shift.
Constrain input and output types to integer tensors.
Direction of moving bits. It can be either "RIGHT" (for right shift) or "LEFT" (for left shift).
 or UNDEFINED. Got: 
 expected to have: 
Attribute expected to have a one-dim tensor
Attribute expected to have a one-dim sparse tensor
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\generator\defs.cc
Shape input must be a one-dimensional tensor.
Invalid shape value: 
(Optional) The value of the output elements.Should be a one-element tensor. If not specified, it defaults to a tensor of value 0 and datatype float32
1D tensor. The shape of the expected output tensor. If empty tensor is given, the output would be a scalar. All values must be >= 0.
Output tensor of shape specified by 'input'.If attribute 'value' is specified, the value and datatype of the output tensor is taken from 'value'.If attribute 'value' is not specified, the value in the output defaults to 0, and the datatype defaults to float32.
Constrain input types.
Constrain output types to be numerics.
Input tensor must be 2-dimensional
(Optional) Index of the diagonal to be populated with ones. Default is 0. If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a lower diagonal.
(Optional) The data type for the elements of the output tensor. If not specified,the data type of the input tensor T1 is used. If input tensor T1 is also notspecified, then type defaults to 'float'.
2D input tensor to copy shape, and optionally, type information from.
Output tensor, same shape as input tensor T1.
Constrain input types. Strings and complex are not supported.
Constrain output types. Strings and complex are not supported.
EyeLike
Lower boundary of the output values.
Upper boundary of the output values.
The data type for the elements of the output tensor. If not specified, default is TensorProto::FLOAT.
The shape of the output tensor.
Output tensor of random values drawn from uniform distribution
The mean of the normal distribution.
The standard deviation of the normal distribution.
The data type for the elements of the output tensor. Default is TensorProto::FLOAT.
Output tensor of random values drawn from normal distribution
(Optional) The data type for the elements of the output tensor, if not specified, we will use the data type of the input tensor.
Input tensor to copy shape and optionally type information from.
Output type must be int32 or int64
Input tensor must have rank 2
sample_size
Number of times to sample.
(Optional) The data type for the elements of the output tensor, if not specified, we will use int32.
Input tensor with shape [batch_size, class_size], where class_size is the number of all possible outcomes. Each value along the axis zero represents the unnormalized log-probability of each corresponding outcome in a batch.
Output tensor with shape [batch_size, sample_size], where sample_size is the number of times to sample. Each value along the axis zero represents the outcome of the corresponding sample in a batch.
Constrain output types to integral tensors.
All inputs to 'Range' op must be of the same type
Scalar. First entry for the range of output values.
Scalar. Exclusive upper limit for the range of output values.
Scalar. Value to step by.
A 1-D tensor with same type as the inputs containing generated range of values.
Constrain input types to common numeric type tensors.
          {
            sub_result = Sub (limit, start)
            sub_result_casted = Cast <to = 1> (sub_result)
            delta_casted = Cast <to = 1> (delta)
            div_result = Div (sub_result_casted, delta_casted)
            ceil_result = Ceil (div_result)
            ceil_result_relu = Relu (ceil_result)
            ceil_result_relu_int = Cast <to = 7> (ceil_result_relu)
            ceil_result_relu_bool = Cast <to = 9> (ceil_result_relu)
            variadic_output, output = Loop (ceil_result_relu_int, ceil_result_relu_bool, start)
              <body = loop_body_attribute (int64 i, bool cond, prev) => (cond_out, current, range) {
                cond_out = Identity (cond)
                current = Add (prev, delta)
                range = Identity (prev)
              }>
          }
        
X_random = RandomUniformLike <low = 0.0, high = 1.0, seed = @seed> (input)
X_greater = Greater (X_random, input)
output = Cast (X_greater)
The data type for the elements of the output tensor. if not specified, we will use the data type of the input tensor.
All values in input have to be in the range:[0, 1].
The returned output tensor only has values 0 or 1, same shape as input tensor.
Constrain output types to all numeric tensors and bool tensors.
Bernoulli
Input to 'Range' op should be scalars (Tensor with only one element and shape empty)
Wrong op_type name for running propagation: 
) vs (
 broadcasting: (
Invalid rank for 
The input tensor of rank >= axis.
The output values with the same shape as the input tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\math\defs.cc
Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32 approximation of 1.6732632423543772848170429916717).
Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32 approximation of 1.0507009873554804934193349852946).
Coefficient of ELU.
            X_alpha = Div (X, alpha)
            Elu_Result = Elu <alpha = 1.0>(X_alpha)
            Y = Mul (alpha, Elu_Result)
        
The Alpha value in Celu formula which control the shape of the unit. The default value is 1.0.
Value of alpha.
Value of beta.
          {
            HS_X = HardSigmoid<alpha = 0.16666667163372, beta = 0.5>(X) 
            Y = Mul (X, HS_X)
          }
        
X_ReduceMax = ReduceMax <keepdims = 1> (input)
                    X_Sub = Sub (input, X_ReduceMax)
                    X_Exp = Exp (X_Sub)
                    X_ReduceSum = ReduceSum <keepdims = 1> (X_Exp, axes)
                    output = Div (X_Exp, X_ReduceSum)
                
Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1) 
                    X_Sub = Sub (input, X_ReduceMax)
                    X_Exp = Exp (X_Sub)
                    X_ReduceSum = ReduceSum <keepdims = 1> (X_Exp, axes)
                    X_Log = Log (X_ReduceSum)
                    output = Sub (X_Sub, X_Log)
                
LogSoftmax(input, axis) = Log(Softmax(input, axis=axis))
Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise
The softsign (x/(1+|x|)) values of the input tensor computed element-wise
Dimension on which to do the sort. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Whether to return the top-K largest or smallest elements.
Whether to return the elements in sorted order.
The sine of the input tensor computed element-wise
The cosine of the input tensor computed element-wise
The tangent of the input tensor computed element-wise
The arcsine of the input tensor computed element-wise
The arccosine of the input tensor computed element-wise
The arctangent of the input tensor computed element-wise
The hyperbolic sine values of the input tensor computed element-wise
The hyperbolic cosine values of the input tensor computed element-wise
The hyperbolic arcsine values of the input tensor computed element-wise
The hyperbolic arccosine values of the input tensor computed element-wise
The hyperbolic arctangent values of the input tensor computed element-wise
input and zero_point pair is expected to have same type.
N-dimensional quantized matrix a
scale of quantized input a
zero point of quantized input a
N-dimensional quantized matrix b
scale of quantized input b
zero point of quantized input b
scale of quantized output y
zero point of quantized output y
Quantized matrix multiply results from a * b
Constrain input a and its zero point data type to 8-bit integer tensor.
Constrain input b and its zero point data type to 8-bit integer tensor.
Constrain output y and its zero point data type to 8-bit integer tensor.
QLinearMatMul
Zero point tensor for input 'A'. It's optional and default value is 0. It could be a scalar or N-D tensor. Scalar refers to per tensor quantization whereas N-D refers to per row quantization. If the input is 2D of shape [M, K] then zero point tensor may be an M element vector [zp_1, zp_2, ..., zp_M]. If the input is N-D tensor with shape [D1, D2, M, K] then zero point tensor may have shape [D1, D2, M, 1]. 
Zero point tensor for input 'B'. It's optional and default value is 0. It could be a scalar or a N-D tensor, Scalar refers to per tensor quantization whereas N-D refers to per col quantization. If the input is 2D of shape [K, N] then zero point tensor may be an N element vector [zp_1, zp_2, ..., zp_N]. If the input is N-D tensor with shape [D1, D2, K, N] then zero point tensor may have shape [D1, D2, 1, N]. 
Constrain output Y data type as 32-bit integer tensor.
Constrain input and output types to floating-point tensors.
expanded_target = Unsqueeze (target, axes)
      input_gather_element = GatherElements <axis = 1> (input, expanded_target)
      loss_NCdd = Neg (input_gather_element)
      loss_N1dd = Slice (loss_NCdd, const_zero, const_one, const_one)
loss = Squeeze (loss_N1dd, axes)
loss_Ndd = Squeeze (loss_N1dd, axes)
loss = ReduceMean <keepdims = 0> (loss_Ndd)
loss = ReduceSum <keepdims = 0> (loss_Ndd)
weight_gather = Gather (weight, target)
loss_unweighted = Squeeze (loss_N1dd, axes)
loss = Mul (loss_unweighted, weight_gather)
loss_Ndd = Mul (loss_unweighted, weight_gather)
            loss_sum = ReduceSum <keepdims = 0> (loss_Ndd)
            weight_gather_sum = ReduceSum <keepdims = 0> (weight_gather)
            loss = Div (loss_sum, weight_gather_sum)
          
      const_zero_target_typed = Sub (expanded_target, expanded_target)
      expanded_target_int64 = Cast <to = 7> (expanded_target)
      mask = Equal (expanded_target_int64, const_ignore_index)
      transform_targets = Where (mask, const_zero_target_typed, expanded_target)
input_gather_element = GatherElements <axis = 1> (input, transform_targets)
const_zero_casted = Cast (const_zero_float)
input_gather_element_transform = Where (mask, const_zero_casted, input_gather_element)
input_gather_element_transform = Where (mask, const_zero_float, input_gather_element)
loss_NCdd = Neg (input_gather_element_transform)
loss_N1dd = Slice (loss_NCdd, const_zero, const_one, const_one)
squeeze_mask = Squeeze (mask, axes)
const_one_casted = Cast (const_one_float)
weight_gather = Where (squeeze_mask, const_zero_casted, const_one_casted)
weight_gather = Where (squeeze_mask, const_zero_float, const_one_float)
weight_gather_temp = Gather (weight, transform_targets)
weight_gather_temp_1 = Where (mask, const_zero_float, weight_gather_temp)
weight_gather_temp_1 = Where (mask, const_zero_casted, weight_gather_temp)
weight_gather = Squeeze (weight_gather_temp_1, axes)
            loss_sum = ReduceSum <keepdims = 0> (loss_Ndd)
            weight_gather_sum = ReduceSum <keepdims = 0> (weight_gather)
            loss = Div (loss_sum, weight_gather_sum)
        
Number of input tensors does not match the operands in the equation.
Ellipsis represents incompatible dimensions.
 does not match the equation indices.
Rank of input 
equation
Einsum expression string.
Operands
Inputs
Constrain input and output types to all numerical tensor types.
Einsum
        X_NCD = Reshape (scores, Shape3D)
        X_NDC = Transpose <perm = [0, 2, 1]> (X_NCD)
        X_LogSM = LogSoftmax <axis = 2> (X_NDC)
        X_LogSM_NCD = Transpose <perm = [0, 2, 1]> (X_LogSM)
        X_shape = Shape (scores)
        X_Log = Reshape (X_LogSM_NCD, X_shape)
      
log_prob = Identity (X_Log)
output = NegativeLogLikelihoodLoss <reduction : string = @reduction, ignore_index : int = @ignore_index> (X_Log, labels, weights)
output = NegativeLogLikelihoodLoss <reduction : string = @reduction, ignore_index : int = @ignore_index> (X_Log, labels)
This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
if coordinate_transformation_mode is "half_pixel", <br/>
x_original = (x_resized + 0.5) / scale - 0.5, <br/>
if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
if coordinate_transformation_mode is "align_corners", <br/>
x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
if coordinate_transformation_mode is "asymmetric", <br/>
x_original = x_resized / scale, <br/>
if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
**History**
- Version 16 adds bfloat16 to the types allowed (for the second and third parameter).
optional(seq(tensor(uint8)))
optional(seq(tensor(uint16)))
optional(seq(tensor(uint32)))
optional(seq(tensor(uint64)))
optional(seq(tensor(int8)))
optional(seq(tensor(int16)))
optional(seq(tensor(int32)))
optional(seq(tensor(int64)))
optional(seq(tensor(float16)))
optional(seq(tensor(float)))
optional(seq(tensor(double)))
optional(seq(tensor(string)))
optional(seq(tensor(bool)))
optional(seq(tensor(complex64)))
optional(seq(tensor(complex128)))
optional(tensor(uint8))
optional(tensor(uint16))
optional(tensor(uint32))
optional(tensor(uint64))
optional(tensor(int8))
optional(tensor(int16))
optional(tensor(int32))
optional(tensor(int64))
optional(tensor(float16))
optional(tensor(float))
optional(tensor(double))
optional(tensor(string))
optional(tensor(bool))
optional(tensor(complex64))
optional(tensor(complex128))
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\tensor\defs.cc
output = Cast (input)
The (first) input tensor will be cast to produce a tensor of the same type as this (second input) tensor.
target_type
Output tensor produced by casting the first input tensor to have the same type as the second input tensor.
Target shape may not have multiple -1 dimensions.
Invalid position of 0.
Invalid Target shape product of 0. Product cannot be 0 in combination with -1
(Optional) By default, when any value in the 'shape' input is equal to zero the corresponding dimension value is copied from the input tensor dynamically. allowzero=1 indicates that if any value in the 'shape' input is set to zero, the zero value is honored, similar to NumPy.
(Optional) Starting axis for slicing the shape. Default value is 0.Negative value means counting dimensions from the back.
(Optional) Ending axis for slicing the shape. Negative value means counting dimensions from the back. If omitted, sizes of all axes upto (including) the last one will be included.
Optional length of each output. Values should be >= 0.Sum of the values must be equal to the dim value at 'axis' specified.
'step' cannot be 0 for Slice
Input rank for starts and ends should be the same: (
Type of reduction to apply: none (default), add, mul. 'none': no reduction applied. 'add':  reduction using the addition operation. 'mul': reduction using the multiplication operation.
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list.
The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. Only one of 'scales' and 'sizes' can be specified.
Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations. If index 0 represents the margin pixel, the reflected value at index -1 will be the same as the value at index 1. For location far away from the border, it will keep being reflected until becoming in bound. If pixel location x = -3.5 reflects by border -1 and becomes x' = 1.5, then reflects by border 1 and becomes x'' = 0.5.
Constrain input and output types to all tensor, sequence, and optional types.
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length along the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor. Negative value means counting dimensions from the back. Accepted range is [-r-1, r] where r = rank(indices).
Input tensor containing indices. Any entries in the 'indices' input tensor with values outside the range [-depth, depth-1] will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [-depth, depth-1]. In case 'depth' is of non-integer type, it will be casted to int64 before use.
(Optional) Whether map positive infinity to true. Default to 1 so that positive infinity induces true. Set this attribute to 0 if positive infinity should be mapped to false.
detect_positive
(Optional) Whether map negative infinity to true. Default to 1 so that negative infinity induces true. Set this attribute to 0 if negative infinity should be mapped to false.
detect_negative
Constrain input and output types to all tensor types (including bfloat).
'input' must have rank >= 2
'sequence_lens' must have rank of 1
(Optional) Specify which axis is time axis. Must be one of 0 (default), or 1.
time_axis
(Optional) Specify which axis is batch axis. Must be one of 1 (default), or 0.
batch_axis
Tensor of rank r >= 2.
Tensor specifying lengths of the sequences in a batch. It has shape `[batch_size]`.
Tensor with same shape of input.
ReverseSequence
(Optional) Whether to sort the unique elements in ascending order before returning as output. Must be one of 0, or 1 (default).
(Optional) The dimension to apply unique. If not specified, the unique elements of the flattened input are returned. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
A N-D input tensor that is to be processed.
A tensor of the same type as 'X' containing all the unique values or subtensors sliced along a provided 'axis' in 'X', either sorted or maintained in the same order they occur in input 'X'
A 1-D INT64 tensor containing indices of 'Y' elements' first occurance in 'X'. When 'axis' is provided, it contains indices to subtensors in input 'X' on the 'axis'. When 'axis' is not provided, it contains indices to values in the flattened input tensor. 
A 1-D INT64 tensor containing, for elements of 'X', its corresponding indices in 'Y'. When 'axis' is provided, it contains indices to subtensors in output 'Y' on the 'axis'. When 'axis' is not provided, it contains indices to values in output 'Y'. 
inverse_indices
A 1-D INT64 tensor containing the count of each element of 'Y' in input 'X'
(Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0, empty string or False).
A 0-D tensor containing a single value corresponding to the number diagonals above or below the main diagonal to exclude or include. Default value is 0 if it's not specified.
Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization.
Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified.
Constrain 'x' to float or int32 tensor.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\quantization\old.cc
N-D quantized input tensor to be de-quantized.
Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified.
Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
output_height
output_width
Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling, i.e., spatial scale of the input feature map X relative to the input image. E.g.; default is 1.0f. 
default 1; Pooled output Y's height.
default 1; Pooled output Y's width.
Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If == 0, then an adaptive number of grid points are used (computed as ceil(roi_width / output_width), and likewise for height). Default is 0.
sampling_ratio
The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'.
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates are in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
RoI pooled output, 4-D tensor of shape (num_rois, C, output_height, output_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
RoiAlign
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\object_detection\old.cc
An input tensor with shape [num_batches, spatial_dimension, 4]. The single box data format is indicated by center_point_box.
An input tensor with shape [num_batches, num_classes, spatial_dimension]
Integer representing the maximum number of boxes to be selected per batch per class. It is a scalar. Default to 0, which means no output.
max_output_boxes_per_class
Float representing the threshold for deciding whether boxes overlap too much with respect to IOU. It is scalar. Value range [0, 1]. Default to 0.
Float representing the threshold for deciding when to remove boxes based on score. It is a scalar.
selected indices from the boxes tensor. [num_selected_indices, 3], the selected index format is [batch_index, class_index, box_index].
selected_indices
Integer indicate the format of the box data. The default is 0. 0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Mostly used for TF models. 1 - the box data is supplied as [x_center, y_center, width, height]. Mostly used for Pytorch models.
Scale for doing quantization to get 'y'. It can be a scalar, which means per-tensor/layer quantization, or a 1-D Tensor for per-axis quantization.
Zero point for doing quantization to get 'y'. Shape must match y_scale. Default is uint8 with zero point of 0 if it's not specified.
(Optional) The axis of the quantization dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\quantization\defs.cc
Scale for input 'x'. It can be a scalar, which means a per-tensor/layer dequantization, or a 1-D tensor for per-axis dequantization.
Zero point for input 'x'. Shape must match x_scale. It's optional. Zero point is 0 when it's not specified.
(Optional) The axis of the dequantizing dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Quantized output tensor
Output zero point. It's a scalar, which means a per-tensor/layer quantization.
Constrain 'x' to float tensor.
Constrain 'y_zero_point' and 'y' to 8-bit unsigned integer tensor.
        {
           Q_Min = Constant<value = float {0.0}>()
           Q_Max = Constant<value = float {255.0}>()
           X_Min = ReduceMin <keepdims = 0> (x)
           X_Min_Adjusted = Min (X_Min, Q_Min)
           X_Max = ReduceMax <keepdims = 0> (x)
           X_Max_Adjusted = Max (X_Max, Q_Min)
           X_Range = Sub (X_Max_Adjusted, X_Min_Adjusted)
           Scale = Div (X_Range, Q_Max)
           Min_Scaled = Div (X_Min_Adjusted, Scale)
           Initial_ZeroPoint_FP = Sub (Q_Min, Min_Scaled)
           Clipped_ZeroPoint_FP = Clip (Initial_ZeroPoint_FP, Q_Min, Q_Max)
           Rounded_ZeroPoint_FP = Round (Clipped_ZeroPoint_FP)
           Zeropoint = Cast <to = 2> (Rounded_ZeroPoint_FP)
           y_scale = Identity (Scale)
           y_zero_point = Identity (Zeropoint)
           y = QuantizeLinear (x, Scale, Zeropoint)
        }
        
Attribute dtype should be of integer type and specify a type.
(Optional) The data type of the tensors in the output sequence. The default type is 'float'.
Empty sequence.
SequenceEmpty
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\sequence\defs.cc
SequenceConstruct is expected to have at least 1 input.
 is null. Type info is expected.
Input type for input at index 
Element type of inputs are expected to be the same.
Tensors.
Sequence enclosing the input tensors.
Constrain input types to any tensor type.
SequenceConstruct
Input Sequence and Tensor are expected to have type info. Current type is null.
 Tensor=
Input Sequence and Tensor are expected to have the same elem type. Sequence=
Input sequence.
input_sequence
Input tensor to be inserted into the input sequence.
Position in the sequence where the new tensor is inserted. It is optional and default is to insert to the back of the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
position
Output sequence that contains the inserted tensor at given position.
Constrain position to integral tensor. It must be a scalar(tensor of empty shape).
SequenceInsert
Input type for input at index 0 is null. Type info is expected.
Position of the tensor in the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
Output tensor at the specified position in the input sequence.
SequenceAt
Output sequence that has the tensor at the specified position removed.
SequenceErase
Length of input sequence. It must be a scalar(tensor of empty shape).
Constrain output to integral tensor. It must be a scalar(tensor of empty shape).
SequenceLength
Only supports `int32_t` or `int64_t` inputs for split
Input 'split' can not be empty.
 sum of split values=
Sum of split values not equal to 'input' dim size on 'axis'. 'axis' dim size=
Length of each output. It can be either a scalar(tensor of empty shape), or a 1-D tensor. All values must be >= 0. 
One or more outputs forming a sequence of tensors after splitting
Constrain split size to integral tensor.
Constrain output types to all tensor types.
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1].
Keep the split dimension or not. Default 1, which means we keep split dimension. If input 'split' is specified, this attribute is ignored.
SplitToSequence
new_axis must be either 0 or 1
], Value=
Invalid value of attribute 'axis'. Accepted range=[
Which axis to concat on. Accepted range in `[-r, r - 1]`, where `r` is the rank of input tensors. When `new_axis` is 1, accepted range is `[-r - 1, r]`. 
Insert and concatenate on a new axis or not, default 0 means do not insert new axis.
Sequence of tensors for concatenation
ConcatFromSequence
Allowed values are 'half_pixel' and 'output_half_pixel'. Use the value 'half_pixel' to pixel shift the input coordinates by -0.5 (the recommended behavior). Use the value 'output_half_pixel' to omit the pixel shift for the input (use this for a backward-compatible behavior).
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\object_detection\defs.cc
axes as an input and attribute cannot be specified at the same time.
Defines behaviour if 'axes' is empty. Default behaviour with 'false' is to reduce all axes. When axes is empty and this attribute is set to true, input tensor will not be reduced,and the output tensor would be equivalent to input tensor.
Optional input list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor if 'noop_with_empty_axes' is false, else act as an Identity op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1] where r = rank(data).
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\reduction\defs.cc
The shape format of inputs X, initial_h and outputs Y, Y_h. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size, num_directions, hidden_size].
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\rnn\defs.cc
The shape format of inputs X, initial_h, initial_c and outputs Y, Y_h, Y_c. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [batch_size, num_directions, hidden_size].
Optional is expected to have an output.
Attribute 'type' should be a TypeProto and it should specify a type.
Input type is null. Type information is expected for the input.
Optional is expected to have either an input or the type attribute set.
The input element.
Type of the element in the optional output
The optional output enclosing the input element.
Constrains input type to all tensor and sequence types.
Constrains output type to all optional tensor or optional sequence types.
Optional
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\optional\defs.cc
OptionalHasElement is expected to have 1 input.
OptionalHasElement is expected to have 1 output.
The optional input.
A scalar boolean tensor. If true, it indicates that optional-type input contains an element. Otherwise, it is empty.
Constrains input type to optional tensor and optional sequence types.
Constrains output to a boolean tensor.
OptionalHasElement
OptionalGetElement must have an input element.
Input type is null. Input must have Type information.
Input must be an optional-type value containing an element with type information.
Output element in the optional input.
Constrain output type to all tensor or sequence types.
OptionalGetElement
optional(seq(tensor(bfloat16)))
optional(tensor(bfloat16))
Loop 'body' subgraph outputs should all be tensors or sequences or optionals, but output 
All Tensor, Sequence(Tensor), Optional(Tensor), and Optional(Sequence(Tensor)) types
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\controlflow\defs.cc
Data to be selected
The indices, based on 0 as the first index of any dimension.
Selected output data as an array
The input must be a tensor of a numeric type or string. The output will be of the same tensor type.
ArrayFeatureExtractor
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\traditionalml\defs.cc
Data to be binarized
Binarized output data
The input must be a tensor of a numeric type. The output will be of the same tensor type.
Values greater than this are mapped to 1, others to 0.
threshold
Binarizer
cast_to
TO_FLOAT
TO_INT64
TO_STRING
The input map that is to be cast to a tensor
A tensor representing the same data as the input map, ordered by their keys
The input must be an integer map to either string or float.
map(int64, string)
map(int64, float)
The output is a 1-D tensor of string, float, or integer.
A string indicating the desired element type of the output tensor, one of 'TO_FLOAT', 'TO_STRING', 'TO_INT64'.
DENSE
Indicates whether to only output as many values as are in the input (dense), or position the input based on using the key of the map as the index of the output (sparse).<br>One of 'DENSE', 'SPARSE'.
map_form
If the value of map_form is 'SPARSE,' this attribute indicates the total length of the output tensor.
max_map
CastMap
Input data
Output data. If strings are input, the output values are integers, and vice versa.
The input must be a tensor of strings or integers, either [N,C] or [C].
The output is a tensor of strings or integers. Its shape will be the same as the input shape.
The strings of the map. This sequence must be the same length as the 'cats_int64s' sequence
cats_strings
The integers of the map. This sequence must be the same length as the 'cats_strings' sequence.
cats_int64s
_Unused
A string to use when an input integer value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
default_string
An integer to use when an input string value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
default_int64
CategoryMapper
A dictionary.
A 1-D tensor holding values from the input dictionary.
The input must be a map from strings or integers to either strings or a numeric type. The key and value types cannot be the same.
map(string, int64)
map(int64, double)
map(string, float)
map(string, double)
The output will be a tensor of the value type of the input map. It's shape will be [1,C], where C is the length of the input dictionary.
A string vocabulary array.<br>One and only one of the vocabularies must be defined.
string_vocabulary
An integer vocabulary array.<br>One and only one of the vocabularies must be defined.
int64_vocabulary
DictVectorizer
An ordered collection of tensors, all with the same element type.
The output array, elements ordered as the inputs.
The input type must be a tensor of a numeric type.
The size of each input in the input list
inputdimensions
FeatureVectorizer
Data to be processed.
Imputed output data
The input type must be a tensor of a numeric type, either [N,C] or [C]. The output type will be of the same tensor type and shape.
Value(s) to change to
imputed_value_floats
A value that needs replacing.
replaced_value_float
Value(s) to change to.
imputed_value_int64s
replaced_value_int64
Imputer
Label encoder has only one input.
Label encoder has only one output.
keys_strings
keys_int64s
keys_floats
Only one of keys_*'s can be set in label encoder.
Input type is not string tensor but key_strings is set
Input type is not int64 tensor but keys_int64s is set
Input type is not float tensor but keys_floats is set
values_strings
values_int64s
values_floats
Only one of values_*'s can be set in label encoder.
Input data. It can be either tensor or scalar.
Output data.
The input type is a tensor of any shape.
Output type is determined by the specified 'values_*' attribute.
A list of strings. One and only one of 'keys_*'s should be set.
A list of ints.
A list of floats.
A list of strings. One and only one of 'value_*'s should be set.
A string.
An integer.
A float.
default_float
LabelEncoder
classlabels_strings
classlabels_ints
intercepts
Input's shape should be 1D or 2D
Data to be classified.
Classification outputs (one class per example).
Classification scores ([N,E] - one score for each class and example
The input must be a tensor of a numeric type, and of of shape [N,C] or [C]. In the latter case, it will be treated as [1,C]
The output will be a tensor of strings or integers.
A collection of weights of the model(s).
coefficients
A collection of intercepts.
Indicates whether to do OvR or multinomial (0=OvR is the default).
multi_class
Class labels when using string labels. One and only one 'classlabels' attribute must be defined.
Class labels when using integer labels. One and only one 'classlabels' attribute must be defined.
Indicates the transform to apply to the scores vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
post_transform
LinearClassifier
Data to be regressed.
Regression outputs (one per target, per example).
The input must be a tensor of a numeric type.
Indicates the transform to apply to the regression output vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Weights of the model(s).
Weights of the intercepts, if used.
The total number of regression targets, 1 if not defined.
targets
LinearRegressor
Data to be encoded, a tensor of shape [N,C] or [C]
Encoded output data
One of 'MAX,' 'L1,' 'L2'
Normalizer
Data to be encoded.
Encoded output data, having one more dimension than X.
List of categories, ints.<br>One and only one of the 'cats_*' attributes must be defined.
List of categories, strings.<br>One and only one of the 'cats_*' attributes must be defined.
If true and category is not present, will return all zeros; if false and a category if not found, the operator will fail.
OneHotEncoder
Data to be scaled.
Scaled output data.
First, offset by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.
Second, multiply by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.<br>Must be same length as 'offset'
Scaler
Class scores (one per class per example), if prob_a and prob_b are provided they are probabilities for each class, otherwise they are raw scores.
The input must be a tensor of a numeric type, either [C] or [N,C].
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used. Its size will match the bactch size of the input.
LINEAR
The kernel type, one of 'LINEAR,' 'POLY,' 'RBF,' 'SIGMOID'.
kernel_type
List of 3 elements containing gamma, coef0, and degree, in that order. Zero if unused for the kernel.
kernel_params
vectors_per_class
support_vectors
First set of probability coefficients.
prob_a
Second set of probability coefficients. This array must be same size as prob_a.<br>If these are provided then output Z are probability estimates, otherwise they are raw scores.
prob_b
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Class labels if using string labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels if using integer labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
SVMClassifier
Regression outputs (one score per target per example).
The input type must be a tensor of a numeric type, either [C] or [N,C].
Chosen support vectors
Flag indicating whether the regression is a one-class SVM or not.
one_class
Support vector coefficients.
The number of support vectors.
n_supports
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
SVMRegressor
nodes_values
nodes_values_as_tensor
nodes_hitrates
nodes_hitrates_as_tensor
class_weights
class_weights_as_tensor
base_values
base_values_as_tensor
Only one of the attributes 'nodes_values', 'nodes_values_as_tensor' should be specified.
Only one of the attributes 'nodes_hitrates', 'nodes_hitrates_as_tensor' should be specified.
Only one of the attributes 'class_weights', 'class_weights_as_tensor' should be specified.
Only one of the attributes 'base_values', 'base_values_as_tensor' should be specified.
Input of shape [N,F]
N, Top class for each point
The class score for each class, for each point, a tensor of shape [N,E].
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used.
Tree id for each node.
nodes_treeids
Node id for each node. Ids may restart at zero for each tree, but it not required to.
nodes_nodeids
Feature id for each node.
nodes_featureids
Thresholds to do the splitting on for each node.
Popularity of each node, used for performance and may be omitted.
The node kind, that is, the comparison to make at the node. There is no comparison to make at a leaf node.<br>One of 'BRANCH_LEQ', 'BRANCH_LT', 'BRANCH_GTE', 'BRANCH_GT', 'BRANCH_EQ', 'BRANCH_NEQ', 'LEAF'
nodes_modes
Child node if expression is true.
nodes_truenodeids
Child node if expression is false.
nodes_falsenodeids
For each node, define what to do in the presence of a missing value: if a value is missing (NaN), use the 'true' or 'false' branch based on the value in this array.<br>This attribute may be left undefined, and the defalt value is false (0) for all nodes.
nodes_missing_value_tracks_true
The id of the tree that this node is in.
class_treeids
node id that this weight is for.
class_nodeids
The index of the class list that each weight is for.
class_ids
The weight for the class in class_id.
classlabels_int64s
Indicates the transform to apply to the score. <br> One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Base values for classification, added to final class score; the size must be the same as the classes or can be left unassigned (assumed 0)
TreeEnsembleClassifier
target_weights
target_weights_as_tensor
Only one of the attributes 'target_weights', 'target_weights_as_tensor' should be specified.
N classes
Node id for each node. Node ids must restart at zero for each tree and increase sequentially.
Child node if expression is true
Child node if expression is false
For each node, define what to do in the presence of a NaN: use the 'true' (if the attribute value is 1) or 'false' (if the attribute value is 0) branch based on the value in this array.<br>This attribute may be left undefined and the defalt value is false (0) for all nodes.
The id of the tree that each node is in.
target_treeids
The node id of each weight
target_nodeids
The index of the target that each weight is for
target_ids
The weight for each target
The total number of targets.
n_targets
Defines how to aggregate leaf values within a target. <br>One of 'AVERAGE,' 'SUM,' 'MIN,' 'MAX.'
aggregate_function
TreeEnsembleRegressor
The input values
The output map
The output will be a sequence of string or integer maps to float.
seq(map(string, float))
seq(map(int64, float))
The keys when using string keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The keys when using int keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
ZipMap
Input data.
The input type must be a tensor of integers or strings, of any shape.
The output type will be a tensor of strings or integers, and will have the same shape as the input.
A list of labels.
classes_strings
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\traditionalml\old.cc
 is undefined so it cannot be parsed.
The type of tensor: 
 Actual:
. Expected:
ParseData type mismatch for tensor: 
load external data into raw data for tensor: 
Cannot parse data from external tensors. Please 
 does not match the actual size
 expected size 
Data size mismatch. Tensor: 
ConstantFill
==> Context: 
graph
 is required to be non-empty.
value_info
' of 
Field '
 is required but missing.
elem_type
key_type
value_type
Unrecognized type value case (value_info name: 
data_type
) to UNDEFINED is not allowed
setting data_type field (tensor name: 
float_data
int32_data
string_data
int64_data
raw_data
double_data
uint64_data
) is stored externally and should not have data field.
Data of TensorProto ( tensor name: 
, but it doesn't exist or is not accessible.
) should be stored in 
) is stored externally but doesn't have a location.
TensorProto ( tensor name: 
) is 0-element but contains data!
TensorProto (tensor name: 
) should contain one and only one value field.
) should not be stored in raw_data field
STRING data (tensor name: 
' instead of '
' should be stored in field '
values of data_type '
Unrecognized data_type (tensor name: 
 values, but NNZ is 
) has 
Sparse tensor indices (
] out of range [0, 
) index value at position [
Sparse tensor (
] not in sorted order.
) first dimension size does not equal NNZ.
) second dimension size does not match rank of tensor.
] out of range.
] not in lexicographic sorted order.
sparse_tensor_proto
) must have rank 1.
Sparse tensor values (
) must have a dense-rank > 0
) dimensions are not positive.
) must have INT64 type.
) must have rank 1 or 2.
) has no index values.
type field and data field mismatch in attribute 
) should not contain more than one value field.
Attribute (name: 
) should refer to attribute in parent node.
op_type
) has zero input and zero output.
, type: 
NodeProto (name: 
Warning: Checker does not support models with experimental ops: 
No opset import for domain '
 with domain_version of 
No Op registered for 
 is deprecated in domain_version of 
Op registered for 
 OpType: 
Bad node spec for node. Name: 
' has been used as graph input names multiple times.
Graph must be in single static assignment (SSA) form, however '
Tensor initializers must have a non-empty name
 initializer name is not unique
 in initializer but not in graph input
Sparse tensor initializers must have a non-empty name
 sparse initializer name is not unique across initializers and sparse_initializers
 is not output of any previous nodes.
name: 
' of node: 
Nodes in a graph must be topologically sorted, however input '
' has been used as output names multiple times.
invalid stol argument
stol argument out of range
invalid stof argument
stof argument out of range
type_proto
floats
strings
tensors
graphs
sparse_tensors
type_protos
 column: 
(line: 
Expected character 
Value expected but not found.
Integer value expected, but not found.
Unexpected literal type.
String value expected, but not found.
Identifier expected but not found.
Unexpected type.
Error parsing TensorProto (expected a tensor type).
Error parsing TensorProto (expected a tensor shape).
Error parsing TensorProto shape (expected numeric dimension).
Unhandled type: %d
Unexpected attribute type.
Error context: 
[ParseError at position 
 already exists.
Data for input  
optional_type
opaque_type
sparse_tensor_type
NOT_SET
 inferred=
type case mismatch. existing=
key type mismatch from MapProto. existing=
type case unsupported. existing=
type case unsupported for symbolic shape inference. inferred=
Cannot infer type and shape for node name 
Shape inference error(s): 
Container for generated shape data cannot be nullptr when enable_data_propagation option is set.
 were provided
 inputs but 
Graph has 
Cannot use the same name as both a subgraph initializer and subgraph input: 
The number of graph input cannot be smaller than the number of node input
 were provided.
Graph initializer names must appear after the actual inputs: 
in initializers. 
Cannot find missing input: 
, node name: 
(op_type:
Inferred elem type differs from existing elem type: (
Inferred shape and existing shape differ in rank: (
Inferred shape and existing shape differ in dimension 
unk__
) is not equal to the existing dim value (
Dimension value inferred (
Number of elements of input 'sizes' must be same as rank of input 'X'
Input 'sizes' must have int64 element type.
Number of elements of input 'scales' must be same as rank of input 'X'
Input 'scales' must have float element type.
FLOATFLOATSGRAPHGRAPHSINTINTSSPARSE_TENSORSPARSE_TENSORSSTRINGSTRINGSTENSORTENSORSTYPE_PROTOTYPE_PROTOSUNDEFINED
DEFAULTEXTERNAL
BFLOAT16BOOLCOMPLEX128COMPLEX64DOUBLEFLOATFLOAT16INT16INT32INT64INT8STRINGUINT16UINT32UINT64UINT8UNDEFINED
IR_VERSIONIR_VERSION_2017_10_10IR_VERSION_2017_10_30IR_VERSION_2017_11_3IR_VERSION_2019_1_22IR_VERSION_2019_3_18IR_VERSION_2019_9_19IR_VERSION_2020_5_8_START_VERSION
EXPERIMENTALSTABLE
onnx.AttributeProto
onnx.ValueInfoProto
onnx.NodeProto
onnx.TrainingInfoProto
onnx.ModelProto
onnx.StringStringEntryProto
onnx.TensorAnnotation
onnx.GraphProto
onnx.TensorProto.Segment
onnx.TensorProto
onnx.SparseTensorProto
onnx.TensorShapeProto.Dimension
onnx.TensorShapeProto
onnx.TypeProto.Tensor
onnx.TypeProto.Sequence
onnx.TypeProto.Map
onnx.TypeProto.Optional
onnx.TypeProto.SparseTensor
onnx.TypeProto.Opaque
onnx.TypeProto
onnx.OperatorSetIdProto
onnx.FunctionProto
MAPOPTIONALSEQUENCESPARSE_TENSORTENSORUNDEFINED
MAPOPTIONALSEQUENCESPARSE_TENSORTENSORUNDEFINED
onnx.SequenceProto
onnx.MapProto
onnx.OptionalProto
~~~~~~~~~~~~~~~~
j?$Dsp
WXO0O
ProcessInfo
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
runtimeVersion
isRedist
SessionCreationStart
UTCReplace_AppSessionGuid
PartA_PrivTags
EvaluationStop
EvaluationStart
SessionCreation
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
sessionId
irVersion
OrtProgrammingProjection
modelProducerName
modelProducerVersion
modelDomain
usefp16
domainToVersionMap
modelGraphName
modelMetaData
loadedFrom
executionProviderIds
RuntimeError
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
hResult
sessionId
errorCode
errorCategory
errorMessage
function
RuntimePerf
UTCReplace_AppSessionGuid
PartA_PrivTags
schemaVersion
sessionId
totalRuns
totalRunDuration
ExecutionProviderEvent
UTCReplace_AppSessionGuid
PartA_PrivTags
adapterLuidLowPart
adapterLuidHighPart
Microsoft.ML.ONNXRuntime
D:\a\_work\1\s\onnxruntime\build\Windows\RelWithDebInfo\RelWithDebInfo\Microsoft.CognitiveServices.Speech.extension.onnxruntime.pdb
.text
.text$di
.text$mn
.text$mn$00
.text$x
.text$yd
.idata$5
.00cfg
.CRT$XCA
.CRT$XCL
.CRT$XCU
.CRT$XCZ
.CRT$XDA
.CRT$XDZ
.CRT$XIA
.CRT$XIZ
.CRT$XLA
.CRT$XLC
.CRT$XLD
.CRT$XLZ
.CRT$XPA
.CRT$XPZ
.CRT$XTA
.CRT$XTZ
.gfids
.giats
.rdata
.rdata$T
.rdata$r
.rdata$voltmd
.rdata$zETW0
.rdata$zETW1
.rdata$zETW2
.rdata$zETW9
.rdata$zzzdbg
.tls$
.tls$ZZZ
.xdata
.xdata$x
.edata
.idata$2
.idata$3
.idata$4
.idata$6
.data
.data$r
.data$rs
.pdata
_RDATA
.rsrc$01
.rsrc$02
@08~F
@08~F
@60CD
P6 JD
P^@ID
P^`ID
"^&^*^.00V4J
@6pGD
FVH$Ja
0vFVH
X<Z"\
NLP4R2
8b:@<
 ."^&
 0"^&
<F>.@
 0"^&
:F<.>
P6PiD
$4&(($*(,*$|
H ,"&
&H(,*",*.
BHD,F&H*JH>
XZZFX
X(Z*X
X(ZxR
p`r(p
b2t(v
h> bNd6f4
"H$,&&(**h
NHP,R&T*V$N
 V"P$
(@*(,$.(0"(
<p>V@
HzJXL(J`
dNnP(R)
BFD4F2
*$,x.*,
:$<T>
@60[D
"X$,&
 F".$
P6PiD
`08~F
$b&,(
 b.* 
0"P$"&}
j d"6
$n&v$D(
~HFJDL
&l(8*
XLZ@\
<0>46
 t"n$B&I
0t2n4
8t:n<
@zBX\
t x"5
&|(N6
:*<HR
"$$H2
F .",
~ b$j&
(T,j.~0T4j6~8T<j>~@bDjF~HFLjN:P
^4`"b"d(\
^4j"l"d(\ZXe
vPx(vA
\4^"n"p(d
\4^"f"h(d
n p",$
("*j"D
$f(j*
,f0j2
4f8j:
<V@jB
DXHjJ:L
Z@\(^$`(X
X@Z(b d(`\T
Z@l(n `(XHT
XT`(X<T
vvx<v
VxX(`fT
XV`(X
Tz|h~^
Tfpfr(t
X@f(h j(`
,X.,0
*8,".$0((
2L4j6
8f<j>
@~DjF
H~LjN
PXTjV
Xf\j^
`fdjf
hXljn:p
vhxfz(
vhxfz(
vhxfz(
vhxfz(
 b"4$(&$(( l
 b"4*(,$(( d
.L0j2
4X8j:
<X@jB:D
NbP4R(T$V(Ne
JNZj\
^Xbjd
f^jjl:n
v@xjz
$f(j*
,V0j2:4
@\B,D"F$H(@
>~@XB,P"R H(@P<
>~@XB,T"V H(@
<HZj\~^bbjd:f
pRr(p
n~pPr(p
lzvhx|zz~h
<h>n@,B"J L(H
$R&R(8*6"
284"6$8(0]
,X<j>
@fDjF
HfLjN:P
XZZj\
^fbjdBf:V%
l8n"p$r(j
Vfvjx
 X",$
FXH,J
BlDpF,H
BlDpF,H
4p6t8,:
b 4""$
(p,v.,0
(p,v.,0
&\(,0
"p$v&,(
 X$b&:(
2z4r648":$<(4
>f@rB
D`HrJ
LnPrRBT
\t^n`4b"d f(^
jxlJn(l
h~jzlJn(lBh
jzlJn(l
rztJv(t
p~zp|
"J&j(:*
4|688":$<(4-
486">$@(<
4|68B"D$<(480
JLLjN
PXTjV
XX\j^
`fdjf
hJljn:p
zP|(z-
vlxfz(||v
zP|(z6v
zP|(z
zP|(zfv
zP|(znv
zP|(z
486"F$H(<
(t*X,(.
(t*X,(.
2V4$6
*L,..,(
&@((*$,
.b2^4
:L<.>,6T:
*^,,.
*^,,8
&n(t*,,
&f>j@
BfFjH
J^NjPfR:V%
Z^\,^
b"ZJV
Z^\,h
b"ZLV
ZLb(ZvV
ZLb(Z
VnXbZ(b
VnXtZ,\
j ~"Z&j(~*Z.j0~2J6j8~:b>j@~BzFjH~JTNjP`R4V
XHZj\~^zbjd~fzjjl~nTrjt~vTzj|~~J
4|6P@(6:2
4|6P@(6X2
4|6P@(6
2l4n6,8":$<(>r2
6P@(6
2j4f6(@62
6P@(6\2
6P@(6*2*B
4|6P@(6X2
4|6P@(6
2f4f6(@
2f4f6(@
&8("*$,(.
"^$,&
($*("
h t",$
, .(*0
"^$,4
6$*("J
"L*("
j t",$
8$:(*
l t",$
0$2(*
$L&.(,
$V&V((*
.(00.p
z2l4.6
F&b(M
 6"* ]
(4b6E
j j"f$:(
*R,R.Z044
 <"n$
&T*n,\.42
L"n$\448e
FVHtJ2L
$B&r(
 H"@$
$L&.(,
$L&.(,
`60kD
8F:@<
8F:.<,6
:F<N6(8
8F:.<,6D8
8F:.<,6
2z4$6\8Y
F .",
2L4462*"
@f`"E
"t$"&6(&&
p60$E
p\`} 
@6P(E
D6F:>
@20Z#
@:`x$
8$:|0
"L<0"
2L4@6$"
(L*@,
6n:~<
:b>vBpD
.F0422
"($t&*$q
,l6\8
.F0422
 "]AS
< ,"&
@6PRE
2L4.6,&
,4."0$2
*n&H4
 L"4$2
 H".$,
z X"f 4
8,$.$0R2
@hJ(@
@$L(J
@hJ@@.4~>
@hJNN
8L:@<
BLD@F"4
8L:@<"@
BLD@F
,|.:06.9
d$>&6(4*
z2F4L6
,.7uS
&H(,*",P.6,
4n6t8
@HB,D&F,>
L$N.P
 N"6$4,
8@J l
>^@*>
F$H:J
\~^,`~b,d.f
vdtLr
|`zL2z~
.L0Z&6(
2~4H6x8
> @(B
JtL$N\J
6ddlf(h
(H*4,2F
@6PnE
$B&,$
*B,**
.D0".-
("2L4
"t$,&"($*
.B0x.
^6h:<<\@
*",0.60X2
>TDjN
P0R4PY
vzx~z$|
4F6482>tFFT4V2D$F$H
JFLZhljFr4t2h$j$l
nFpZ>(B
`6P{E
N$P$R*T
b0d,f0h(j0l.n
H&.(,
, &"&$&"
(~*",
0F2442
L"H$.&,.L"H$.&,8
4 ""$$(&B
D,h0y
 R"2  $
&R(2& *
R$"&*$8"b(8**(l,@.*,
0H2*0P,
p2`}/
$L&z()
,2.$,
224$2m
8 :H<9
>2@*>
FFH4J2L<N
(~*x,
<"DZ:
\@^.\
`Fb.`
d@f.d
hBj.h
T$lPn
T$pPr
vPx8v
z\|.z
Lt@T-
p:@M0
:0<~>p:F(
(.@.B
&V(4&t,0*
.V04.t402
6N826 :
,6.*0
@HPX`
P6PiD
.N*>(M
40Z2(4(6:8X:
>X@RBtLNH>F
h0VN*P(R:TXV|XRZl\`^R`znNj4h>f
rr*t(v:xXz
&X(R*l,X.R0
8V:.<0> @bBxDZF^HXJRVi
XNT6R>P
$0Z(\,^^`tbRdbf`hPjrvPr4p>n
xVz*|(~,
\ z"n$X.
4n6^8
:n<^>
HnJ^L
NnP^R
XjZ,\(^,`Xb
hnj^l
j j"j$j&j(j*j,j.j0j2j4j6j8j:j<d>6
j j"j$j&j(j*j,j.j0j2j4j6j8j:j<j>j@dB4
8@HPX`,
8@HPX`hv
*\,`2
*v&^"E
*(6(8
8@HR@JB
>^@pF=
H"L0N0P"RJT
`::Jf
Microsoft.CognitiveServices.Speech.extension.onnxruntime.dll
OrtGetApiBase
OrtSessionOptionsAppendExecutionProvider_CPU
FindClose
FindFirstFileW
FindNextFileW
GetLastError
SetLastError
MultiByteToWideChar
WideCharToMultiByte
api-ms-win-core-processenvironment-l1-1-0.dll
api-ms-win-core-file-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-0.dll
api-ms-win-core-string-l1-1-0.dll
?_Xlength_error@std@@YAXPEBD@Z
_Mtx_init_in_situ
_Mtx_destroy_in_situ
_Mtx_lock
_Mtx_unlock
?_Throw_C_error@std@@YAXH@Z
??0?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAA@XZ
??1?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAA@XZ
?_Pninc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAAPEADXZ
??1?$basic_ios@DU?$char_traits@D@std@@@std@@UEAA@XZ
??0?$basic_ios@DU?$char_traits@D@std@@@std@@IEAA@XZ
??0?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@_N@Z
??1?$basic_ostream@DU?$char_traits@D@std@@@std@@UEAA@XZ
?_Lock@?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAAXXZ
?_Unlock@?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAAXXZ
?imbue@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAXAEBVlocale@2@@Z
?setbuf@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAPEAV12@PEAD_J@Z
?showmanyc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JXZ
?sync@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAHXZ
?uflow@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAHXZ
?xsgetn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JPEAD_J@Z
?xsputn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JPEBD_J@Z
?_Xout_of_range@std@@YAXPEBD@Z
?write@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@PEBD_J@Z
?read@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@PEAD_J@Z
?uncaught_exception@std@@YA_NXZ
?sputc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHD@Z
?sputn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAA_JPEBD_J@Z
?setstate@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAAXH_N@Z
?_Osfx@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAXXZ
?flush@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@XZ
?_Xbad_alloc@std@@YAXXZ
?_Getcvt@_Locinfo@std@@QEBA?AU_Cvtvec@@XZ
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@P6AAEAVios_base@1@AEAV21@@Z@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_K@Z
?_Xbad_function_call@std@@YAXXZ
??0?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@IEAA@XZ
??1?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
?sputc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@QEAAG_W@Z
?sputn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@QEAA_JPEB_W_J@Z
?_Pninc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@IEAAPEA_WXZ
??1?$basic_ios@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
?setstate@?$basic_ios@_WU?$char_traits@_W@std@@@std@@QEAAXH_N@Z
??0?$basic_ios@_WU?$char_traits@_W@std@@@std@@IEAA@XZ
?_Osfx@?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAXXZ
?flush@?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV12@XZ
??0?$basic_iostream@_WU?$char_traits@_W@std@@@std@@QEAA@PEAV?$basic_streambuf@_WU?$char_traits@_W@std@@@1@@Z
??1?$basic_iostream@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
?_Lock@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAAXXZ
?_Unlock@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAAXXZ
?imbue@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAXAEBVlocale@2@@Z
?setbuf@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAPEAV12@PEA_W_J@Z
?showmanyc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JXZ
?sync@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAHXZ
?uflow@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAGXZ
?xsgetn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JPEA_W_J@Z
?xsputn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JPEB_W_J@Z
MSVCP140_APP.dll
_purecall
__std_terminate
__std_exception_copy
__std_exception_destroy
_CxxThrowException
__CxxFrameHandler4
memcpy
memmove
memset
memchr
memcmp
__C_specific_handler
__std_type_info_destroy_list
VCRUNTIME140_APP.dll
VCRUNTIME140_1_APP.dll
_invalid_parameter_noinfo_noreturn
abort
__acrt_iob_func
fflush
__stdio_common_vfprintf
__stdio_common_vsprintf
_errno
strtod
strtol
_dclass
_fdclass
strerror
calloc
isalpha
_close
_read
_write
ceilf
_initterm
_initterm_e
_callnewh
malloc
_seh_filter_dll
_configure_narrow_argv
_initialize_narrow_environment
_initialize_onexit_table
_register_onexit_function
_execute_onexit_table
_crt_atexit
_cexit
api-ms-win-crt-runtime-l1-1-0.dll
api-ms-win-crt-stdio-l1-1-0.dll
api-ms-win-crt-convert-l1-1-0.dll
api-ms-win-crt-string-l1-1-0.dll
api-ms-win-crt-math-l1-1-0.dll
api-ms-win-crt-heap-l1-1-0.dll
api-ms-win-crt-filesystem-l1-1-0.dll
InitOnceBeginInitialize
InitOnceComplete
ReleaseSRWLockExclusive
AcquireSRWLockExclusive
WakeAllConditionVariable
SleepConditionVariableSRW
QueryPerformanceCounter
GetCurrentProcessId
GetCurrentThreadId
GetSystemTimeAsFileTime
InitializeSListHead
api-ms-win-core-synch-l1-2-0.dll
api-ms-win-core-synch-l1-1-0.dll
api-ms-win-core-profile-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-0.dll
api-ms-win-core-sysinfo-l1-1-0.dll
api-ms-win-core-interlocked-l1-1-0.dll
GetEnvironmentVariableA
CreateDirectoryA
CreateDirectoryW
DeleteFileW
GetFileAttributesA
GetFileAttributesW
GetFileSizeEx
GetFinalPathNameByHandleW
ReadFile
RemoveDirectoryW
SetFilePointerEx
CreateFile2
IsDebuggerPresent
OutputDebugStringW
CloseHandle
RaiseFailFastException
HeapAlloc
HeapFree
GetProcessHeap
WaitForSingleObject
Sleep
GetCurrentThread
SetThreadDescription
GetSystemInfo
GetLogicalProcessorInformation
FreeLibrary
GetModuleFileNameA
GetProcAddress
SetThreadAffinityMask
FormatMessageA
FormatMessageW
LoadPackagedLibrary
WakeConditionVariable
GetCurrentProcessorNumber
PathCchRemoveBackslash
PathCchRemoveFileSpec
EventRegister
EventUnregister
EventSetInformation
EventWriteTransfer
GetSystemTimePreciseAsFileTime
api-ms-win-core-file-l1-2-0.dll
api-ms-win-core-debug-l1-1-0.dll
api-ms-win-core-handle-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-2.dll
api-ms-win-core-heap-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-3.dll
api-ms-win-core-libraryloader-l1-2-0.dll
api-ms-win-core-processtopology-obsolete-l1-1-0.dll
api-ms-win-core-localization-l1-2-0.dll
api-ms-win-core-libraryloader-l2-1-0.dll
api-ms-win-core-processthreads-l1-1-1.dll
api-ms-win-core-path-l1-1-0.dll
api-ms-win-eventing-provider-l1-1-0.dll
api-ms-win-core-sysinfo-l1-2-0.dll
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@H@Z
??0_Lockit@std@@QEAA@H@Z
??1_Lockit@std@@QEAA@XZ
?_Xinvalid_argument@std@@YAXPEBD@Z
_Xtime_get_ticks
_Query_perf_counter
_Query_perf_frequency
??Bid@locale@std@@QEAA_KXZ
?classic@locale@std@@SAAEBV12@XZ
?_Getgloballocale@locale@std@@CAPEAV_Locimp@12@XZ
?always_noconv@codecvt_base@std@@QEBA_NXZ
?_Getcat@?$ctype@D@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?widen@?$ctype@_W@std@@QEBA_WD@Z
?_Getcat@?$ctype@_W@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?in@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEBD1AEAPEBDPEAD3AEAPEAD@Z
?out@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEBD1AEAPEBDPEAD3AEAPEAD@Z
?unshift@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEAD1AEAPEAD@Z
?_Getcat@?$codecvt@DDU_Mbstatet@@@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?getloc@ios_base@std@@QEBA?AVlocale@2@XZ
?getloc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEBA?AVlocale@2@XZ
?sbumpc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?sgetc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?snextc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?_Init@?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAAXXZ
?imbue@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAA?AVlocale@2@AEBV32@@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@F@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_J@Z
??0?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAA@PEAV?$basic_streambuf@_WU?$char_traits@_W@std@@@1@_N@Z
??1?$basic_ostream@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@I@Z
??0?$basic_istream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@_N@Z
??1?$basic_istream@DU?$char_traits@D@std@@@std@@UEAA@XZ
?_Ipfx@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAA_N_N@Z
??5?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@AEAF@Z
?get@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAHXZ
?_Fiopen@std@@YAPEAU_iobuf@@PEB_WHH@Z
?id@?$ctype@D@std@@2V0locale@2@A
?id@?$ctype@_W@std@@2V0locale@2@A
?id@?$codecvt@DDU_Mbstatet@@@std@@2V0locale@2@A
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_N@Z
?widen@?$basic_ios@DU?$char_traits@D@std@@@std@@QEBADD@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@P6AAEAV01@AEAV01@@Z@Z
?put@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@D@Z
??0?$basic_iostream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@@Z
??1?$basic_iostream@DU?$char_traits@D@std@@@std@@UEAA@XZ
?cerr@std@@3V?$basic_ostream@DU?$char_traits@D@std@@@1@A
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@I@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@PEBX@Z
_Thrd_hardware_concurrency
?_Syserror_map@std@@YAPEBDH@Z
?_Winerror_map@std@@YAHH@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@K@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@H@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@K@Z
?clear@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAAXH_N@Z
_Thrd_id
?wclog@std@@3V?$basic_ostream@_WU?$char_traits@_W@std@@@1@A
??0_Locinfo@std@@QEAA@PEBD@Z
??1_Locinfo@std@@QEAA@XZ
?_Getfalse@_Locinfo@std@@QEBAPEBDXZ
?_Gettrue@_Locinfo@std@@QEBAPEBDXZ
?c_str@?$_Yarn@D@std@@QEBAPEBDXZ
??0facet@locale@std@@IEAA@_K@Z
??1facet@locale@std@@MEAA@XZ
?imbue@?$basic_ios@_WU?$char_traits@_W@std@@@std@@QEAA?AVlocale@2@AEBV32@@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@_J@Z
?_Decref@facet@locale@std@@UEAAPEAV_Facet_base@3@XZ
?_Incref@facet@locale@std@@UEAAXXZ
?id@?$numpunct@D@std@@2V0locale@2@A
__std_type_info_compare
__RTtypeid
__std_type_info_name
__current_exception
__current_exception_context
strncpy_s
terminate
strcmp
strncmp
_get_stream_buffer_pointers
fclose
fgetc
fgetpos
fputc
fread
fsetpos
_fseeki64
fwrite
setvbuf
ungetc
_lock_file
_unlock_file
wcsftime
_localtime64_s
tolower
strtoll
strtoull
localeconv
sqrtf
_fdsign
log1pf
floorf
rintf
remainderf
floor
strnlen
_aligned_free
_aligned_malloc
bsearch
_strtoi64
isspace
ldexp
_invalid_parameter_noinfo
__stdio_common_vswprintf
__stdio_common_vsnprintf_s
_wsopen_s
_fstat64i32
_beginthreadex
_sopen_s
_difftime64
_gmtime64_s
_mktime64
llroundl
_stat64i32
strtof
isdigit
isalnum
api-ms-win-crt-time-l1-1-0.dll
api-ms-win-crt-locale-l1-1-0.dll
api-ms-win-crt-utility-l1-1-0.dll
LocalFree
api-ms-win-core-heap-l2-1-0.dll
.?AVbad_array_new_length@std@@
.?AVbad_alloc@std@@
.?AVexception@std@@
.?AVFatalException@protobuf@google@@
.?AVOnnxRuntimeException@onnxruntime@@
.?AVNotImplementedException@onnxruntime@@
.?AU?$default_delete@VIExecutionProvider@onnxruntime@@@std@@
.?AV<lambda_78d2ff8fcf22c6166aa97abbb5fd0d75>@@
.?AV<lambda_6b9436f4089e82f5864d5365b56a5e02>@@
.?AV<lambda_3435a69bc2a4a58cf25c9601fa916799>@@
.P6AXPEAX@Z
.?AUException@Ort@@
.?AVlogic_error@std@@
.?AV<lambda_9bb5d71c29e163b6768bdebbeaa9ef83>@@
.?AV<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@
.?AV<lambda_ca87e505bf8a7e1f26579083c3683d94>@@
.?AVbad_cast@std@@
.?AVruntime_error@std@@
.?AVbad_optional_access@std@@
.?AVexception@detail@nlohmann@@
.?AVother_error@detail@nlohmann@@
.?AU?$default_delete@VCPUExecutionProvider@onnxruntime@@@std@@
.?AV<lambda_739930acb5d4a4b1d92f387c9190b820>@@
.?AV<lambda_165747221b83b97edb1c8980b4a934c8>@@
.P6A?AVStatus@common@onnxruntime@@AEAVGraph@2@AEA_NAEBVIExecutionProvider@2@@Z
.?AV<lambda_b32e5f2bc2fafd58a4afcda5e8537c65>@@
.?AV<lambda_90fa7e4386c5622637b0b1880f5ca8f3>@@
.?AV<lambda_ba9cfe2bb13e49d1f5f6d627965891ec>@@
.?AU?$default_delete@VModel@onnxruntime@@@std@@
.?AV<lambda_c89e6783ea7ba65dd2bbca371d42018d>@@
.?AVout_of_range@std@@
.?AVout_of_range@detail@nlohmann@@
.?AVtype_error@detail@nlohmann@@
.?AVinvalid_iterator@detail@nlohmann@@
.?AVparse_error@detail@nlohmann@@
.?AVInferenceError@onnx@@
.?AVSchemaError@onnx@@
.?AV<lambda_80bd8f1476bc31a08ed6cb365cfefa4a>@@
.?AV<lambda_bb296edf374db63a1fb223cbff2a45aa>@@
.P6AXAEAUInferenceContext@onnx@@@Z
.?AV<lambda_a6025d7753fe49dfa6ce58be5196bf75>@@
.?AV<lambda_194fafbac36b97ada7ff78b4fe337622>@@
.?AV<lambda_28a69d198faef3db79470de4de6f53e9>@@
.?AV<lambda_6922b57be4edd39a89a7cea9e2ebb658>@@
.?AV<lambda_716d92b2455b6dca0a3e195a50699167>@@
.?AV<lambda_73cc642ed8afaa2889c4f09584fca345>@@
.?AV<lambda_0fb4e93f4014e9a9ed52287648f86c91>@@
.?AV<lambda_3a80fca790cdb0fce14ddaedefa20351>@@
.?AV<lambda_519fe9cae569b1ad1c3f73288fa352d4>@@
.?AV<lambda_b35f6304ab9b91e067de16d773b507fb>@@
.?AV<lambda_ab7cc530eb49a3a15082dbc27eb613da>@@
.?AV<lambda_8fef7dbb6b3e81cda489ebe45ab449bb>@@
.?AV<lambda_d522df09ab9335db57f0cfc8c09d6630>@@
.?AV<lambda_daa97a08fba16356a015278e0f3ca1ed>@@
.?AV<lambda_888c8332848e83c225ef5f5587c3b38e>@@
.?AV<lambda_18dbcf0a6112b471cd3435637c32f0f8>@@
.?AV<lambda_de00575298e9c7ead3b243890c596395>@@
.?AV<lambda_598c6d249dbd14226af8e69fe738f910>@@
.?AV<lambda_7965ceabe5f45db89655ad0a7fd04cd6>@@
.?AV<lambda_dcbbb9aee7454d5a0feb975df66a7001>@@
.?AV<lambda_33c11271a908f4f215dd361ca0be165e>@@
.?AV<lambda_055b4d24f8a1f4b549310d8384e8330c>@@
.?AV<lambda_f8f4a9a0b8865f5f39e8ba472bf52edc>@@
.?AV<lambda_61a830e6f94472550f401a07bc054c29>@@
.?AV<lambda_adedb98ee19cb4d9a4a46a5fd17584b5>@@
.?AVGraphConstantInitializerGetter@?A0x9d9d0a9c@onnxruntime@@
.?AV<lambda_d2c978ff584bacbceac7be3bb080e51e>@@
.?AV<lambda_1c47a842a4ad24719aaf09edc25c7aef>@@
.?AV<lambda_4de083bd9feef97ef116b9ac6f248cfc>@@
.P6A?AVStatus@common@onnxruntime@@AEAVFuncManager@2@AEBVOpKernelInfo@2@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@Z
.?AV<lambda_9ad4dd46fb7ebf522a3e85e715143745>@@
.?AV<lambda_a7f558f1dd0bc6dfbc34073d8010b2d2>@@
.?AU?$Elu@M@functors@onnxruntime@@
.?AU?$HardSigmoid@M@functors@onnxruntime@@
.?AU?$LeakyRelu@M@functors@onnxruntime@@
.?AU?$Relu@M@functors@onnxruntime@@
.?AU?$Relu@N@functors@onnxruntime@@
.?AU?$Selu@M@functors@onnxruntime@@
.?AU?$Sigmoid@M@functors@onnxruntime@@
.?AU?$Sigmoid@N@functors@onnxruntime@@
.?AU?$Softplus@M@functors@onnxruntime@@
.?AU?$Softsign@M@functors@onnxruntime@@
.?AU?$Tanh@M@functors@onnxruntime@@
.?AU?$Tanh@N@functors@onnxruntime@@
.?AU?$Celu@M@functors@onnxruntime@@
.?AU?$ThresholdedRelu@M@functors@onnxruntime@@
.?AU?$Abs@M@functors@onnxruntime@@
.?AU?$Abs@N@functors@onnxruntime@@
.?AU?$Abs@C@functors@onnxruntime@@
.?AU?$Abs@F@functors@onnxruntime@@
.?AU?$Abs@H@functors@onnxruntime@@
.?AU?$Abs@_J@functors@onnxruntime@@
.?AU?$Abs@E@functors@onnxruntime@@
.?AU?$Abs@G@functors@onnxruntime@@
.?AU?$Abs@I@functors@onnxruntime@@
.?AU?$Abs@_K@functors@onnxruntime@@
.?AU?$Floor@M@functors@onnxruntime@@
.?AU?$Reciprocal@M@functors@onnxruntime@@
.?AU?$Reciprocal@N@functors@onnxruntime@@
.?AU?$Sqrt@M@functors@onnxruntime@@
.?AU?$Sqrt@N@functors@onnxruntime@@
.?AU?$Exp@M@functors@onnxruntime@@
.?AU?$Exp@N@functors@onnxruntime@@
.?AV<lambda_95dd41682914710e4e8d31623057e7d3>@@
.?AV<lambda_acccfeb1e0041e26bf01c6097464f8c5>@@
.?AV<lambda_23a1bb0478ab7117c6dff4712434f02b>@@
.?AV<lambda_13046178b359e9c81742cfc406e97a28>@@
.?AU?$MaxPool3DTask@M@onnxruntime@@
.?AU?$MaxPool2DTask@M@onnxruntime@@
.?AU?$MaxPool1DTask@M@onnxruntime@@
.?AU?$MaxPool3DTask@N@onnxruntime@@
.?AU?$MaxPool2DTask@N@onnxruntime@@
.?AU?$MaxPool1DTask@N@onnxruntime@@
.?AU?$MaxPool3DTask@C@onnxruntime@@
.?AU?$MaxPool2DTask@C@onnxruntime@@
.?AU?$MaxPool1DTask@C@onnxruntime@@
.?AU?$MaxPool3DTask@E@onnxruntime@@
.?AU?$MaxPool2DTask@E@onnxruntime@@
.?AU?$MaxPool1DTask@E@onnxruntime@@
.?AV<lambda_28c42d729a2f53041e8b22b1ed6cdff0>@@
.?AV<lambda_4bcb1ddbded281b4b93a8d23384ad316>@@
.?AV<lambda_e79b149fca88b77c33b72523d605d32a>@@
.?AV<lambda_b547b93cbe3e16cfc4195284dfd5eaef>@@
.?AV<lambda_2bf8017c8b0b3ab5a242f82899957cda>@@
.?AV<lambda_cfafdf587dd99b527f40f2a9bbc4721a>@@
.?AV<lambda_6cda9f0816757e5a4d291ef9c3329fae>@@
.?AV<lambda_4f02b89eec40e1f508d9a8a5576d7ee8>@@
.?AV<lambda_20a837f51a15ec806ec07fe236459bf3>@@
.?AV<lambda_9bcf543f98218e465d42a5f7a449290e>@@
.?AV<lambda_621fbd8d0cbcf0a8f4c51871d816bf2f>@@
.?AV<lambda_191f334b7e6fbfb2860cdf729a487dba>@@
.?AV<lambda_b9c72854712561eaa1748a5213a8f880>@@
.?AV<lambda_44094649bc82ecb2fc1ec6afdbc202d7>@@
.?AV<lambda_e128163c41b62dbd7415427042732d90>@@
.?AV<lambda_5fa3956cb796f4fb0ed4cc8ce896bcf4>@@
.?AV<lambda_aa268cbc0b0d4966ec51ad17dda0ec82>@@
.?AV<lambda_d1b650f23fa7659d3b2735ce4ed580e4>@@
.?AV<lambda_b6c8ff4cf86b60687891fce83403bcfe>@@
.?AV<lambda_19653ee275cc0117099f6e46319415af>@@
.?AV<lambda_3acaf4e71a87bfb836a528474a23b2b9>@@
.?AV<lambda_af13a0a68d606e99765e2f7bd840b2f7>@@
.?AV<lambda_fc2c6db54ba2969b0c3aebde05d3921d>@@
.?AV<lambda_5032e4da5cc3197800498a50f18978ca>@@
.?AV<lambda_3723f23b8a34d9d98e7ee4d14fc03d1b>@@
.?AV<lambda_9b63af4b3b6c6dd79d915ddcfe92473d>@@
.?AV<lambda_9444b9c3df22cd88603cfb31f51cceb7>@@
.?AV<lambda_9c51e5beef5cfad81c8e2b8d3dd04a4a>@@
.?AV<lambda_0b0bbca98147f2b1d98b75bc68203f51>@@
.?AV<lambda_101e0d486e161cfbbc4332cd98f3239a>@@
.?AV<lambda_ee8bcd2d07e1fd45b1c55d57b7556b9f>@@
.?AV<lambda_eeeed7b40e814a0e70cf05a3907bbf81>@@
.?AV<lambda_a2ae5f61cc20c1ab03a30ab181749eea>@@
.?AV<lambda_1efd3ecb51119ba3eba8bc9319f01386>@@
.?AV<lambda_f77770976f2f1ea63d04f11ed8ae8858>@@
.?AV<lambda_72aab4f7a75329bf9825db841274d3a3>@@
.?AV<lambda_6f8420b50886667bda26b0e8f59183bf>@@
.?AV<lambda_3aac6f1c979a8b893423e58931ed2daa>@@
.?AV<lambda_b609acf5869a906202c2ec8d4f323bb0>@@
.?AV<lambda_40d9bd0925a189b8d1c995cd48d17d39>@@
.?AV<lambda_d8f306720719e22494f4df721d014f49>@@
.?AV<lambda_cc71ada574b25d74a4c48413625b90d1>@@
.?AV<lambda_de173f36c1a40fc38c17fd4d3151fc18>@@
.?AV<lambda_5933cfcb3215128b0a25c0614f75da87>@@
.?AV<lambda_761421d99b53ea1d25ac65996497fbea>@@
.?AV<lambda_c2abf8115bf6da52b8610764cf48ee0f>@@
.?AV<lambda_887dae5249605a4edc99e39f2a0adf15>@@
.?AV<lambda_8f6bf12e356c17071a18123d1fef52d6>@@
.?AV<lambda_e65b3d84cc1ebbac94bfd47d08839322>@@
.?AV<lambda_5178fbfdb12cb266aaef66d97a4a2fc5>@@
.?AV<lambda_d88752c7e7055eb8ee4749bbd38c2e1a>@@
.?AV<lambda_368acd23d928f0f5d2e3ced50c09e50c>@@
.?AV<lambda_89d3c68acc787e643b03eef066fea4d2>@@
.?AV<lambda_9e35eefcb137cd146c958ca877000a5d>@@
.?AV<lambda_3b70c471f0d6c3603fdf76e6ccfb54a3>@@
.?AV<lambda_91f296869b04eedc9f496835c423da26>@@
.?AV<lambda_243c848b67147a62f5be9d25d42a217b>@@
.?AV<lambda_46087cac4b4384e4406cfa052cc4f414>@@
.?AV<lambda_3ae9af8a84288cef25a7cf83bd0834fa>@@
.?AV<lambda_409a8ec0de4403e02d09bb9a4b937276>@@
.?AV<lambda_79f470cac7ca56067b4bc354acf028f6>@@
.?AV<lambda_994ac64fe4673357a711f942252cee0c>@@
.?AV<lambda_d5d46741b892946aacca2ea22e630eea>@@
.?AV<lambda_59fb7201bedc86d0ed85da074d1993f3>@@
.?AV<lambda_578472dc2e9e27345d825b47aca036a6>@@
.?AV<lambda_61cda506a6bb2ddf6aa949685eb7c77c>@@
.?AV<lambda_e252e05424c33acac940c2f481ad24ee>@@
.?AV<lambda_6ae1de67e6e99002a693271defb4e48d>@@
.?AV<lambda_b62b9616dd6208ed1baf09034b8ca175>@@
.?AV<lambda_3cfedd26cd9ef5f4cd0322b54223b692>@@
.?AV<lambda_06e28cef24f38d1ecd4447df16780ad3>@@
.?AV<lambda_339ccdd8cf9a471a2525280227358fe6>@@
.?AV<lambda_d7a2681e4ada46acb33dd1adb547c252>@@
.?AV<lambda_f59689bb1f16cb74228cd5fe68f4cabe>@@
.?AV<lambda_24ac27632a899010d1e56f7da8454199>@@
.?AV<lambda_ed67f482bebf565f55f04daede9ac63d>@@
.?AV<lambda_11c15110a2869c43f5467753b7474409>@@
.?AV<lambda_cba067a26cf21de5d0e68b8b6f37fe8f>@@
.?AV<lambda_8a367ed868a5821659948b0a337825f5>@@
.?AV<lambda_cb7393b1270049ba922f1a24832dd162>@@
.?AV<lambda_ea5f658f0d872dbd3ae3afb1f1fd1122>@@
.?AV<lambda_18f6d57bac34239d650ddbef707551e4>@@
.?AV<lambda_ca42e3f2ca4d6bbcd7bf706226d12a4c>@@
.?AV<lambda_b3e04491343c2b41488666814183e8a7>@@
.?AV<lambda_9b3108d194a09162f36c1b6ecbe4bd22>@@
.?AV<lambda_cf886ef71e61e28cd5fd0d3055f9efbe>@@
.?AV<lambda_265c7b3426b87aef377811f8829e6fd7>@@
.?AV<lambda_67b6bf510365b722acc4b67b8d30f927>@@
.?AV<lambda_c23a6e376db7c7388aa04e9eb8ee3aca>@@
.?AV<lambda_f418dafe297dbbe0e3ada3e20a715a40>@@
.?AV<lambda_a51dc28255d67c31f47c2a37cec4d4e4>@@
.?AV<lambda_7331cae3c69c0d5b155ee357c1007837>@@
.?AV<lambda_678560984ac7af19a5b63edeab48a227>@@
.?AV<lambda_70539968d61afd98aa9c406314f181bf>@@
.?AV<lambda_12237f9b9f786fa2f677523e51689677>@@
.?AV<lambda_a179296bb96622fe30c41b2986ab7695>@@
.?AV<lambda_d085624eed89d70192230e9a1f62c5a7>@@
.?AV<lambda_581b6d14e5adbd13737160d24e40c605>@@
.?AV<lambda_3e80eabb3a9d111992ebd5907a12e903>@@
.?AV<lambda_8d1cbd61cf9e0403bbdc22c2b23b0de2>@@
.?AV<lambda_601c95e3fba8a34ac8d24c850c4e911b>@@
.?AV<lambda_a6353a4d545858b8902fbb038d252087>@@
.?AV<lambda_a0f363c6d35242db2945bd981d31d01b>@@
.?AV<lambda_dbdf3737eb2cb2871abd98870dad8484>@@
.?AV<lambda_b88ca2272a912106e48e54848e61d223>@@
.?AV<lambda_d132db5c486427a93d54120da48d5ea6>@@
.?AV<lambda_0aeb3b3202e2e34a7d6b98b623e6a327>@@
.?AV<lambda_b765106161737954a77d8a171216f44e>@@
.?AV<lambda_b92cd1be17f8632fbcc9dec212afe76b>@@
.?AV<lambda_aa638f082cd6e633ea8c394e1663fa60>@@
.?AV<lambda_ab076180da33c991061bdac15a41448d>@@
.?AV<lambda_1a286ef6a47f06b31852d582b51b4ff5>@@
.?AV<lambda_f563daf0e095e96808b0280be50284eb>@@
.?AV<lambda_6bbfc6268021e2bfd0f1bd3e4700889b>@@
.?AV<lambda_f0ea35f12b551ef953688db40e1f4b34>@@
.?AV<lambda_4f04249e04d07d50d630e12dc9f30f23>@@
.?AV<lambda_c8779530b1b47f6b819a3c840cb70825>@@
.?AV<lambda_d2c19ae18917b59844dd4110518387dd>@@
.?AV<lambda_1f8675d15ee5efaa8f5579945c6d118a>@@
.?AV<lambda_6c91c6f34bd8327dc22f6b7f8735fd5b>@@
.?AV<lambda_786b2ff03846fcfa21d00bf234deaff2>@@
.?AV<lambda_30e1101d7025e2d839d1daa9ac434cd1>@@
.?AV<lambda_115059020db09aa13bab825ad518034e>@@
.?AV<lambda_5820733bf712edf4856ad2454498e68c>@@
.?AV<lambda_e77a57374f1e055f8281ce5dd65e8ebd>@@
.?AV<lambda_6e3cb65d29853e95007cf81c805209f2>@@
.?AV<lambda_33215563a6aacb86deff746a6aa28a6c>@@
.?AV<lambda_e1a7abf114b955966097bd83c14de705>@@
.?AV<lambda_0251dfdaad61cfa5b2a46c99b78d27e8>@@
.?AV<lambda_9800a6d45ddc69dc425addf83da8e9e3>@@
.?AV<lambda_310ceee0e4c58a7a83d7d00319ed9410>@@
.?AV<lambda_42580b4f3e49f7dcfbf37d76233bd856>@@
.?AV<lambda_d48cb9baeb37d51a45fff2e006fd2ed3>@@
.?AV<lambda_e08a75ecff8a2a27b308be3f8dfddc66>@@
.?AV<lambda_3b97251de202434e86d007c33f9345a1>@@
.?AV<lambda_c646dd14edaacae64487e0b96ad575f5>@@
.?AV<lambda_f30a6117225d3cb8e4a11f826263726e>@@
.?AV<lambda_b9ad0ccbf56c00a46342640cba7cdc2c>@@
.?AV<lambda_d0c5713ac46ee06d27e6324a463b7bee>@@
.?AV<lambda_1fd04ff7ed408ca4ebed6e8107f19670>@@
.?AV<lambda_fd4f2bbf00caf507fea1cc6053ab984e>@@
.?AV<lambda_3f0ef66d0b0de67b55e854d697da2fff>@@
.?AV<lambda_0f619f3ff08e9e7659a763308b991cbe>@@
.?AV<lambda_7c13e222993d6446f9d97d9b8d2341e0>@@
.P6A?AV?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J1@Z
.P6A?AV?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J1@Z
.?AV<lambda_4bd02c7b372889e26c922fb97a0c9ac3>@@
.?AV<lambda_bbed65651851398ae9e91eb41072a5f9>@@
.?AV<lambda_e7ad5c511f7f0ca88484948ab82410f1>@@
.?AV<lambda_86dd40270c718f299cd5113909653b31>@@
.?AV<lambda_91a43e75998e3a49d1905d29f4a7bae4>@@
.?AV<lambda_712a327d31152b694fd95674c69e7447>@@
.?AV<lambda_0e4160f1c09428b722c89257b1bbabcb>@@
.?AV<lambda_d7872c9b42ef54f352452eac083f3a35>@@
.?AV<lambda_53001c91fe43da87bd732d9a4fb0e358>@@
.?AV<lambda_cefaaa440fbc31a737d643cd7070b2a7>@@
.?AV<lambda_773e80e25f547e476dbfdd43767644cb>@@
.?AV<lambda_534716bd90e3d628f36025c4e60922bb>@@
.?AV<lambda_2830e7879c71bbb5a2447c8cce82dc3b>@@
.?AV<lambda_59efc6d2c00331cc0701da5f7ba31f88>@@
.?AV<lambda_59d0f05394547c6e0e03de3b8b189e7d>@@
.?AV<lambda_464e1f80ac51d01e54b77145fd34c5bb>@@
.?AV<lambda_41bb79d9c7cc8f02e2f871c5095cf1ee>@@
.?AV<lambda_fa46dd69454a850b787307a9d6678e80>@@
.?AV<lambda_70b1e1dcbe48b81893d8f59a8144faf6>@@
.?AV<lambda_ae0d8b5a2da4af67276477f8d17abe42>@@
.?AV<lambda_6744a0008aca8ce8a0b29db8f1c01fa1>@@
.?AV<lambda_9dc7af5c7bcff785bd9190f2cb464b36>@@
.?AV<lambda_f273d4d4788dd6d522544c26d76a5ae4>@@
.?AV<lambda_eb887415aed41a3927a754246db16d35>@@
.?AV<lambda_8e2d345faf08aedb7570dd988fdca755>@@
.?AV<lambda_ef9ce4d0dc32ab06ddd4426fedb787f1>@@
.?AV<lambda_06471b7954288b9dda9f9d99a72bb7c6>@@
.?AV<lambda_d8b96520499b24df75ab37992af46b4d>@@
.?AV<lambda_88f211d79a091f6a481688e49635f453>@@
.?AV<lambda_8205a59784c4f81abae5636754370a87>@@
.?AV<lambda_03e7406b29b220fa131a6585ce48dcd2>@@
.?AV<lambda_2a3f9f19c48a100998729328075237dc>@@
.?AV<lambda_8ffce33af8696a7a42fa073f6875aacb>@@
.?AV<lambda_8f0d91faf2fd476a9a61179d9b72837d>@@
.?AV<lambda_a1b033c1238f74f04d136673bf3141a7>@@
.?AV<lambda_1cd5cfe6b76bb3ba1c53203d58a4eedd>@@
.?AV<lambda_72e83488395612e0f6a2602b726a187c>@@
.?AV<lambda_f55fed088cc6887bf534564a0809769f>@@
.?AV<lambda_c6728963f8bb91595df67d14c61fd8fa>@@
.?AV<lambda_b2b5b00a4ad3647a9a40b4f0dbb0745d>@@
.?AV<lambda_f2842527842316c8394eef731b560fea>@@
.?AV<lambda_a32f11f3f6edc3a900d9d34015d67705>@@
.?AV<lambda_cc7060560dae87f5475ce357b0faca8e>@@
.?AV<lambda_11002e821957b929b79aa649ecf0a381>@@
.?AV<lambda_ecc9b9120eb4793427a94169f5623a5b>@@
.?AV<lambda_7b13e0aa9183a7266252ed7dbdd54f99>@@
.?AV<lambda_038eb253b7f4e93118566e43dda81530>@@
.?AV<lambda_f8dbfaed9d55440bb15cbf009ac934a6>@@
.?AV<lambda_88cacdca8b660ada94d8f522e9f11bdd>@@
.?AV<lambda_33ab9233a6e2a6fe6c24d1963cbc3111>@@
.?AV<lambda_51f7b34ad2d14ff9bfb03559ccadc81f>@@
.?AV<lambda_1221b4097effa32a8dd388b4455dd2c1>@@
.?AV<lambda_e69e76386d33ec96f42e27fde06de5c2>@@
.?AV<lambda_4092000fa2c851eb2ddefc1b6efbf1fc>@@
.?AV<lambda_95c74ffd32a4d994a62a191daf0fff27>@@
.?AV<lambda_337593ad4f874bae98bb3aa9ea22758d>@@
.?AV<lambda_ee954de93bf759bd8b1f4b4c9716ded3>@@
.?AV<lambda_e4fd1e1090be16100e1685f2f4877667>@@
.?AV<lambda_95aae9bbb822c713ca9677b3a07b3381>@@
.?AV<lambda_50ac1bbabd41636fda9e1bf36b1fc455>@@
.?AV<lambda_65379b8fe5c982ca5593c72a9026c7e8>@@
.P6AMMMM@Z
.?AV<lambda_2f3c8dfb82c3078faed3c459500f6cd5>@@
.?AV<lambda_3410038a349fbad62fb0cd42ca2fc595>@@
.?AV<lambda_0f2ad18a551e793a8bddf1de1dc21689>@@
.?AV<lambda_9cf24a11d7a47ec83a2235f766fd2a5c>@@
.?AV<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@
.?AV<lambda_d63de458c7355252fdf7dac6af546a6c>@@
.?AU?$default_delete@VIAllocator@onnxruntime@@@std@@
.?AU?$default_delete@VBFCArena@onnxruntime@@@std@@
.?AV<lambda_8811b8e0b984fa7408be2a8e645ea91e>@@
.?AV<lambda_f7fefea6bfb8182e95c707a77e7f4a8f>@@
.?AV<lambda_535c714f3912f6e19812f86aced1c234>@@
.?AV<lambda_d77ac61f6238a68ec5589d982d5615ac>@@
.?AV<lambda_e1a8783767138f2900763c385a76ace5>@@
.?AV<lambda_9188795b2d63d4fadeae802c62453f68>@@
.?AV<lambda_23cd650266f5b996762e121f69bcde45>@@
.?AV<lambda_a191614639fd357df18cb9db7ec0bbb0>@@
.?AV<lambda_d05c3c022071d814f376085832823fd8>@@
.?AV<lambda_46f2340c6974a9abf9bf427b63a5b9bc>@@
.?AV<lambda_3d53fdafdcab72e11f157b0377fe813b>@@
.?AV<lambda_70dd8648671da4762d31e7f5cb99db35>@@
.?AV<lambda_f05e941e43878b26850ba9c86261d871>@@
.?AV<lambda_c21643d1fb44758b12325da46a2d32c5>@@
.?AV<lambda_4404716c35945f1da6a07154c932397d>@@
.?AV<lambda_d5d62f4b858abcded92348c54a906570>@@
.?AV<lambda_1123ca3288c22333dcfbc6780e56f3b6>@@
.?AV<lambda_957302132dd7fea31b11af321304eee3>@@
.?AV<lambda_9de7ed3747c068fd694551112d802911>@@
.?AV<lambda_76259788010337ce84c7523a6ac9ea2f>@@
.?AV<lambda_c7328f9d78ba121fe15792ce469c1b69>@@
.?AV<lambda_3863377c4067e3a3117e9e245fcb11f1>@@
.?AV<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>@@
.?AV<lambda_f663e1cb5f92583d40a80c3711b532b4>@@
.?AV<lambda_9a9b192dcae6874632669a18925ebf5e>@@
.?AV<lambda_d8e8fb9b3d14cba6be93e2f77767d47a>@@
.?AV<lambda_5861f1c440cc9e376f7e9d4be12a7211>@@
.?AV<lambda_da7b70169c4d0c30b25c92beb94d63ae>@@
.?AV<lambda_59a791f3e63b70edef38fb68dcebe7ec>@@
.?AV<lambda_c007df17e8115f08c5c6e2ce7e2201c0>@@
.?AV<lambda_e318b9a1ac6011cec45976779008bc1d>@@
.P6A?AVStatus@common@onnxruntime@@AEBVNode@2@AEAVGraph@2@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV56@AEBUResolveOptions@42@@Z
.?AUPriorityNodeCompare@onnxruntime@@
.?AV<lambda_0457fc55cb15f22bdcba75f54e0aa1c1>@@
.?AUNodeCompare@onnxruntime@@
.?AV<lambda_a047e4fa7a019da5da5dcb5093bd2da9>@@
.?AV<lambda_0a3d98e003a8310444f50c395f4ee870>@@
.?AV<lambda_02a8234b34a60137e169504412a1f413>@@
.?AV<lambda_c39fd5c6fac165bf428d70a08e4c8f15>@@
.?AV<lambda_e5264339f7df0674b92961d30b5a7ffa>@@
.?AV<lambda_59fa69d97a341ecc9726a25d2543c4ff>@@
.?AV<lambda_89acb1907ff24a2b752ebe76d28b2b79>@@
.?AV<lambda_6c857460828ce55880a8ee13df644424>@@
.?AV<lambda_21f2ebef859bbaf3ad57fb860d7bd5a6>@@
.?AV<lambda_b6c01241d8af757add895871e0bda6b2>@@
.?AV<lambda_d6b1ae38293f8956d8614f7fd42d8be1>@@
.?AV<lambda_96b6749a5bd8eb049fa653bd6c986087>@@
.?AV<lambda_0c24edbe84bc491fb6a29a020f4d3aa5>@@
.?AV<lambda_5061ec701805e08c70a11faeac892816>@@
.?AV<lambda_f2de741e38c166518c2010e724b68513>@@
.?AV<lambda_adcf8be8a94343086b930752e64c0b0f>@@
.?AV<lambda_9f96fff69aa6e4d3c160f75385bed764>@@
.?AV<lambda_ef5c424a4193a85193eb7ea4c70aae69>@@
.?AV<lambda_a8b00e76dfe980214923eafc43926fd4>@@
.?AV<lambda_5837c21ac5ed4b7ba5939ba692f3a2cd>@@
.?AV<lambda_fc1c3f3352c8b4d29b9f843047cd4c91>@@
.?AV<lambda_cf601ebc85517f1e503d9f32197b5b17>@@
.?AV<lambda_efd47e41ca57d95ede53a33e8845ee3a>@@
.?AV<lambda_0127cc6c89895d74380b7c79a5b9fb82>@@
.?AV<lambda_94eb456bb6dd50ea434b460dd28415e2>@@
.?AV<lambda_7807cde4d0ef8224ba8270c9901bf983>@@
.?AV<lambda_95ba9287d9318e63f29052645b806916>@@
.?AV<lambda_860b5cff89ff5f292872db2aaa19c52a>@@
.?AV<lambda_7ab6b48869ceb01d1e728c1066baabd3>@@
.?AV<lambda_ec14091c8d829910b5be28a833d6a3dd>@@
.?AV<lambda_4913db8c05460fd84e03b1ef7ec1a215>@@
.?AV<lambda_dd92783c3b5068fe6d4b01b7a52eff87>@@
.?AV<lambda_53e6651898ab41a7609d88940da1a1cb>@@
.?AV<lambda_f88babf2ad8b675b7b86e082d193f4e3>@@
.?AV<lambda_84a2e50dc6af381ce5371c455f14a164>@@
.?AV<lambda_918223fcda849fef98116a4781c4f02e>@@
.?AV<lambda_bf3ede44b9863bac339552631fecea38>@@
.?AV<lambda_6e2f42e69c3f77b25a074e65f1eca470>@@
.?AV<lambda_147527a66291af5e3f9c1e417e66fd9c>@@
.?AV<lambda_885ce9bf676f456b6d4e77149ebef2ea>@@
.?AV<lambda_5329cb936988b5974a3a2ce900136f33>@@
.?AV<lambda_2ac171e27e2ef21b455a8883502f09aa>@@
.?AV<lambda_eae84d9e160bdd32110c79960a898549>@@
.?AV<lambda_0e85b1a3aa4aedfca1acdf52f931b8f2>@@
.?AV<lambda_8f5b5ae0f1d46d8c6eb147bbc6d3c96a>@@
.?AV<lambda_4e733be9ef1a8040b2cc0e98d09e233e>@@
.?AV<lambda_7db27467264314088f348a12ba91a5a9>@@
.?AV<lambda_27a06fd9b1f731a63767571c10bf29a4>@@
.?AV<lambda_c8957f10c145d7d78c010e1cb01ee7eb>@@
.?AV<lambda_8b7a180b7300a7362eece741d298bed3>@@
.?AV<lambda_5fda51538eb73549320e6236b953b0c5>@@
.?AV<lambda_1ea1e7671a1665ca234eb6cc181c60bb>@@
.?AV<lambda_d3857f49b3e4107314682ca90a39ea61>@@
.?AV<lambda_a931912cfcdf336ec0429a60e07a6cf5>@@
.?AV<lambda_f958ba65e401c00d0ddfa815d235fd3f>@@
.?AV<lambda_f92d41c84d566f3577a74275e60ee3bc>@@
.?AV<lambda_3fbfdfe39393a610cb9132779b271854>@@
.?AV<lambda_3b79ba1930d9045b1d0a1c3e7b558aa7>@@
.P6A?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV01@0@Z
.?AV<lambda_bcef20d2b13b7b49fdebd823a7e734e1>@@
.P6AXAEAVOpSchema@onnx@@@Z
.?AV<lambda_581e172f6e6bf6d53a792d4f2adbb4c0>@@
.?AV<lambda_f0be09c6ec8e17e7ac33afa3db53ce78>@@
.?AV<lambda_680b87823779380f32485d5ed8cbcf84>@@
.?AV<lambda_c2fef1cfbd08e9e21bcb74b985df87e6>@@
.?AV<lambda_a7a0686f23e7f9337eaa10f069ee321b>@@
.?AV<lambda_9289ae269610356b68d5c3f46e89bf66>@@
.?AV<lambda_9a122db8c0c6f400c116ad5d2cdaf0bc>@@
.?AV<lambda_08db83bf9ac8665fc4de47cb08668b85>@@
.?AVinvalid_argument@std@@
.?AV<lambda_6cceb9a81b349eec63834bf776269859>@@
.?AV<lambda_539862c5b8039ccfff5acf2ed512ba97>@@
.?AV<lambda_3361a7c3c06ae8fda0091b29a15bc377>@@
.?AVResultException@wil@@
.?AV<lambda_1c511d989171b0ae840c900d36af6cdf>@@
.?AV<lambda_ad8ca076531a0e62bdc4758313aec8ec>@@
.?AV<lambda_7ecdffb9bc3f419b33196d548224f0a4>@@
.?AV<lambda_0b4cc153b058489c05500d0b394c47a0>@@
.?AV<lambda_9dd547f200315c70f4064d52aef7ac6e>@@
.?AV<lambda_68d1128749cbe2edd5a4d05aa87c891c>@@
.?AV<lambda_5033badb7240167b30b90523bec68adf>@@
.?AV<lambda_3525a67688acab3a16549c70f50b343d>@@
.?AVValidationError@checker@onnx@@
.?AV<lambda_59d0c8449581e17e31aa5d36d4e1dfcc>@@
.?AV<lambda_5fe773ac1f878f81aadf16bc155901d0>@@
.?AV<lambda_abb9581c367ec240a8c0e5afd8181e99>@@
.?AV<lambda_be82f0d3082d1770e6fe9b6560ab180a>@@
.?AV<lambda_c6cc7a538d9c817426d2f4671032805a>@@
.?AV<lambda_33763db33c7430e0074fd25b65b4479f>@@
.?AV<lambda_0af4c846dd5af6632beb77ffbd6469c9>@@
.?AV<lambda_aec81523952d967a50c07470b5814993>@@
.?AV<lambda_5c5ac1f6c71d812ad45802a5c8ea5757>@@
.?AV<lambda_fd266a9166d0b10d35a0d8f14994daa2>@@
.?AV<lambda_2e20e62e8d812957e92321838accac54>@@
.?AV<lambda_22aeb0e20ec618f43aaa785665edaa1d>@@
.?AV<lambda_1249aa664b6dd8c7cf40d23fbaec080e>@@
.?AV<lambda_458163864faccd230ccf1ce10d3e187d>@@
.?AV<lambda_6f010deb824d03b6370449d6f782b9da>@@
.P6A_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@1@AEAVFunctionProto@1@@Z
.?AV<lambda_58c18cbe2e241c86a9c2f0282cd3e9cd>@@
.?AV<lambda_2f4103e1c4a1773101a6c1f055d56df4>@@
.?AV<lambda_a4015e490e3e9078f9108a810d677815>@@
.?AV<lambda_c9fe283d46d2f293dcb8573f075d3809>@@
.?AV<lambda_d08789fec1ddb2ea31a7e42b01821aaa>@@
.?AV<lambda_43d76a454d7e446551a32b163679964a>@@
.?AV<lambda_9c03d71b3e2a72420d0112f6f3840dd4>@@
.?AV<lambda_27a631d2450c357a52927c1dfbd2efda>@@
.?AV<lambda_58fbb8df4116cc5ed49a05a90528c0bc>@@
.?AV<lambda_a345bf27d2a96610b3b006a123df813d>@@
.?AV<lambda_fbf4f22e77a262ac13623763b425fa95>@@
.?AV<lambda_922ea2af44b61076061b9738fd44abd8>@@
.?AV<lambda_fcf7b72cb8688ac639f6066c6f9347c9>@@
.?AV<lambda_fe5b044a59055ca66e7af958ee5f5bc3>@@
.?AV<lambda_51967558c7fd075e660195f4e6702ce2>@@
.?AV<lambda_8dc767ccba8e089e41f89b04cb108c10>@@
.?AV<lambda_7c61692eadeb4ccd34c8bb00529bfb83>@@
.?AV<lambda_6bb3fafba21860621ead2400f83d0ab0>@@
.?AV<lambda_655336b29940dd8dbdcd42ec2ee05996>@@
.?AV<lambda_0afff8b6c40408852605b1495798325e>@@
.?AV<lambda_9148a73a32272a5a33edca914c11c2a4>@@
.?AV<lambda_556d3d9e1da4d900ac4beace2594775f>@@
.?AV<lambda_fdb0134f4d01b5f723238dd45cc4059f>@@
.?AV<lambda_aa88e462824a3ef64606c92b2b205d10>@@
.?AV<lambda_6b0122b627329aed747a7281e017781a>@@
.?AV<lambda_4cd868df938477ea9946d2d55c43c695>@@
.?AV<lambda_727130accb380845b50f2c19a2b46d02>@@
.?AV<lambda_d3c7976f3f38539a50838a16dd62ccb2>@@
.?AV<lambda_6711c07c0f8ab9cb8e9a7125cbe3a01a>@@
.?AV<lambda_747f5a5054cea5042105b3988bb8e54a>@@
.?AV<lambda_7c393e0ced2515f63b0674de1e1229b1>@@
.?AV<lambda_6aeba50936d3f6c7b11f3c24b58165e0>@@
.?AV<lambda_006f042491572090b778a6887556c541>@@
.?AV<lambda_d2d693a490e9887da5a024c703dc8e3e>@@
.?AV<lambda_404d0fe71cc8d7867c9f1bc290b28bbd>@@
.?AV<lambda_2cdbc5f873c2ce32c36481fab53d6870>@@
.?AV<lambda_4bfaa77b47cc3b72c0199e4158dcfdd3>@@
.?AV<lambda_3050f982855d87e103d3099ed68136e7>@@
.?AV<lambda_a26d879b56b4c4dd33ee8f6ff5f1da50>@@
.?AV<lambda_bc30b190ccdc11003b68eaf48bc55331>@@
.?AV<lambda_66cabf3c04f8f57705ecc5d1dde38596>@@
.?AV<lambda_90811df5034c6b064f00ff028e410b34>@@
.?AV<lambda_af999ce2e03a2039dbf31c1ff13e0675>@@
.?AV<lambda_f20c684c9a749a148b4d30f212c71a01>@@
.?AV<lambda_c9e45910c6dad78e6e958bb0527b44e1>@@
.?AV<lambda_d655da6f0498ff82874b3d8a213ddf66>@@
.?AV<lambda_242966bc823a6ea57016299e4846b19a>@@
.?AV<lambda_ef1b5ee9690bf60d6d8ba03dec70f0fc>@@
.?AV<lambda_9cc2379234b917d77614797746e75684>@@
.?AV<lambda_b090b097d440a4b2445143675bf63aa8>@@
.?AV<lambda_0f569c3741dec4cbd25547f5cfa47a1f>@@
.?AV<lambda_13bf14abed62c4ddb7d24aa834c66cd3>@@
.?AV<lambda_8bbb4bb940b6248f0079a061cca5209e>@@
.?AV<lambda_a4fb1c1b5f905e04c31cbbe6c165878a>@@
.?AV<lambda_dec8978adb68f88cd37c14b215792fcb>@@
.?AV<lambda_6665c408830d0dff611752f43635ad2f>@@
.?AV<lambda_acdb2664af6229da1e4c43d330c314d8>@@
.?AV<lambda_45e1f6e47762148b282b3bb16964d9a7>@@
.?AV<lambda_5151cdb5e2d0e967b0ff9b516f4dde5e>@@
.?AV<lambda_08b89006bb2cd45177aec966a5a64a25>@@
.?AV<lambda_95cb1f26d899b1547c4804541e11a44a>@@
.?AV<lambda_845fb0d365668e61a65e09bae6280c09>@@
.?AV<lambda_36945aef9b69b8bc246158e60ded74ff>@@
.?AV<lambda_048b899a3305cb2c0c070dd18e5b4d17>@@
.?AV<lambda_af2c39467b4484bc2a2f611cf533daa7>@@
.?AV<lambda_4c81a7b179f9e26e2d05ebefbb83c381>@@
.?AV<lambda_cc9e076beb57119667e5b07bb3c48707>@@
.?AV<lambda_673e4ce19ce5833538c9ec8e56f2275c>@@
.?AV<lambda_522944c70ac483ca59ad2373ac030c86>@@
.?AV<lambda_7ca26f875a5bd8018609c044fb5616a1>@@
.?AV<lambda_6367df6aa050372a33bd7465b9bffebf>@@
.?AV<lambda_40f74427ec28f20a5d59b70a3f7ba162>@@
.?AV<lambda_913ebb992bc3e09bdf2737529cebbf5a>@@
.?AV<lambda_c2634be0290355aa32c42903b822d942>@@
.?AV<lambda_6105a132d5626ddb9b2ed4958c88e1e2>@@
.?AV<lambda_f9b942c519c5abdf8c9e76770faf15a7>@@
.?AV<lambda_64e20fef6bc734aa72d77b8028e3b077>@@
.?AV<lambda_d9adada7822ba67bc618dd6220c7e11e>@@
.?AV<lambda_2bed918e0092d38de095a3dfcc39bb6a>@@
.?AV<lambda_031e8dfd8d6a123502d9ec2194443e60>@@
.?AV<lambda_14ab4d68c965e23bff80a9edfde3b16e>@@
.?AV<lambda_577697c65f7f30ab5c890fb5e643c3c6>@@
.?AV<lambda_0ba48c1f3299a5f4228b96a5876e6f39>@@
.?AV<lambda_bea95f42caac40af3d5dbd854845ff13>@@
.?AV<lambda_6dd6cf995614bc7c2e490d548728e197>@@
.?AV<lambda_d30ba908d7a4df45178218a83c8b90aa>@@
.?AV<lambda_cfd05ce920f37ad131560f3f4ba5b162>@@
.?AV<lambda_40d7d549b7296d37bd8a375a6a32735f>@@
.?AV<lambda_da7c0e243075d823e83aad5424aee4f1>@@
.?AV<lambda_bb245b6c588ba3a259962707ee90e1f2>@@
.?AV<lambda_f1490410ee527b42f3bd28e691dae2a7>@@
.?AV<lambda_95d4c31e5917c076b85b93f005fcb675>@@
.?AV<lambda_3e5e22c83296c8f56ae7effebfec7009>@@
.?AV<lambda_cc810076352af54d8ab1334d58ef2ac8>@@
.?AV<lambda_4c0d5472c0e9893aea307d804bd55070>@@
.?AV<lambda_4ae79009ffed4baaf3b13205e614d6ec>@@
.?AV<lambda_50bf1563c4f2a658d5a1f8997cf7d841>@@
.?AV<lambda_90e67d7cf9c8fca59bac4a84fc304da2>@@
.?AV<lambda_e3ece229d743061e7008260e800aa786>@@
.?AV<lambda_b79d623619c8b488913a18719fb07ba7>@@
.?AV<lambda_1d7aed3977eb6b0e8500a44cbf6dc587>@@
.?AV<lambda_47f0845d7b66643be4c58515f34249ea>@@
.?AV<lambda_53687b87e8fc26669694bb154ed06213>@@
.?AV<lambda_85b8c9439e9295f048404909acdf29d3>@@
.?AV<lambda_486023130535c54dc87259934f24df6e>@@
.?AV<lambda_3354f944db7877754471d985be3fe29b>@@
.?AV<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@
.?AV<lambda_9a4c460641eeb4213d39e91aec522d90>@@
.?AV<lambda_be9619b5fb1d1db7cf718b1fda3d5e82>@@
.?AV<lambda_2369389c848e11c0cf2fa8c55ee9bc1b>@@
.?AV<lambda_0847b334bbfd42737aafe7ba61663e74>@@
.?AV<lambda_61155733672bad5b1a1677020dbf30f2>@@
.?AV<lambda_4b94da34bdfcb505ddcef5cb50b95e3d>@@
.?AV<lambda_a4ad4e98f1a94b9237ebaa976e8eb831>@@
.?AV<lambda_253a3836eec6c1ddbcb7d28211e21bd6>@@
.?AV<lambda_712b3a1726a5ab1ce39d1b3e7f50d979>@@
.?AV<lambda_4c0362c3e20008eb9ad4ca148d83f23f>@@
.?AV<lambda_b83bed438099179cd13c5a6033b90f7d>@@
.?AV<lambda_57b4e734a8f319c201f732e76dc19318>@@
.?AV<lambda_f01e87ef597d7dc3f33e6877997ee749>@@
.?AV<lambda_113fc5cdb3f9f5e45a498eccec03db60>@@
.?AV<lambda_1abf5a492f2ce98320288d0a19f9a732>@@
.?AV<lambda_b86aa8ef1de0593a5547f08d792c1565>@@
.?AV<lambda_d70c00502c59385fd81a95257fd26b78>@@
.?AV<lambda_dfdd7885f2409b865180b051dead44b8>@@
.?AV<lambda_62f1ce9bc208e37c7e5739c8f36388ed>@@
.?AV<lambda_6a3bd940152ae2677fd2b897f7b984e8>@@
.?AV<lambda_2bf767e58fd6076f82b597352ebe6a94>@@
.?AV<lambda_95e960d5e662fcb57840658a282318a0>@@
.?AV<lambda_510b48fcc953c4af1dbcb4b8cf19756a>@@
.?AV<lambda_1f77acb4e34034b00a5a2150384c9d77>@@
.?AV<lambda_874d535e153c7e2cc7bc8cf3f159ba49>@@
.?AV<lambda_16aeacf7ad4b53ba550defbc9c03abde>@@
.?AV<lambda_5e0f6565dc7aa7f6ebc79fe2fd37d8ea>@@
.?AV<lambda_f4d85bd911255cc25b789888dd092506>@@
.?AV<lambda_d6d6a472b26fc7f192d382e93bba1d57>@@
.?AV<lambda_65ea036252223d30a37862dfd4f7bc69>@@
.?AV<lambda_90a5aa05649581dcb39db34fc6f2962a>@@
.?AV<lambda_9c23f807f5b88acf4c74334fd51de3b9>@@
.?AV<lambda_c6a4c758ec4a05da2df0a96bda1f195f>@@
.?AV<lambda_b881ee6a3336741e3e3697374c374936>@@
.?AV<lambda_1e6c58f2c47fbfdcb340ca8aa595e354>@@
.?AV<lambda_03c53d5c540d06d25e58298bd3e2675f>@@
.?AV<lambda_348952d4e8cb4d6ca40b91f67d9fe4cc>@@
.?AV<lambda_3ce4407e5879111e6c1a6435d36077e4>@@
.?AV<lambda_d05a56d909a989a3c2db176db7149e23>@@
.?AV<lambda_c765ee4079d8132e5b64fd41ad2c9a7d>@@
.?AV<lambda_5e0adb550519bb305a282a49bc052ff5>@@
.?AV<lambda_d0fdf4211aa9516cbe57f435cdbb747f>@@
.?AV<lambda_8288630972d659cd373e2f56e7530b06>@@
.?AV<lambda_baa2815e04b51c513ad52e6ee2edd5e6>@@
.?AV<lambda_1f3bf02585dcf20edf66f391042bccc5>@@
.?AV<lambda_aecfda1830c0ee30e0e4a23c265062da>@@
.?AV<lambda_b6dee4d13517d8cf66ef1e240c3ec6a4>@@
.?AV<lambda_0031e1631721c75a1f7a0e71cb748ed7>@@
.?AV<lambda_dcbbb46dcb2ccb38f1b7e3e89a0ca172>@@
.?AV<lambda_2dc16cf30de15202e0434934c8ec0571>@@
.?AV<lambda_c9cc85b6189178098c01bbceb71ba127>@@
.?AV<lambda_f013722fb06ba87b6ded393d910c85c6>@@
.?AV<lambda_84e0d1c8300760043597f8486883bb16>@@
.?AV<lambda_68f8064281287c2a20e44f23c72be5d5>@@
.?AV<lambda_b0ef8716b08a7c90da37b162fe225b7a>@@
.?AV<lambda_bb618da91ef45dc5293c089a74c35488>@@
.?AV<lambda_82b38e81208f4cf45ccff9cab1f1ab56>@@
.?AV<lambda_5169332acacd2cda6014329563a49097>@@
.?AV<lambda_b0f9e3c706f87be7af57692823441e06>@@
.?AV<lambda_3e2860b55958cf532cc6672e843fd5e5>@@
.?AV<lambda_d8059ce711ce14c36533947d64fa5a34>@@
.?AV<lambda_bb1f7ff97f0a93bd0d62291fdf3e87e2>@@
.?AV<lambda_221457049dd6e599b1e592be3898266a>@@
.?AV<lambda_6bf7af48e7a4158e20b4f833c15de130>@@
.?AV<lambda_a6d62ed7a3aadce21a3a08f0b111f7e9>@@
.?AV<lambda_0b84cd883df2cf8f5da7751da99be58c>@@
.?AV<lambda_b4d34ceb4628d068b1d974c038b79a44>@@
.?AV<lambda_3bf9d7b5239a137326d2c5fa821fa737>@@
.?AV<lambda_88b1496ecc213c07fd24b30bb5c856e7>@@
.?AV<lambda_c277816ed3e96f001ac0003fb11da190>@@
.?AV<lambda_19a25a0e0bced01a01388502a5fb897a>@@
.?AV<lambda_965a3b769c39b0bedf189a3ea0545ea9>@@
.?AV<lambda_939f4702fdcc80c80258913a08838422>@@
.?AV<lambda_ee988755aabf6d6b8cbe1162f42f9b60>@@
.?AV<lambda_6d0547d7d9e564311a780ca9dc7db655>@@
.?AV<lambda_81de0b469ab0f1e7bc6d7cfef2665991>@@
.?AV<lambda_0a786afdc494302a03a8347211af4f5e>@@
.?AV<lambda_8a900b8b41180a41f1571bb2c4cf6f8e>@@
.?AV<lambda_91fdf8e96bd0363c4307fa79933bf9ee>@@
.?AV<lambda_3ad3f00f380cbc79acdede7031c2b35c>@@
.?AV<lambda_1642adc2d95a594ec2d1ca1c1679605d>@@
.?AV<lambda_1cdda74d195f4dc7bbdbaed3ee174bf7>@@
.?AV<lambda_f8ab3456636176a3e9c9876b6c4ed749>@@
.?AV<lambda_b24067cfb776b28c2465a46fad4c39cd>@@
.?AV<lambda_b3ffb2b19f45444139b13fc0568f9537>@@
.?AV<lambda_d86f3bcde641b4c18df519c60bc10d09>@@
.?AV<lambda_e6687d53b2ff8a73e462a3df53da446b>@@
.?AV<lambda_538a9c85037de841067641f3e5d92fd5>@@
.?AV<lambda_56054d16adda54f2046f2f8778fd36d1>@@
.?AV<lambda_58e45bcf81f2eb4f6ae6b3f124defb13>@@
.?AV<lambda_217211e0b9216fbae93bbaf0026e78ee>@@
.?AV<lambda_0a0326aaa0c17e1dc10459d8b6c3398c>@@
.?AV<lambda_28d76a4078a4a8dbd4ec44ed08d36b25>@@
.?AV<lambda_95797973064e7dd662318da5d5424fd6>@@
.?AV<lambda_20ce3835ea17537cf13d089eb1a443c1>@@
.?AV<lambda_1147aa6d38b42c0a8559813b3004180f>@@
.?AV<lambda_18e0b70d8d5a276d72055cc8661094dd>@@
.?AV<lambda_4e978ba75a8a0f3f4d2d1e75d74ac4de>@@
.?AV<lambda_ddcedb921562b53aaf13cbc0af192f90>@@
.?AV<lambda_64826d400df5e2683a863a4dbb954602>@@
.?AV<lambda_5bd441e42294bfab33849ec1b22ce125>@@
.?AV<lambda_d2aedfced5017e33ef2fd58df23b739b>@@
.?AV<lambda_5dddc316c01bb02791c37b03fa523bb0>@@
.?AV<lambda_6434b01e914b4662f3f5703792865f82>@@
.?AV<lambda_00b59445cb71ad9abff9006cdec65ab0>@@
.?AV<lambda_2d779c3a3c8b726adf3efb1bfd3cbb40>@@
.?AV<lambda_37fc46271b5a9d577e78557058b76819>@@
.?AV<lambda_06e5eb766e97cbbd1e9836fc044820b5>@@
.?AV<lambda_ddff9a77cb22aafff303a88b4705bee2>@@
.?AV<lambda_d73f309e1e17ba4988eef7d15e33e2b5>@@
.?AV<lambda_b1c0cff63caf505f6536baee30943a62>@@
.?AV<lambda_c4dc4b2967ca7204e8ba49b0607e0250>@@
.?AV<lambda_cd453f5abbb4020fb3775475830cd8d1>@@
.?AV<lambda_140ab31565a9f257f202ece6453c4bfd>@@
.?AV<lambda_1d718ae1c6eee88a5015989ae3eac075>@@
.?AV<lambda_52be072c62487a4543b8a1a3d2fbad23>@@
.?AV<lambda_e41de5887194c6f47359224ea1f4265d>@@
.?AV<lambda_a935037996bf9e3d7f1925320992d343>@@
.?AV<lambda_02cf852cc5a543f808433f03632ba155>@@
.?AV<lambda_aa831217bcc44892538d39aae8c330f6>@@
.?AV<lambda_9283763b81fbf1c4441399956127b6eb>@@
.?AV<lambda_2a976ac88d60c988f6c82762c8669484>@@
.?AV<lambda_62526b7eac31a4fea5091c2f348a5e23>@@
.?AV<lambda_9e7e71f1a8889f6f7faa45e435ef1f25>@@
.?AV<lambda_ab7fd2a16f2ab36f5c7b628818e71578>@@
.?AV<lambda_d7d65f11678621cb189879800cf53faf>@@
.?AV<lambda_9f22cccb787c8b0be66f7b40706128ae>@@
.?AV<lambda_a45f274125d5aab3ada44bd6d91ed7f6>@@
.?AV<lambda_53958a524045125d538038a834c170f9>@@
.?AV<lambda_1476157c6a284e4f379191854345eea5>@@
.?AV<lambda_0aa1cbb10b7e27c8eaa9e1c4d936a012>@@
.?AV<lambda_218f765d5b26dc460cf68e4f7ef3c8f7>@@
.?AV<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@
.P6AXAEAUDataPropagationContext@onnx@@@Z
.?AVZeroCopyInputStream@io@protobuf@google@@
.?AVZeroCopyOutputStream@io@protobuf@google@@
.?AV?$basic_stringbuf@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_streambuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_ostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ios@DU?$char_traits@D@std@@@std@@
.?AVios_base@std@@
.?AV?$_Iosb@H@std@@
.?AVCopyingInputStreamAdaptor@io@protobuf@google@@
.?AVCopyingOutputStreamAdaptor@io@protobuf@google@@
.?AVCopyingInputStream@io@protobuf@google@@
.?AVCopyingOutputStream@io@protobuf@google@@
.?AVFileInputStream@io@protobuf@google@@
.?AVCopyingFileInputStream@FileInputStream@io@protobuf@google@@
.?AVFileOutputStream@io@protobuf@google@@
.?AVCopyingFileOutputStream@FileOutputStream@io@protobuf@google@@
.?AVOstreamOutputStream@io@protobuf@google@@
.?AVCopyingOstreamOutputStream@OstreamOutputStream@io@protobuf@google@@
.?AVMessageLite@protobuf@google@@
.?AV?$basic_stringbuf@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_stringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_iostream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_istream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ios@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ostream@_WU?$char_traits@_W@std@@@std@@
.?AVtype_info@@
.?AV_Ref_count_base@std@@
.?AVIDataTransfer@onnxruntime@@
.?AVCPUDataTransfer@onnxruntime@@
.?AV?$_Func_base@XPEA_K@std@@
.?AV?$_Func_base@XPEAD@std@@
.?AV?$_Func_base@XPEAPEAUOrtValue@@@std@@
.?AV?$_Ref_count_obj2@VIAllocatorImplWrappingOrtAllocator@onnxruntime@@@std@@
.?AV?$_Ref_count_resource@PEAVIExecutionProvider@onnxruntime@@U?$default_delete@VIExecutionProvider@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3435a69bc2a4a58cf25c9601fa916799>@@XPEA_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6b9436f4089e82f5864d5365b56a5e02>@@XPEAD@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_78d2ff8fcf22c6166aa97abbb5fd0d75>@@XPEAPEAUOrtValue@@@std@@
.?AV?$_Ref_count_resource@PEAXP6AXPEAX@Z@std@@
.?AUOrtAllocatorImpl@onnxruntime@@
.?AUOrtAllocator@@
.?AUOrtDefaultCpuAllocator@@
.?AV?$_Func_base@_NH@std@@
.?AVISchemaRegistry@onnx@@
.?AVIOnnxRuntimeOpSchemaCollection@onnxruntime@@
.?AVOpKernel@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVFuncManager@3@AEBVOpKernelInfo@3@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AVOnnxRuntimeOpSchemaRegistry@onnxruntime@@
.?AUCustomOpKernel@onnxruntime@@
.?AV?$_Ref_count_obj2@VKernelRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VOnnxRuntimeOpSchemaRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VCustomRegistry@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ca87e505bf8a7e1f26579083c3683d94>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9bb5d71c29e163b6768bdebbeaa9ef83>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AVIAllocator@onnxruntime@@
.?AUOrtAllocatorImplWrappingIAllocator@onnxruntime@@
.?AVIAllocatorImplWrappingOrtAllocator@onnxruntime@@
.?AVCPUAllocator@onnxruntime@@
.?AUProviderHostImpl@onnxruntime@@
.?AUProviderHost@onnxruntime@@
.?AUNodeAttributes_Iterator@onnxruntime@@
.?AUTensorShapeProto_Dimension_Iterator@onnxruntime@@
.?AUNode__NodeIterator@onnxruntime@@
.?AUNode__EdgeIterator@onnxruntime@@
.?AUTensorShapeProto_Dimension_Iterator_Impl@onnxruntime@@
.?AUNodeAttributes_Iterator_Impl@onnxruntime@@
.?AUNode__NodeIterator_Impl@onnxruntime@@
.?AUNode__EdgeIterator_Impl@onnxruntime@@
.?AV?$basic_istringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_istream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_filebuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ifstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ofstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$_Func_base@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AVIExecutionProvider@onnxruntime@@
.?AVGraphTransformer@onnxruntime@@
.?AVExLibLoader@onnxruntime@@
.?AVInsertCastTransformer@onnxruntime@@
.?AVInferenceSession@onnxruntime@@
.?AVAllocator@flatbuffers@@
.?AVDefaultAllocator@flatbuffers@@
.?AVMemcpyTransformer@onnxruntime@@
.?AVCPUExecutionProvider@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVGraph@3@AEA_NAEAVIExecutionProvider@3@@std@@
.?AV?$_Ref_count_obj2@V?$unordered_map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@U?$hash@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@U?$equal_to@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@@std@@@2@@std@@@std@@
.?AV?$_Ref_count_obj2@VAllocatorManager@onnxruntime@@@std@@
.?AV?$_Ref_count_resource@PEAVCPUExecutionProvider@onnxruntime@@U?$default_delete@VCPUExecutionProvider@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVModel@onnxruntime@@U?$default_delete@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ba9cfe2bb13e49d1f5f6d627965891ec>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90fa7e4386c5622637b0b1880f5ca8f3>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b32e5f2bc2fafd58a4afcda5e8537c65>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEAVGraph@3@AEA_NAEBVIExecutionProvider@3@@ZV123@AEAV43@AEA_NAEAV53@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_165747221b83b97edb1c8980b4a934c8>@@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_739930acb5d4a4b1d92f387c9190b820>@@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c89e6783ea7ba65dd2bbca371d42018d>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AVISink@logging@onnxruntime@@
.?AVLoggingWrapper@@
.?AV?$basic_stringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_iostream@DU?$char_traits@D@std@@@std@@
.?AV?$_Func_base@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAUInferenceContext@onnx@@@ZXAEAU12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb296edf374db63a1fb223cbff2a45aa>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_80bd8f1476bc31a08ed6cb365cfefa4a>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33c11271a908f4f215dd361ca0be165e>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dcbbb9aee7454d5a0feb975df66a7001>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7965ceabe5f45db89655ad0a7fd04cd6>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_598c6d249dbd14226af8e69fe738f910>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_de00575298e9c7ead3b243890c596395>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18dbcf0a6112b471cd3435637c32f0f8>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_888c8332848e83c225ef5f5587c3b38e>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_daa97a08fba16356a015278e0f3ca1ed>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d522df09ab9335db57f0cfc8c09d6630>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8fef7dbb6b3e81cda489ebe45ab449bb>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ab7cc530eb49a3a15082dbc27eb613da>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b35f6304ab9b91e067de16d773b507fb>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_519fe9cae569b1ad1c3f73288fa352d4>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3a80fca790cdb0fce14ddaedefa20351>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0fb4e93f4014e9a9ed52287648f86c91>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_73cc642ed8afaa2889c4f09584fca345>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_716d92b2455b6dca0a3e195a50699167>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6922b57be4edd39a89a7cea9e2ebb658>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_28a69d198faef3db79470de4de6f53e9>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_194fafbac36b97ada7ff78b4fe337622>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6025d7753fe49dfa6ce58be5196bf75>@@X$$QEAVOpSchema@onnx@@@std@@
.?AVRemoveDuplicateCastTransformer@onnxruntime@@
.?AVRewriteRule@onnxruntime@@
.?AVRuleBasedGraphTransformer@onnxruntime@@
.?AVNhwcTransformer@onnxruntime@@
.?AVQDQFinalCleanupTransformer@onnxruntime@@
.?AVAttentionFusion@onnxruntime@@
.?AVBiasDropoutFusion@onnxruntime@@
.?AVBiasGeluFusion@onnxruntime@@
.?AVBiasSoftmaxFusion@onnxruntime@@
.?AVCastElimination@onnxruntime@@
.?AVCommonSubexpressionElimination@onnxruntime@@
.?AVConvAddFusion@onnxruntime@@
.?AVConvBNFusion@onnxruntime@@
.?AVConvMulFusion@onnxruntime@@
.?AVDivMulFusion@onnxruntime@@
.?AVEliminateDropout@onnxruntime@@
.?AVDynamicQuantizeMatMulFusion@onnxruntime@@
.?AVEmbedLayerNormFusion@onnxruntime@@
.?AVExpandElimination@onnxruntime@@
.?AVFastGeluFusion@onnxruntime@@
.?AVGeluApproximation@onnxruntime@@
.?AVGeluFusion@onnxruntime@@
.?AVGemmActivationFusion@onnxruntime@@
.?AVGemmSumFusion@onnxruntime@@
.?AVGemmTransposeFusion@onnxruntime@@
.?AVEliminateIdentity@onnxruntime@@
.?AVLayerNormFusion@onnxruntime@@
.?AVSimplifiedLayerNormFusion@onnxruntime@@
.?AVMatMulAddFusion@onnxruntime@@
.?AVMatMulIntegerToFloatFusion@onnxruntime@@
.?AVMatMulScaleFusion@onnxruntime@@
.?AVMatmulTransposeFusion@onnxruntime@@
.?AVNchwcTransformer@onnxruntime@@
.?AVNoopElimination@onnxruntime@@
.?AVNotWhereFusion@onnxruntime@@
.?AVClipQuantFusion@onnxruntime@@
.?AVQDQPropagationTransformer@onnxruntime@@
.?AVQDQS8ToU8Transformer@onnxruntime@@
.?AVReluQuantFusion@onnxruntime@@
.?AVFuseReluClip@onnxruntime@@
.?AVReshapeFusion@onnxruntime@@
.?AVSkipLayerNormFusion@onnxruntime@@
.?AVEliminateSlice@onnxruntime@@
.?AVTransposeOptimizer@onnxruntime@@
.?AVUnsqueezeElimination@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNodeArg@3@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61a830e6f94472550f401a07bc054c29>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f8f4a9a0b8865f5f39e8ba472bf52edc>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_055b4d24f8a1f4b549310d8384e8330c>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AVTensorRef@api@onnx_layout_transformation@@
.?AVValueInfoRef@api@onnx_layout_transformation@@
.?AVNodeRef@api@onnx_layout_transformation@@
.?AVGraphRef@api@onnx_layout_transformation@@
.?AVApiValueInfo@onnxruntime@@
.?AVApiTensor@onnxruntime@@
.?AVApiNode@onnxruntime@@
.?AVApiGraph@onnxruntime@@
.?AUAction@onnxruntime@@
.?AURemoveNodes@onnxruntime@@
.?AUReplaceWithNew@onnxruntime@@
.?AUNodeSelector@onnxruntime@@
.?AVConvActivationFusion@onnxruntime@@
.?AVSelectorActionTransformer@onnxruntime@@
.?AVConvActivation@selectors@?A0xe2853e69@onnxruntime@@
.?AVConvAddRelu@selectors@?A0xe2853e69@onnxruntime@@
.?AVFuseConvActivation@actions@?A0xe2853e69@onnxruntime@@
.?AVFuseConvAddRelu@actions@?A0xe2853e69@onnxruntime@@
.?AUMergeIntoTarget@onnxruntime@@
.?AVQDQSelectorActionTransformer@onnxruntime@@
.?AVNodeGroupSelector@QDQ@onnxruntime@@
.?AVDropQDQNodeGroupSelector@QDQ@onnxruntime@@
.?AVDropDQNodeGroupSelector@QDQ@onnxruntime@@
.?AVUnaryNodeGroupSelector@QDQ@onnxruntime@@
.?AVBinaryNodeGroupSelector@QDQ@onnxruntime@@
.?AVVariadicNodeGroupSelector@QDQ@onnxruntime@@
.?AVConvNodeGroupSelector@QDQ@onnxruntime@@
.?AVMatMulNodeGroupSelector@QDQ@onnxruntime@@
.?AVGemmNodeGroupSelector@QDQ@onnxruntime@@
.?AVBaseSelector@QDQ@onnxruntime@@
.?AVDropQDQNodesSelector@QDQ@onnxruntime@@
.?AVDropDQNodesSelector@QDQ@onnxruntime@@
.?AVUnarySelector@QDQ@onnxruntime@@
.?AVBinarySelector@QDQ@onnxruntime@@
.?AVVariadicSelector@QDQ@onnxruntime@@
.?AVConvSelector@QDQ@onnxruntime@@
.?AVMatMulSelector@QDQ@onnxruntime@@
.?AVGemmSelector@QDQ@onnxruntime@@
.?AVConstantFolding@onnxruntime@@
.?AV?$_Func_base@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_adedb98ee19cb4d9a4a46a5fd17584b5>@@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AVFreeDimensionOverrideTransformer@onnxruntime@@
.?AV?$_Func_base@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@VGraphConstantInitializerGetter@?A0x9d9d0a9c@onnxruntime@@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AUReplaceWithNewFixed@onnxruntime@@
.?AUQDQReplaceWithNew@QDQ@onnxruntime@@
.?AUReplaceWithQLinear@QDQ@onnxruntime@@
.?AUUnaryReplaceWithQLinear@QDQ@onnxruntime@@
.?AUBinaryReplaceWithQLinear@QDQ@onnxruntime@@
.?AUVariadicReplaceWithQLinear@QDQ@onnxruntime@@
.?AUConvReplaceWithQLinear@QDQ@onnxruntime@@
.?AUMatMulReplaceWithQLinear@QDQ@onnxruntime@@
.?AUGemmReplaceWithQuant@QDQ@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c47a842a4ad24719aaf09edc25c7aef>@@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2c978ff584bacbceac7be3bb080e51e>@@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AVOptimizerExecutionFrame@onnxruntime@@
.?AVIExecutionFrame@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_4de083bd9feef97ef116b9ac6f248cfc>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AUIExecutionProviderFactory@onnxruntime@@
.?AUCpuProviderFactory@onnxruntime@@
.?AV?$_Ref_count_obj2@UCpuProviderFactory@onnxruntime@@@std@@
.?AUProviderHostCPU@onnxruntime@@
.?AUProviderHostCPUImpl@onnxruntime@@
.?AVTranspose@onnxruntime@@
.?AVTransposeBase@onnxruntime@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEAVFuncManager@3@AEBVOpKernelInfo@3@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@ZV123@AEAV43@AEBV53@AEAV67@@std@@
.?AVGather@onnxruntime@@
.?AVGatherBase@onnxruntime@@
.?AV?$_Func_base@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a7f558f1dd0bc6dfbc34073d8010b2d2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9ad4dd46fb7ebf522a3e85e715143745>@@X_J_J@std@@
.?AVUnsqueeze@onnxruntime@@
.?AVUnsqueezeBase@onnxruntime@@
.?AVClip@onnxruntime@@
.?AV?$Clip_6@M@onnxruntime@@
.?AV?$Clip_6Base@M@clip_internal@onnxruntime@@
.?AU?$ElementWiseRangedTransform@M@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$LeakyRelu@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Relu@M@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@N@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Relu@N@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@C@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@H@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sigmoid@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sigmoid@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Tanh@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Tanh@N@functors@onnxruntime@@@onnxruntime@@
.?AU?$ParametricSoftplus@M@functors@onnxruntime@@
.?AU?$ScaledTanh@M@functors@onnxruntime@@
.?AV?$_Func_impl_no_alloc@U?$Tanh@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Tanh@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sigmoid@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sigmoid@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Relu@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Relu@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$LeakyRelu@M@functors@onnxruntime@@X_J_J@std@@
.?AVPow@onnxruntime@@
.?AV?$Add@M@onnxruntime@@
.?AV?$Add@N@onnxruntime@@
.?AV?$Add@H@onnxruntime@@
.?AV?$Add@_J@onnxruntime@@
.?AV?$Sub@M@onnxruntime@@
.?AV?$Sub@N@onnxruntime@@
.?AV?$Sub@H@onnxruntime@@
.?AV?$Sub@_J@onnxruntime@@
.?AV?$Mul@M@onnxruntime@@
.?AV?$Mul@N@onnxruntime@@
.?AV?$Mul@H@onnxruntime@@
.?AV?$Mul@_J@onnxruntime@@
.?AV?$Div@M@onnxruntime@@
.?AV?$Div@N@onnxruntime@@
.?AV?$Div@H@onnxruntime@@
.?AV?$Div@_J@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@C@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@F@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@F@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@H@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@_J@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@_J@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@E@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@E@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@G@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@G@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@I@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@I@functors@onnxruntime@@@onnxruntime@@
.?AU?$ElementWiseRangedTransform@_K@functors@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@_K@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Floor@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Reciprocal@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Reciprocal@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sqrt@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sqrt@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Exp@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Exp@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$Sum_8@M@onnxruntime@@
.?AV?$Sum_8@N@onnxruntime@@
.?AV?$Less@M@onnxruntime@@
.?AV?$Less@N@onnxruntime@@
.?AV?$Less@H@onnxruntime@@
.?AV?$Less@_J@onnxruntime@@
.?AV?$Greater@M@onnxruntime@@
.?AV?$Greater@N@onnxruntime@@
.?AV?$Greater@H@onnxruntime@@
.?AV?$Greater@_J@onnxruntime@@
.?AV?$Equal@_N@onnxruntime@@
.?AV?$Equal@H@onnxruntime@@
.?AV?$Equal@_J@onnxruntime@@
.?AV?$Equal@M@onnxruntime@@
.?AV?$Equal@N@onnxruntime@@
.?AV?$Erf@M@onnxruntime@@
.?AV?$PRelu@M@onnxruntime@@
.?AV?$Expand_8@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_95dd41682914710e4e8d31623057e7d3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Exp@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Exp@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sqrt@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sqrt@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Reciprocal@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Reciprocal@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Floor@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@_K@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@I@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@G@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@E@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@_J@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@H@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@F@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@C@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_13046178b359e9c81742cfc406e97a28>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_23a1bb0478ab7117c6dff4712434f02b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_acccfeb1e0041e26bf01c6097464f8c5>@@X_J_J@std@@
.?AV?$Hardmax@M@onnxruntime@@
.?AV?$Softmax@M@onnxruntime@@
.?AV?$Softmax@N@onnxruntime@@
.?AV?$Conv@M@onnxruntime@@
.?AVMaxPoolV8@onnxruntime@@
.?AVPoolBase@onnxruntime@@
.?AV?$Pool@MVAveragePool@onnxruntime@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@E@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@E@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@E@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@C@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@C@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@C@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@N@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@N@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@N@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@M@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@M@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@M@onnxruntime@@X_J_J@std@@
.?AV?$ReduceKernel@$00@onnxruntime@@
.?AV?$ReduceKernelBase@$00@onnxruntime@@
.?AV?$ReduceKernel@$0A@@onnxruntime@@
.?AV?$ReduceKernelBase@$0A@@onnxruntime@@
.?AV?$ReduceLogSumExp@M@onnxruntime@@
.?AV?$ReduceLogSumExp@H@onnxruntime@@
.?AV?$ReduceLogSumExp@N@onnxruntime@@
.?AV?$ReduceMax@M@onnxruntime@@
.?AV?$ReduceMax@H@onnxruntime@@
.?AV?$ReduceMax@_J@onnxruntime@@
.?AV?$ReduceMax@N@onnxruntime@@
.?AV?$ReduceMax@C@onnxruntime@@
.?AV?$ReduceMax@E@onnxruntime@@
.?AV?$ReduceMean@M@onnxruntime@@
.?AV?$ReduceMean@H@onnxruntime@@
.?AV?$ReduceMean@N@onnxruntime@@
.?AV?$ReduceMin@M@onnxruntime@@
.?AV?$ReduceMin@H@onnxruntime@@
.?AV?$ReduceMin@_J@onnxruntime@@
.?AV?$ReduceMin@N@onnxruntime@@
.?AV?$ReduceSum@M@onnxruntime@@
.?AV?$ReduceSum@H@onnxruntime@@
.?AV?$ReduceSum@_J@onnxruntime@@
.?AV?$ReduceSum@N@onnxruntime@@
.?AV?$ArgMax@M@onnxruntime@@
.?AV?$ArgMax@H@onnxruntime@@
.?AV?$ArgMax@C@onnxruntime@@
.?AV?$ArgMax@E@onnxruntime@@
.?AV?$ArgMax@N@onnxruntime@@
.?AV?$_Func_base@NPEBN@std@@
.?AV?$_Func_base@XAEANPEBN_J@std@@
.?AV?$_Func_base@_JPEB_J@std@@
.?AV?$_Func_base@XAEA_JPEB_J_J@std@@
.?AV?$_Func_base@HPEBH@std@@
.?AV?$_Func_base@XAEAHPEBH_J@std@@
.?AV?$_Func_base@MPEBM@std@@
.?AV?$_Func_base@XAEAMPEBM_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5032e4da5cc3197800498a50f18978ca>@@NPEBN@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fc2c6db54ba2969b0c3aebde05d3921d>@@XAEANPEBN_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af13a0a68d606e99765e2f7bd840b2f7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3acaf4e71a87bfb836a528474a23b2b9>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_19653ee275cc0117099f6e46319415af>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6c8ff4cf86b60687891fce83403bcfe>@@_JPEB_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d1b650f23fa7659d3b2735ce4ed580e4>@@XAEA_JPEB_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa268cbc0b0d4966ec51ad17dda0ec82>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5fa3956cb796f4fb0ed4cc8ce896bcf4>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e128163c41b62dbd7415427042732d90>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_44094649bc82ecb2fc1ec6afdbc202d7>@@HPEBH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b9c72854712561eaa1748a5213a8f880>@@XAEAHPEBH_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_191f334b7e6fbfb2860cdf729a487dba>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_621fbd8d0cbcf0a8f4c51871d816bf2f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9bcf543f98218e465d42a5f7a449290e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_20a837f51a15ec806ec07fe236459bf3>@@MPEBM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4f02b89eec40e1f508d9a8a5576d7ee8>@@XAEAMPEBM_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6cda9f0816757e5a4d291ef9c3329fae>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cfafdf587dd99b527f40f2a9bbc4721a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bf8017c8b0b3ab5a242f82899957cda>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b547b93cbe3e16cfc4195284dfd5eaef>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e79b149fca88b77c33b72523d605d32a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bcb1ddbded281b4b93a8d23384ad316>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_28c42d729a2f53041e8b22b1ed6cdff0>@@X_J_J@std@@
.?AV?$_Func_base@EPEBE@std@@
.?AV?$_Func_base@XAEAEPEBE_J@std@@
.?AV?$_Func_base@CPEBC@std@@
.?AV?$_Func_base@XAEACPEBC_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c51e5beef5cfad81c8e2b8d3dd04a4a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9444b9c3df22cd88603cfb31f51cceb7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9b63af4b3b6c6dd79d915ddcfe92473d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3723f23b8a34d9d98e7ee4d14fc03d1b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d132db5c486427a93d54120da48d5ea6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b88ca2272a912106e48e54848e61d223>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dbdf3737eb2cb2871abd98870dad8484>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a0f363c6d35242db2945bd981d31d01b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6353a4d545858b8902fbb038d252087>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_601c95e3fba8a34ac8d24c850c4e911b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8d1cbd61cf9e0403bbdc22c2b23b0de2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3e80eabb3a9d111992ebd5907a12e903>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_581b6d14e5adbd13737160d24e40c605>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d085624eed89d70192230e9a1f62c5a7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a179296bb96622fe30c41b2986ab7695>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_12237f9b9f786fa2f677523e51689677>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_70539968d61afd98aa9c406314f181bf>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_678560984ac7af19a5b63edeab48a227>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7331cae3c69c0d5b155ee357c1007837>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a51dc28255d67c31f47c2a37cec4d4e4>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f418dafe297dbbe0e3ada3e20a715a40>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c23a6e376db7c7388aa04e9eb8ee3aca>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_67b6bf510365b722acc4b67b8d30f927>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_265c7b3426b87aef377811f8829e6fd7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cf886ef71e61e28cd5fd0d3055f9efbe>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9b3108d194a09162f36c1b6ecbe4bd22>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b3e04491343c2b41488666814183e8a7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ca42e3f2ca4d6bbcd7bf706226d12a4c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18f6d57bac34239d650ddbef707551e4>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ea5f658f0d872dbd3ae3afb1f1fd1122>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cb7393b1270049ba922f1a24832dd162>@@NPEBN@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a367ed868a5821659948b0a337825f5>@@XAEANPEBN_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cba067a26cf21de5d0e68b8b6f37fe8f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_11c15110a2869c43f5467753b7474409>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ed67f482bebf565f55f04daede9ac63d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_24ac27632a899010d1e56f7da8454199>@@_JPEB_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f59689bb1f16cb74228cd5fe68f4cabe>@@XAEA_JPEB_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7a2681e4ada46acb33dd1adb547c252>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_339ccdd8cf9a471a2525280227358fe6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_06e28cef24f38d1ecd4447df16780ad3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3cfedd26cd9ef5f4cd0322b54223b692>@@HPEBH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b62b9616dd6208ed1baf09034b8ca175>@@XAEAHPEBH_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6ae1de67e6e99002a693271defb4e48d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e252e05424c33acac940c2f481ad24ee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61cda506a6bb2ddf6aa949685eb7c77c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_578472dc2e9e27345d825b47aca036a6>@@MPEBM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59fb7201bedc86d0ed85da074d1993f3>@@XAEAMPEBM_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d5d46741b892946aacca2ea22e630eea>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_994ac64fe4673357a711f942252cee0c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_79f470cac7ca56067b4bc354acf028f6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_409a8ec0de4403e02d09bb9a4b937276>@@EPEBE@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3ae9af8a84288cef25a7cf83bd0834fa>@@XAEAEPEBE_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_46087cac4b4384e4406cfa052cc4f414>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_243c848b67147a62f5be9d25d42a217b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_91f296869b04eedc9f496835c423da26>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b70c471f0d6c3603fdf76e6ccfb54a3>@@CPEBC@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9e35eefcb137cd146c958ca877000a5d>@@XAEACPEBC_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_89d3c68acc787e643b03eef066fea4d2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_368acd23d928f0f5d2e3ced50c09e50c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d88752c7e7055eb8ee4749bbd38c2e1a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5178fbfdb12cb266aaef66d97a4a2fc5>@@NPEBN@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e65b3d84cc1ebbac94bfd47d08839322>@@XAEANPEBN_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8f6bf12e356c17071a18123d1fef52d6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_887dae5249605a4edc99e39f2a0adf15>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2abf8115bf6da52b8610764cf48ee0f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_761421d99b53ea1d25ac65996497fbea>@@_JPEB_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5933cfcb3215128b0a25c0614f75da87>@@XAEA_JPEB_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_de173f36c1a40fc38c17fd4d3151fc18>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc71ada574b25d74a4c48413625b90d1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8f306720719e22494f4df721d014f49>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40d9bd0925a189b8d1c995cd48d17d39>@@HPEBH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b609acf5869a906202c2ec8d4f323bb0>@@XAEAHPEBH_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3aac6f1c979a8b893423e58931ed2daa>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f8420b50886667bda26b0e8f59183bf>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_72aab4f7a75329bf9825db841274d3a3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f77770976f2f1ea63d04f11ed8ae8858>@@MPEBM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1efd3ecb51119ba3eba8bc9319f01386>@@XAEAMPEBM_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a2ae5f61cc20c1ab03a30ab181749eea>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eeeed7b40e814a0e70cf05a3907bbf81>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee8bcd2d07e1fd45b1c55d57b7556b9f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_101e0d486e161cfbbc4332cd98f3239a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b0bbca98147f2b1d98b75bc68203f51>@@X_J_J@std@@
.?AVDeepCpuGruOp@onnxruntime@@
.?AV?$_Func_base@XPEAH@std@@
.?AV?$_Func_base@XPEAM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0aeb3b3202e2e34a7d6b98b623e6a327>@@XPEAM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b765106161737954a77d8a171216f44e>@@XPEAH@std@@
.?AVDeepCpuLstmOp@onnxruntime@@
.?AVLSTMBase@onnxruntime@@
.?AVCast@?A0xf3e57488@onnxruntime@@
.?AVConcat@onnxruntime@@
.?AVConcatBase@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa638f082cd6e633ea8c394e1663fa60>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b92cd1be17f8632fbcc9dec212afe76b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2c19ae18917b59844dd4110518387dd>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c8779530b1b47f6b819a3c840cb70825>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4f04249e04d07d50d630e12dc9f30f23>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f0ea35f12b551ef953688db40e1f4b34>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bbfc6268021e2bfd0f1bd3e4700889b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f563daf0e095e96808b0280be50284eb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1a286ef6a47f06b31852d582b51b4ff5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ab076180da33c991061bdac15a41448d>@@X_J_J@std@@
.?AV?$IdentityOp@$00@onnxruntime@@
.?AV?$IdentityOp@$0A@@onnxruntime@@
.?AVReshape@onnxruntime@@
.?AVShape@onnxruntime@@
.?AUSlice1@onnxruntime@@
.?AVSliceBase@onnxruntime@@
.?AUSlice10@onnxruntime@@
.?AVSplit@onnxruntime@@
.?AVSplitBase@onnxruntime@@
.?AVSqueeze@onnxruntime@@
.?AVSqueezeBase@onnxruntime@@
.?AUTile@onnxruntime@@
.?AV?$Expand@M@onnxruntime@@
.?AV?$Expand@N@onnxruntime@@
.?AV?$Expand@C@onnxruntime@@
.?AV?$Expand@F@onnxruntime@@
.?AV?$Expand@H@onnxruntime@@
.?AV?$Expand@_J@onnxruntime@@
.?AV?$Expand@E@onnxruntime@@
.?AV?$Expand@G@onnxruntime@@
.?AV?$Expand@I@onnxruntime@@
.?AV?$Expand@_K@onnxruntime@@
.?AV?$Expand@_N@onnxruntime@@
.?AV?$Expand@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_3f0ef66d0b0de67b55e854d697da2fff>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd4f2bbf00caf507fea1cc6053ab984e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1fd04ff7ed408ca4ebed6e8107f19670>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d0c5713ac46ee06d27e6324a463b7bee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b9ad0ccbf56c00a46342640cba7cdc2c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f30a6117225d3cb8e4a11f826263726e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c646dd14edaacae64487e0b96ad575f5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b97251de202434e86d007c33f9345a1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e08a75ecff8a2a27b308be3f8dfddc66>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d48cb9baeb37d51a45fff2e006fd2ed3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_42580b4f3e49f7dcfbf37d76233bd856>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_310ceee0e4c58a7a83d7d00319ed9410>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9800a6d45ddc69dc425addf83da8e9e3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0251dfdaad61cfa5b2a46c99b78d27e8>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e1a7abf114b955966097bd83c14de705>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33215563a6aacb86deff746a6aa28a6c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6e3cb65d29853e95007cf81c805209f2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e77a57374f1e055f8281ce5dd65e8ebd>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5820733bf712edf4856ad2454498e68c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_115059020db09aa13bab825ad518034e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_30e1101d7025e2d839d1daa9ac434cd1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_786b2ff03846fcfa21d00bf234deaff2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6c91c6f34bd8327dc22f6b7f8735fd5b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f8675d15ee5efaa8f5579945c6d118a>@@X_J_J@std@@
.?AVConstantOfShape@?A0x34ff6731@onnxruntime@@
.?AV?$ConstantOfShapeBase@U?$TypeList@_JUMLFloat16@onnxruntime@@MNCFHEGI_K_N@onnxruntime@@@onnxruntime@@
.?AVIControlFlowKernel@controlflow@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@PEAX_K@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBV?$span@$$CB_K@gsl@@AEBVTensor@3@AEAV63@@std@@
.?AV?$_Func_base@V?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J_J@std@@
.?AV?$_Func_base@V?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J_J@std@@
.?AVIterator@?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@
.?AV?$Scan@$08@onnxruntime@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J1@ZV12@AEBU3@_J_J@std@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J1@ZV12@AEAU3@_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c13e222993d6446f9d97d9b8d2341e0>@@VStatus@common@onnxruntime@@AEBV?$span@$$CB_K@gsl@@AEBVTensor@4@AEAV74@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f619f3ff08e9e7659a763308b991cbe>@@VStatus@common@onnxruntime@@PEAX_K@std@@
.?AV?$Where@E@onnxruntime@@
.?AV?$Where@H@onnxruntime@@
.?AV?$Where@_J@onnxruntime@@
.?AV?$Where@M@onnxruntime@@
.?AV?$Where@N@onnxruntime@@
.?AV?$Where@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$Gemm@M@onnxruntime@@
.?AVGemmBase@onnxruntime@@
.?AV?$Gemm@N@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bd02c7b372889e26c922fb97a0c9ac3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bbed65651851398ae9e91eb41072a5f9>@@X_J_J@std@@
.?AV?$MatMul@M@onnxruntime@@
.?AV?$MatMul@N@onnxruntime@@
.?AV?$MatMul@H@onnxruntime@@
.?AV?$MatMul@_J@onnxruntime@@
.?AV?$DequantizeLinear@C@onnxruntime@@
.?AV?$DequantizeLinear@E@onnxruntime@@
.?AV?$DequantizeLinear@H@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_e7ad5c511f7f0ca88484948ab82410f1>@@X_J_J@std@@
.?AVMatMulIntegerBase@onnxruntime@@
.?AVMatMulInteger@onnxruntime@@
.?AVConvInteger@onnxruntime@@
.?AV?$CumSum@M@onnxruntime@@
.?AV?$CumSum@N@onnxruntime@@
.?AV?$CumSum@H@onnxruntime@@
.?AV?$CumSum@_J@onnxruntime@@
.?AV?$Round@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Round@M@onnxruntime@@
.?AV?$Round@N@onnxruntime@@
.?AV?$DynamicQuantizeLinear@E@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_86dd40270c718f299cd5113909653b31>@@X_J_J@std@@
.?AVIf@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVTensorShape@3@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_91a43e75998e3a49d1905d29f4a7bae4>@@VStatus@common@onnxruntime@@AEBVTensorShape@4@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AVScatterND@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_70b1e1dcbe48b81893d8f59a8144faf6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fa46dd69454a850b787307a9d6678e80>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_41bb79d9c7cc8f02e2f871c5095cf1ee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_464e1f80ac51d01e54b77145fd34c5bb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59d0f05394547c6e0e03de3b8b189e7d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59efc6d2c00331cc0701da5f7ba31f88>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2830e7879c71bbb5a2447c8cce82dc3b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_534716bd90e3d628f36025c4e60922bb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_773e80e25f547e476dbfdd43767644cb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cefaaa440fbc31a737d643cd7070b2a7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53001c91fe43da87bd732d9a4fb0e358>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7872c9b42ef54f352452eac083f3a35>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0e4160f1c09428b722c89257b1bbabcb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_712a327d31152b694fd95674c69e7447>@@X_J_J@std@@
.?AV?$_Func_base@X_J@std@@
.?AVGatherElements@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_06471b7954288b9dda9f9d99a72bb7c6>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef9ce4d0dc32ab06ddd4426fedb787f1>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8e2d345faf08aedb7570dd988fdca755>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eb887415aed41a3927a754246db16d35>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f273d4d4788dd6d522544c26d76a5ae4>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9dc7af5c7bcff785bd9190f2cb464b36>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6744a0008aca8ce8a0b29db8f1c01fa1>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ae0d8b5a2da4af67276477f8d17abe42>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8b96520499b24df75ab37992af46b4d>@@X_J@std@@
.?AVRange@onnxruntime@@
.?AV?$TopK@$0L@M@onnxruntime@@
.?AV?$TopK@$0L@N@onnxruntime@@
.?AV?$TopK@$0L@H@onnxruntime@@
.?AV?$TopK@$0L@_J@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_8f0d91faf2fd476a9a61179d9b72837d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8ffce33af8696a7a42fa073f6875aacb>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a3f9f19c48a100998729328075237dc>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03e7406b29b220fa131a6585ce48dcd2>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8205a59784c4f81abae5636754370a87>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88f211d79a091f6a481688e49635f453>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1221b4097effa32a8dd388b4455dd2c1>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51f7b34ad2d14ff9bfb03559ccadc81f>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33ab9233a6e2a6fe6c24d1963cbc3111>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88cacdca8b660ada94d8f522e9f11bdd>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f8dbfaed9d55440bb15cbf009ac934a6>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_038eb253b7f4e93118566e43dda81530>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7b13e0aa9183a7266252ed7dbdd54f99>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ecc9b9120eb4793427a94169f5623a5b>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_11002e821957b929b79aa649ecf0a381>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc7060560dae87f5475ce357b0faca8e>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a32f11f3f6edc3a900d9d34015d67705>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f2842527842316c8394eef731b560fea>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b2b5b00a4ad3647a9a40b4f0dbb0745d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6728963f8bb91595df67d14c61fd8fa>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f55fed088cc6887bf534564a0809769f>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_72e83488395612e0f6a2602b726a187c>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cd5cfe6b76bb3ba1c53203d58a4eedd>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a1b033c1238f74f04d136673bf3141a7>@@X_J@std@@
.?AVReorderInput@contrib@onnxruntime@@
.?AVReorderOutput@contrib@onnxruntime@@
.?AVNchwcConv@contrib@onnxruntime@@
.?AVNchwcMaxPool@contrib@onnxruntime@@
.?AVNchwcPoolBase@contrib@onnxruntime@@
.?AVNchwcAveragePool@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_e69e76386d33ec96f42e27fde06de5c2>@@X_J@std@@
.?AVMLAS_QGEMM_OUTPUT_PROCESSOR@@
.?AVMLAS_QGEMM_SCALE_BIAS_OUTPUT_PROCESSOR@@
.?AVMatMulIntegerToFloatBase@contrib@onnxruntime@@
.?AVDynamicQuantizeMatMul@contrib@onnxruntime@@
.?AVMatMulIntegerToFloat@contrib@onnxruntime@@
.?AVDynamicQuantizeLSTM@contrib@onnxruntime@@
.?AVFusedConvFloat@contrib@onnxruntime@@
.?AV?$FusedGemm@M@contrib@onnxruntime@@
.?AV?$BiasGelu@M$0A@@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_4092000fa2c851eb2ddefc1b6efbf1fc>@@X_J@std@@
.?AV?$Gelu@M@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_95c74ffd32a4d994a62a191daf0fff27>@@X_J@std@@
.?AV?$LayerNorm@M$0A@@contrib@onnxruntime@@
.?AV?$LayerNorm@M$00@contrib@onnxruntime@@
.?AV?$LayerNorm@N$0A@@contrib@onnxruntime@@
.?AV?$LayerNorm@N$00@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_95aae9bbb822c713ca9677b3a07b3381>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e4fd1e1090be16100e1685f2f4877667>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee954de93bf759bd8b1f4b4c9716ded3>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_337593ad4f874bae98bb3aa9ea22758d>@@X_J@std@@
.?AV?$SkipLayerNorm@M@contrib@onnxruntime@@
.?AV?$SkipLayerNorm@N@contrib@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_65379b8fe5c982ca5593c72a9026c7e8>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_50ac1bbabd41636fda9e1bf36b1fc455>@@X_J@std@@
.?AV?$_Func_base@MMMM@std@@
.?AV?$_Func_impl_no_alloc@P6AMMMM@ZMMMM@std@@
.?AVIterator@?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_2f3c8dfb82c3078faed3c459500f6cd5>@@VStatus@common@onnxruntime@@AEBVTensorShape@4@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_base@XPEAE@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f2ad18a551e793a8bddf1de1dc21689>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3410038a349fbad62fb0cd42ca2fc595>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9cf24a11d7a47ec83a2235f766fd2a5c>@@XPEAE@std@@
.?AVDataTypeImpl@onnxruntime@@
.?AVTensorTypeBase@onnxruntime@@
.?AVSparseTensorTypeBase@onnxruntime@@
.?AVSequenceTensorTypeBase@onnxruntime@@
.?AVNonTensorTypeBase@onnxruntime@@
.?AVOptionalTypeBase@onnxruntime@@
.?AVPrimitiveDataTypeBase@onnxruntime@@
.?AV?$_Func_base@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$TensorType@H@onnxruntime@@
.?AV?$TensorType@M@onnxruntime@@
.?AV?$TensorType@_N@onnxruntime@@
.?AV?$TensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$TensorType@C@onnxruntime@@
.?AV?$TensorType@E@onnxruntime@@
.?AV?$TensorType@G@onnxruntime@@
.?AV?$TensorType@F@onnxruntime@@
.?AV?$TensorType@_J@onnxruntime@@
.?AV?$TensorType@N@onnxruntime@@
.?AV?$TensorType@I@onnxruntime@@
.?AV?$TensorType@_K@onnxruntime@@
.?AV?$TensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SparseTensorType@H@onnxruntime@@
.?AV?$SparseTensorType@M@onnxruntime@@
.?AV?$SparseTensorType@_N@onnxruntime@@
.?AV?$SparseTensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$SparseTensorType@C@onnxruntime@@
.?AV?$SparseTensorType@E@onnxruntime@@
.?AV?$SparseTensorType@G@onnxruntime@@
.?AV?$SparseTensorType@F@onnxruntime@@
.?AV?$SparseTensorType@_J@onnxruntime@@
.?AV?$SparseTensorType@N@onnxruntime@@
.?AV?$SparseTensorType@I@onnxruntime@@
.?AV?$SparseTensorType@_K@onnxruntime@@
.?AV?$SparseTensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SparseTensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceTensorType@M@onnxruntime@@
.?AV?$SequenceTensorType@N@onnxruntime@@
.?AV?$SequenceTensorType@C@onnxruntime@@
.?AV?$SequenceTensorType@E@onnxruntime@@
.?AV?$SequenceTensorType@F@onnxruntime@@
.?AV?$SequenceTensorType@G@onnxruntime@@
.?AV?$SequenceTensorType@H@onnxruntime@@
.?AV?$SequenceTensorType@I@onnxruntime@@
.?AV?$SequenceTensorType@_J@onnxruntime@@
.?AV?$SequenceTensorType@_K@onnxruntime@@
.?AV?$SequenceTensorType@_N@onnxruntime@@
.?AV?$SequenceTensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$SequenceTensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SequenceTensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@H@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@M@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@_N@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@C@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@E@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@G@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@F@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@_J@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@N@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@I@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@_K@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@UMLFloat16@2@@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@UBFloat16@2@@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@H@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@M@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@_N@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@C@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@E@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@G@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@F@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@_J@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@N@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@I@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@_K@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@UMLFloat16@2@@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@UBFloat16@2@@onnxruntime@@
.?AV?$PrimitiveDataType@H@onnxruntime@@
.?AV?$PrimitiveDataType@M@onnxruntime@@
.?AV?$PrimitiveDataType@_N@onnxruntime@@
.?AV?$PrimitiveDataType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$PrimitiveDataType@C@onnxruntime@@
.?AV?$PrimitiveDataType@E@onnxruntime@@
.?AV?$PrimitiveDataType@G@onnxruntime@@
.?AV?$PrimitiveDataType@F@onnxruntime@@
.?AV?$PrimitiveDataType@_J@onnxruntime@@
.?AV?$PrimitiveDataType@N@onnxruntime@@
.?AV?$PrimitiveDataType@I@onnxruntime@@
.?AV?$PrimitiveDataType@_K@onnxruntime@@
.?AV?$PrimitiveDataType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$PrimitiveDataType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_base@XPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d63de458c7355252fdf7dac6af546a6c>@@XPEAX@std@@
.?AVIExecutor@onnxruntime@@
.?AVSequentialExecutor@onnxruntime@@
.?AVOpKernelContext@onnxruntime@@
.?AV?$_Ref_count_resource@PEAVBFCArena@onnxruntime@@U?$default_delete@VBFCArena@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8811b8e0b984fa7408be2a8e645ea91e>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_base@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e1a8783767138f2900763c385a76ace5>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d77ac61f6238a68ec5589d982d5615ac>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_535c714f3912f6e19812f86aced1c234>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f7fefea6bfb8182e95c707a77e7f4a8f>@@X_K_K@std@@
.?AVISequentialPlannerContext@onnxruntime@@
.?AVSequentialPlannerContext@onnxruntime@@
.?AV?$_Func_base@V?$shared_ptr@VIAllocator@onnxruntime@@@std@@HW4OrtMemType@@@std@@
.?AV?$_Func_base@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@HAEBUOrtValue@@AEBUOrtCallback@3@_N_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d05c3c022071d814f376085832823fd8>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a191614639fd357df18cb9db7ec0bbb0>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_23cd650266f5b996762e121f69bcde45>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9188795b2d63d4fadeae802c62453f68>@@VStatus@common@onnxruntime@@HAEBUOrtValue@@AEBUOrtCallback@4@_N_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_46f2340c6974a9abf9bf427b63a5b9bc>@@V?$shared_ptr@VIAllocator@onnxruntime@@@std@@HW4OrtMemType@@@std@@
.?AVBFCArena@onnxruntime@@
.?AVFunctionKernel@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_f05e941e43878b26850ba9c86261d871>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_70dd8648671da4762d31e7f5cb99db35>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3d53fdafdcab72e11f157b0377fe813b>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AVExecutionFrame@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_c21643d1fb44758b12325da46a2d32c5>@@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_base@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_957302132dd7fea31b11af321304eee3>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1123ca3288c22333dcfbc6780e56f3b6>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d5d62f4b858abcded92348c54a906570>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4404716c35945f1da6a07154c932397d>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_base@X$$V@std@@
.?AVParallelExecutor@onnxruntime@@
.?AVOpKernelContextInternal@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_9de7ed3747c068fd694551112d802911>@@X$$V@std@@
.?AVExecutionPlanBase@onnxruntime@@
.?AUSequentialExecutionPlan@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_c7328f9d78ba121fe15792ce469c1b69>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_76259788010337ce84c7523a6ac9ea2f>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3863377c4067e3a3117e9e245fcb11f1>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AVITensorAllocator@onnxruntime@@
.?AVTensorAllocatorWithMemPattern@onnxruntime@@
.?AVSimpleTensorAllocator@onnxruntime@@
.?AV?$_Func_impl_no_alloc@V<lambda_f663e1cb5f92583d40a80c3711b532b4>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_base@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@PEAXPEBUOrtApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5861f1c440cc9e376f7e9d4be12a7211>@@VStatus@common@onnxruntime@@PEAXPEBUOrtApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8e8fb9b3d14cba6be93e2f77767d47a>@@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a9b192dcae6874632669a18925ebf5e>@@XPEAX@std@@
.?AVGraphInferencer@onnx@@
.?AUInferenceContext@onnx@@
.?AUFunctionBodyBuildContext@onnx@@
.?AUFunctionBodyBuildContextImpl@onnx@@
.?AVGraph@onnxruntime@@
.?AVGraphInferencerImpl@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@AEBUResolveOptions@53@@std@@
.?AVInferenceContextImpl@onnxruntime@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVGraph@3@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@AEBUResolveOptions@53@@ZV123@AEBV43@AEAV53@AEBV67@AEAV67@AEBU853@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e318b9a1ac6011cec45976779008bc1d>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c007df17e8115f08c5c6e2ce7e2201c0>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59a791f3e63b70edef38fb68dcebe7ec>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_da7b70169c4d0c30b25c92beb94d63ae>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_base@_N_K@std@@
.?AV?$_Func_base@_NPEBVNode@onnxruntime@@PEBV12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a3d98e003a8310444f50c395f4ee870>@@_N_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a047e4fa7a019da5da5dcb5093bd2da9>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@UNodeCompare@onnxruntime@@_NPEBVNode@2@PEBV32@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0457fc55cb15f22bdcba75f54e0aa1c1>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@UPriorityNodeCompare@onnxruntime@@_NPEBVNode@2@PEBV32@@std@@
.?AVSchemaRegistryManager@onnxruntime@@
.?AV?$_Ref_count_obj2@VSchemaRegistryManager@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VModel@onnxruntime@@@std@@
.?AVNhwcInferenceContext@contrib@onnxruntime@@
.?AV?$_Func_base@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6c857460828ce55880a8ee13df644424>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_89acb1907ff24a2b752ebe76d28b2b79>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59fa69d97a341ecc9726a25d2543c4ff>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e5264339f7df0674b92961d30b5a7ffa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c39fd5c6fac165bf428d70a08e4c8f15>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_02a8234b34a60137e169504412a1f413>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a8b00e76dfe980214923eafc43926fd4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef5c424a4193a85193eb7ea4c70aae69>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9f96fff69aa6e4d3c160f75385bed764>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_adcf8be8a94343086b930752e64c0b0f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f2de741e38c166518c2010e724b68513>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5061ec701805e08c70a11faeac892816>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0c24edbe84bc491fb6a29a020f4d3aa5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_96b6749a5bd8eb049fa653bd6c986087>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d6b1ae38293f8956d8614f7fd42d8be1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6c01241d8af757add895871e0bda6b2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_21f2ebef859bbaf3ad57fb860d7bd5a6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@2@AEAVFunctionProto@2@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0127cc6c89895d74380b7c79a5b9fb82>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_efd47e41ca57d95ede53a33e8845ee3a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cf601ebc85517f1e503d9f32197b5b17>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fc1c3f3352c8b4d29b9f843047cd4c91>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5837c21ac5ed4b7ba5939ba692f3a2cd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1ea1e7671a1665ca234eb6cc181c60bb>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5fda51538eb73549320e6236b953b0c5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8b7a180b7300a7362eece741d298bed3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c8957f10c145d7d78c010e1cb01ee7eb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_27a06fd9b1f731a63767571c10bf29a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7db27467264314088f348a12ba91a5a9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4e733be9ef1a8040b2cc0e98d09e233e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8f5b5ae0f1d46d8c6eb147bbc6d3c96a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0e85b1a3aa4aedfca1acdf52f931b8f2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eae84d9e160bdd32110c79960a898549>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2ac171e27e2ef21b455a8883502f09aa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5329cb936988b5974a3a2ce900136f33>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_885ce9bf676f456b6d4e77149ebef2ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_147527a66291af5e3f9c1e417e66fd9c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6e2f42e69c3f77b25a074e65f1eca470>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bf3ede44b9863bac339552631fecea38>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_918223fcda849fef98116a4781c4f02e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_84a2e50dc6af381ce5371c455f14a164>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f88babf2ad8b675b7b86e082d193f4e3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53e6651898ab41a7609d88940da1a1cb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dd92783c3b5068fe6d4b01b7a52eff87>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4913db8c05460fd84e03b1ef7ec1a215>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ec14091c8d829910b5be28a833d6a3dd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ab6b48869ceb01d1e728c1066baabd3>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_860b5cff89ff5f292872db2aaa19c52a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95ba9287d9318e63f29052645b806916>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7807cde4d0ef8224ba8270c9901bf983>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_94eb456bb6dd50ea434b460dd28415e2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f958ba65e401c00d0ddfa815d235fd3f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a931912cfcdf336ec0429a60e07a6cf5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d3857f49b3e4107314682ca90a39ea61>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@I_K@std@@
.?AV?$_Func_base@U?$Offset@UNodeIndexAndKernelDefHash@fbs@onnxruntime@@@flatbuffers@@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3fbfdfe39393a610cb9132779b271854>@@I_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f92d41c84d566f3577a74275e60ee3bc>@@U?$Offset@UNodeIndexAndKernelDefHash@fbs@onnxruntime@@@flatbuffers@@_K@std@@
.?AVFunction@onnxruntime@@
.?AVFunctionImpl@onnxruntime@@
.?AVViewerFunctionImpl@onnxruntime@@
.?AVGraphInferencerImpl@shape_inference@onnx@@
.?AUInferenceContextImpl@shape_inference@onnx@@
.?AV?$_Func_base@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV12@AEBV12@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV12@0@ZV12@AEBV12@AEBV12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b79ba1930d9045b1d0a1c3e7b558aa7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a7a0686f23e7f9337eaa10f069ee321b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2fef1cfbd08e9e21bcb74b985df87e6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_680b87823779380f32485d5ed8cbcf84>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f0be09c6ec8e17e7ac33afa3db53ce78>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_581e172f6e6bf6d53a792d4f2adbb4c0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAVOpSchema@onnx@@@ZXAEAV12@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bcef20d2b13b7b49fdebd823a7e734e1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9289ae269610356b68d5c3f46e89bf66>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a122db8c0c6f400c116ad5d2cdaf0bc>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08db83bf9ac8665fc4de47cb08668b85>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6cceb9a81b349eec63834bf776269859>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_539862c5b8039ccfff5acf2ed512ba97>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3361a7c3c06ae8fda0091b29a15bc377>@@X_J@std@@
.?AVerror_category@std@@
.?AV_Generic_error_category@std@@
.?AV_System_error_category@std@@
.?AVEnvThread@onnxruntime@@
.?AVWindowsThread@?A0x6f1db497@onnxruntime@@
.?AVWindowsEnv@?A0x6f1db497@onnxruntime@@
.?AVEnv@onnxruntime@@
.?AVThreadPoolInterface@Eigen@@
.?AVExtendedThreadPoolInterface@concurrency@onnxruntime@@
.?AV?$ThreadPoolTempl@VEnv@onnxruntime@@@concurrency@onnxruntime@@
.?AV?$_Func_base@XI@std@@
.?AV?$_Func_base@_N$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_68d1128749cbe2edd5a4d05aa87c891c>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9dd547f200315c70f4064d52aef7ac6e>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b4cc153b058489c05500d0b394c47a0>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ecdffb9bc3f419b33196d548224f0a4>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ad8ca076531a0e62bdc4758313aec8ec>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c511d989171b0ae840c900d36af6cdf>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3525a67688acab3a16549c70f50b343d>@@_N$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5033badb7240167b30b90523bec68adf>@@X$$V@std@@
.?AVWOStreamSink@logging@onnxruntime@@
.?AVCLogSink@logging@onnxruntime@@
.?AVTelemetry@onnxruntime@@
.?AVWindowsTelemetry@onnxruntime@@
.?AVfacet@locale@std@@
.?AV_Facet_base@std@@
.?AU_Crt_new_delete@std@@
.?AV?$numpunct@D@std@@
.?AVWindowsEnvTime@?A0x936fa4c5@onnxruntime@@
.?AVEnvTime@onnxruntime@@
.?AVOpSchemaRegistry@onnx@@
.?AV?$_Func_impl_no_alloc@V<lambda_59d0c8449581e17e31aa5d36d4e1dfcc>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fe5b044a59055ca66e7af958ee5f5bc3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fcf7b72cb8688ac639f6066c6f9347c9>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_922ea2af44b61076061b9738fd44abd8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fbf4f22e77a262ac13623763b425fa95>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a345bf27d2a96610b3b006a123df813d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58fbb8df4116cc5ed49a05a90528c0bc>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_27a631d2450c357a52927c1dfbd2efda>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c03d71b3e2a72420d0112f6f3840dd4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_43d76a454d7e446551a32b163679964a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d08789fec1ddb2ea31a7e42b01821aaa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9fe283d46d2f293dcb8573f075d3809>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4015e490e3e9078f9108a810d677815>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2f4103e1c4a1773101a6c1f055d56df4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58c18cbe2e241c86a9c2f0282cd3e9cd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@P6A_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@2@AEAVFunctionProto@2@@Z_NAEBU12@AEBV32@AEAV42@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f010deb824d03b6370449d6f782b9da>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_458163864faccd230ccf1ce10d3e187d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1249aa664b6dd8c7cf40d23fbaec080e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_22aeb0e20ec618f43aaa785665edaa1d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2e20e62e8d812957e92321838accac54>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd266a9166d0b10d35a0d8f14994daa2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5c5ac1f6c71d812ad45802a5c8ea5757>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aec81523952d967a50c07470b5814993>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0af4c846dd5af6632beb77ffbd6469c9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33763db33c7430e0074fd25b65b4479f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6cc7a538d9c817426d2f4671032805a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_be82f0d3082d1770e6fe9b6560ab180a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_abb9581c367ec240a8c0e5afd8181e99>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5fe773ac1f878f81aadf16bc155901d0>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_655336b29940dd8dbdcd42ec2ee05996>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bb3fafba21860621ead2400f83d0ab0>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c61692eadeb4ccd34c8bb00529bfb83>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8dc767ccba8e089e41f89b04cb108c10>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51967558c7fd075e660195f4e6702ce2>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6711c07c0f8ab9cb8e9a7125cbe3a01a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d3c7976f3f38539a50838a16dd62ccb2>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_727130accb380845b50f2c19a2b46d02>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4cd868df938477ea9946d2d55c43c695>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6b0122b627329aed747a7281e017781a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa88e462824a3ef64606c92b2b205d10>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fdb0134f4d01b5f723238dd45cc4059f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_556d3d9e1da4d900ac4beace2594775f>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9148a73a32272a5a33edca914c11c2a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0afff8b6c40408852605b1495798325e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9cc2379234b917d77614797746e75684>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef1b5ee9690bf60d6d8ba03dec70f0fc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_242966bc823a6ea57016299e4846b19a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d655da6f0498ff82874b3d8a213ddf66>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9e45910c6dad78e6e958bb0527b44e1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f20c684c9a749a148b4d30f212c71a01>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af999ce2e03a2039dbf31c1ff13e0675>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90811df5034c6b064f00ff028e410b34>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_66cabf3c04f8f57705ecc5d1dde38596>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bc30b190ccdc11003b68eaf48bc55331>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a26d879b56b4c4dd33ee8f6ff5f1da50>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3050f982855d87e103d3099ed68136e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bfaa77b47cc3b72c0199e4158dcfdd3>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2cdbc5f873c2ce32c36481fab53d6870>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_404d0fe71cc8d7867c9f1bc290b28bbd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2d693a490e9887da5a024c703dc8e3e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_006f042491572090b778a6887556c541>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6aeba50936d3f6c7b11f3c24b58165e0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c393e0ced2515f63b0674de1e1229b1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_747f5a5054cea5042105b3988bb8e54a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc810076352af54d8ab1334d58ef2ac8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3e5e22c83296c8f56ae7effebfec7009>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95d4c31e5917c076b85b93f005fcb675>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f1490410ee527b42f3bd28e691dae2a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb245b6c588ba3a259962707ee90e1f2>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_da7c0e243075d823e83aad5424aee4f1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40d7d549b7296d37bd8a375a6a32735f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cfd05ce920f37ad131560f3f4ba5b162>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d30ba908d7a4df45178218a83c8b90aa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6dd6cf995614bc7c2e490d548728e197>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bea95f42caac40af3d5dbd854845ff13>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0ba48c1f3299a5f4228b96a5876e6f39>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_577697c65f7f30ab5c890fb5e643c3c6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_14ab4d68c965e23bff80a9edfde3b16e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_031e8dfd8d6a123502d9ec2194443e60>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bed918e0092d38de095a3dfcc39bb6a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d9adada7822ba67bc618dd6220c7e11e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_64e20fef6bc734aa72d77b8028e3b077>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f9b942c519c5abdf8c9e76770faf15a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6105a132d5626ddb9b2ed4958c88e1e2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2634be0290355aa32c42903b822d942>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_913ebb992bc3e09bdf2737529cebbf5a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40f74427ec28f20a5d59b70a3f7ba162>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6367df6aa050372a33bd7465b9bffebf>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ca26f875a5bd8018609c044fb5616a1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_522944c70ac483ca59ad2373ac030c86>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_673e4ce19ce5833538c9ec8e56f2275c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc9e076beb57119667e5b07bb3c48707>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c81a7b179f9e26e2d05ebefbb83c381>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af2c39467b4484bc2a2f611cf533daa7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_048b899a3305cb2c0c070dd18e5b4d17>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_36945aef9b69b8bc246158e60ded74ff>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_845fb0d365668e61a65e09bae6280c09>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95cb1f26d899b1547c4804541e11a44a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08b89006bb2cd45177aec966a5a64a25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5151cdb5e2d0e967b0ff9b516f4dde5e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_45e1f6e47762148b282b3bb16964d9a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_acdb2664af6229da1e4c43d330c314d8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6665c408830d0dff611752f43635ad2f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dec8978adb68f88cd37c14b215792fcb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fb1c1b5f905e04c31cbbe6c165878a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8bbb4bb940b6248f0079a061cca5209e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_13bf14abed62c4ddb7d24aa834c66cd3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f569c3741dec4cbd25547f5cfa47a1f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b090b097d440a4b2445143675bf63aa8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90e67d7cf9c8fca59bac4a84fc304da2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_50bf1563c4f2a658d5a1f8997cf7d841>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4ae79009ffed4baaf3b13205e614d6ec>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c0d5472c0e9893aea307d804bd55070>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1d7aed3977eb6b0e8500a44cbf6dc587>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b79d623619c8b488913a18719fb07ba7>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e3ece229d743061e7008260e800aa786>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dfdd7885f2409b865180b051dead44b8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d70c00502c59385fd81a95257fd26b78>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b86aa8ef1de0593a5547f08d792c1565>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1abf5a492f2ce98320288d0a19f9a732>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_113fc5cdb3f9f5e45a498eccec03db60>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f01e87ef597d7dc3f33e6877997ee749>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_57b4e734a8f319c201f732e76dc19318>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b83bed438099179cd13c5a6033b90f7d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c0362c3e20008eb9ad4ca148d83f23f>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_712b3a1726a5ab1ce39d1b3e7f50d979>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_253a3836eec6c1ddbcb7d28211e21bd6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4ad4e98f1a94b9237ebaa976e8eb831>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4b94da34bdfcb505ddcef5cb50b95e3d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61155733672bad5b1a1677020dbf30f2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0847b334bbfd42737aafe7ba61663e74>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2369389c848e11c0cf2fa8c55ee9bc1b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_be9619b5fb1d1db7cf718b1fda3d5e82>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a4c460641eeb4213d39e91aec522d90>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3354f944db7877754471d985be3fe29b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_486023130535c54dc87259934f24df6e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_85b8c9439e9295f048404909acdf29d3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53687b87e8fc26669694bb154ed06213>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_47f0845d7b66643be4c58515f34249ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bf767e58fd6076f82b597352ebe6a94>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a3bd940152ae2677fd2b897f7b984e8>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_62f1ce9bc208e37c7e5739c8f36388ed>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c23f807f5b88acf4c74334fd51de3b9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90a5aa05649581dcb39db34fc6f2962a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_65ea036252223d30a37862dfd4f7bc69>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d6d6a472b26fc7f192d382e93bba1d57>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f4d85bd911255cc25b789888dd092506>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5e0f6565dc7aa7f6ebc79fe2fd37d8ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_16aeacf7ad4b53ba550defbc9c03abde>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_874d535e153c7e2cc7bc8cf3f159ba49>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f77acb4e34034b00a5a2150384c9d77>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_510b48fcc953c4af1dbcb4b8cf19756a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95e960d5e662fcb57840658a282318a0>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b0ef8716b08a7c90da37b162fe225b7a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_68f8064281287c2a20e44f23c72be5d5>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_84e0d1c8300760043597f8486883bb16>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f013722fb06ba87b6ded393d910c85c6>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9cc85b6189178098c01bbceb71ba127>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2dc16cf30de15202e0434934c8ec0571>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dcbbb46dcb2ccb38f1b7e3e89a0ca172>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0031e1631721c75a1f7a0e71cb748ed7>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6dee4d13517d8cf66ef1e240c3ec6a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aecfda1830c0ee30e0e4a23c265062da>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f3bf02585dcf20edf66f391042bccc5>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_baa2815e04b51c513ad52e6ee2edd5e6>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8288630972d659cd373e2f56e7530b06>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d0fdf4211aa9516cbe57f435cdbb747f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5e0adb550519bb305a282a49bc052ff5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c765ee4079d8132e5b64fd41ad2c9a7d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d05a56d909a989a3c2db176db7149e23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3ce4407e5879111e6c1a6435d36077e4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_348952d4e8cb4d6ca40b91f67d9fe4cc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03c53d5c540d06d25e58298bd3e2675f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1e6c58f2c47fbfdcb340ca8aa595e354>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b881ee6a3336741e3e3697374c374936>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6a4c758ec4a05da2df0a96bda1f195f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18e0b70d8d5a276d72055cc8661094dd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1147aa6d38b42c0a8559813b3004180f>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_20ce3835ea17537cf13d089eb1a443c1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95797973064e7dd662318da5d5424fd6>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_28d76a4078a4a8dbd4ec44ed08d36b25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a0326aaa0c17e1dc10459d8b6c3398c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_217211e0b9216fbae93bbaf0026e78ee>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58e45bcf81f2eb4f6ae6b3f124defb13>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_56054d16adda54f2046f2f8778fd36d1>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_538a9c85037de841067641f3e5d92fd5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e6687d53b2ff8a73e462a3df53da446b>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d86f3bcde641b4c18df519c60bc10d09>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b3ffb2b19f45444139b13fc0568f9537>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b24067cfb776b28c2465a46fad4c39cd>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f8ab3456636176a3e9c9876b6c4ed749>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cdda74d195f4dc7bbdbaed3ee174bf7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1642adc2d95a594ec2d1ca1c1679605d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3ad3f00f380cbc79acdede7031c2b35c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_91fdf8e96bd0363c4307fa79933bf9ee>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a900b8b41180a41f1571bb2c4cf6f8e>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a786afdc494302a03a8347211af4f5e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_81de0b469ab0f1e7bc6d7cfef2665991>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6d0547d7d9e564311a780ca9dc7db655>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee988755aabf6d6b8cbe1162f42f9b60>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_939f4702fdcc80c80258913a08838422>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_965a3b769c39b0bedf189a3ea0545ea9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_19a25a0e0bced01a01388502a5fb897a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c277816ed3e96f001ac0003fb11da190>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88b1496ecc213c07fd24b30bb5c856e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3bf9d7b5239a137326d2c5fa821fa737>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b4d34ceb4628d068b1d974c038b79a44>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b84cd883df2cf8f5da7751da99be58c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6d62ed7a3aadce21a3a08f0b111f7e9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bf7af48e7a4158e20b4f833c15de130>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_221457049dd6e599b1e592be3898266a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb1f7ff97f0a93bd0d62291fdf3e87e2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8059ce711ce14c36533947d64fa5a34>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3e2860b55958cf532cc6672e843fd5e5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b0f9e3c706f87be7af57692823441e06>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5169332acacd2cda6014329563a49097>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_82b38e81208f4cf45ccff9cab1f1ab56>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb618da91ef45dc5293c089a74c35488>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ddcedb921562b53aaf13cbc0af192f90>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4e978ba75a8a0f3f4d2d1e75d74ac4de>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5bd441e42294bfab33849ec1b22ce125>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_64826d400df5e2683a863a4dbb954602>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6434b01e914b4662f3f5703792865f82>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5dddc316c01bb02791c37b03fa523bb0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2aedfced5017e33ef2fd58df23b739b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c4dc4b2967ca7204e8ba49b0607e0250>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b1c0cff63caf505f6536baee30943a62>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d73f309e1e17ba4988eef7d15e33e2b5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ddff9a77cb22aafff303a88b4705bee2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_06e5eb766e97cbbd1e9836fc044820b5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_37fc46271b5a9d577e78557058b76819>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2d779c3a3c8b726adf3efb1bfd3cbb40>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_00b59445cb71ad9abff9006cdec65ab0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_140ab31565a9f257f202ece6453c4bfd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cd453f5abbb4020fb3775475830cd8d1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a935037996bf9e3d7f1925320992d343>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e41de5887194c6f47359224ea1f4265d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_52be072c62487a4543b8a1a3d2fbad23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1d718ae1c6eee88a5015989ae3eac075>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_02cf852cc5a543f808433f03632ba155>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a976ac88d60c988f6c82762c8669484>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9283763b81fbf1c4441399956127b6eb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa831217bcc44892538d39aae8c330f6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0aa1cbb10b7e27c8eaa9e1c4d936a012>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1476157c6a284e4f379191854345eea5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53958a524045125d538038a834c170f9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a45f274125d5aab3ada44bd6d91ed7f6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9f22cccb787c8b0be66f7b40706128ae>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7d65f11678621cb189879800cf53faf>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ab7fd2a16f2ab36f5c7b628818e71578>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9e7e71f1a8889f6f7faa45e435ef1f25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_62526b7eac31a4fea5091c2f348a5e23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_218f765d5b26dc460cf68e4f7ef3c8f7>@@XAEAUInferenceContext@onnx@@@std@@
.?AUDataPropagationContext@onnx@@
.?AUDataPropagationContextImpl@shape_inference@onnx@@
.?AV?$_Func_impl_no_alloc@P6AXAEAUDataPropagationContext@onnx@@@ZXAEAU12@@std@@
.?AVAttributeProto@onnx@@
.?AVFunctionProto@onnx@@
.?AVGraphProto@onnx@@
.?AVModelProto@onnx@@
.?AVNodeProto@onnx@@
.?AVOperatorSetIdProto@onnx@@
.?AVSparseTensorProto@onnx@@
.?AVStringStringEntryProto@onnx@@
.?AVTensorAnnotation@onnx@@
.?AVTensorProto@onnx@@
.?AVTensorProto_Segment@onnx@@
.?AVTensorShapeProto@onnx@@
.?AVTensorShapeProto_Dimension@onnx@@
.?AVTrainingInfoProto@onnx@@
.?AVTypeProto@onnx@@
.?AVTypeProto_Map@onnx@@
.?AVTypeProto_Opaque@onnx@@
.?AVTypeProto_Optional@onnx@@
.?AVTypeProto_Sequence@onnx@@
.?AVTypeProto_SparseTensor@onnx@@
.?AVTypeProto_Tensor@onnx@@
.?AVValueInfoProto@onnx@@
.?AVMapProto@onnx@@
.?AVOptionalProto@onnx@@
.?AVSequenceProto@onnx@@
P0+d+
P0EME
VS_VERSION_INFO
StringFileInfo
040904E4
CompanyName
Microsoft Corporation
FileDescription
ONNX Runtime
FileVersion
Internal Build
InternalName
ONNX Runtime
LegalCopyright
 Microsoft Corporation. All rights reserved.
OriginalFilename
onnxruntime.dll
ProductName
Microsoft
 Windows
 Operating System
ProductVersion
Internal Build
VarFileInfo
Translation
Washington1
Redmond1
Microsoft Corporation1(0&
Microsoft Code Signing PCA 20110
210902183259Z
220901183259Z0t1
Washington1
Redmond1
Microsoft Corporation1
Microsoft Corporation0
B5}oN/
hFrGh
E0C1)0'
 Microsoft Operations Puerto Rico1
230012+4675970
M0K0I
Chttp://www.microsoft.com/pkiops/crl/MicCodSigPCA2011_2011-07-08.crl0a
U0S0Q
Ehttp://www.microsoft.com/pkiops/certs/MicCodSigPCA2011_2011-07-08.crt0
,dL@a
Washington1
Redmond1
Microsoft Corporation1200
)Microsoft Root Certificate Authority 20110
110708205909Z
260708210909Z0~1
Washington1
Redmond1
Microsoft Corporation1(0&
Microsoft Code Signing PCA 20110
S0Q0O
Ihttp://crl.microsoft.com/pki/crl/products/MicRooCerAut2011_2011_03_22.crl0^
R0P0N
Bhttp://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt0
3http://www.microsoft.com/pkiops/docs/primarycps.htm0@
Legal_policy_statement
e_.,>
D=xz#
*?*kXIc
QEX82q'
WqVNHE
Washington1
Redmond1
Microsoft Corporation1(0&
Microsoft Code Signing PCA 2011
Microsof
http://www.microsoft.com0
0{4vh
l,wtm
gCY&mB
20220726085702.174Z0
Washington1
Redmond1
Microsoft Corporation1%0#
Microsoft America Operations1&0$
Thales TSS ESN:12BC-E3AE-74EB1%0#
Microsoft Time-Stamp Service
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
211202190524Z
230228190524Z0
Washington1
Redmond1
Microsoft Corporation1%0#
Microsoft America Operations1&0$
Thales TSS ESN:12BC-E3AE-74EB1%0#
Microsoft Time-Stamp Service0
[oz:h<g
2}>E7
l{RsD
X0V0T
Nhttp://www.microsoft.com/pkiops/crl/Microsoft%20Time-Stamp%20PCA%202010(1).crl0l
`0^0\
Phttp://www.microsoft.com/pkiops/certs/Microsoft%20Time-Stamp%20PCA%202010(1).crt0
u2.7Q 
B3utO
&j#fi
Washington1
Redmond1
Microsoft Corporation1200
)Microsoft Root Certificate Authority 20100
210930182225Z
300930183225Z0|1
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
q\Q17
&S|9a
!]_0t
U0S0Q
3http://www.microsoft.com/pkiops/Docs/Repository.htm0
O0M0K
Ehttp://crl.microsoft.com/pki/crl/products/MicRooCerAut_2010-06-23.crl0Z
N0L0J
>http://www.microsoft.com/pki/certs/MicRooCerAut_2010-06-23.crt0
>NGdx
fg:SM
xSu$W
as.,k{n?,
J>f;O
!TkjE
Washington1
Redmond1
Microsoft Corporation1%0#
Microsoft America Operations1&0$
Thales TSS ESN:12BC-E3AE-74EB1%0#
Microsoft Time-Stamp Service
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 20100
20220726112033Z
20220727112033Z0w0=
1/0-0
1(0&0
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 2010
Washington1
Redmond1
Microsoft Corporation1&0$
Microsoft Time-Stamp PCA 2010
J![^Jb
>703HB
